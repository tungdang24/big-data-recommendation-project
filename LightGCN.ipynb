{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Movie Recommendation with LightGCN**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Mu50kKA5_Dur"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n"
      ],
      "metadata": {
        "id": "J_SwBpzH_SLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "print(\"PyTorch has version {}\".format(torch.__version__))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUXbr2wI2RHC",
        "outputId": "02868395-b4df-452b-883d-2378d7edaeae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch has version 2.6.0+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jhucurizRlt",
        "outputId": "f9f0bf58-27b5-466b-e3c6-562741e4d375"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorly\n",
            "  Downloading tensorly-0.9.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from tensorly) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from tensorly) (1.14.1)\n",
            "Downloading tensorly-0.9.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/7.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/7.4 MB\u001b[0m \u001b[31m130.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m131.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m91.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorly\n",
            "Successfully installed tensorly-0.9.0\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_scatter-2.1.2%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m121.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2+pt26cu124\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_sparse-0.6.18%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.14.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-sparse) (2.0.2)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18+pt26cu124\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\n",
            "Collecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_cluster-1.6.3%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-cluster) (1.14.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-cluster) (2.0.2)\n",
            "Installing collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.3+pt26cu124\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\n",
            "Collecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_spline_conv-1.2.2%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.2.2+pt26cu124\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.19.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.1.31)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorly\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.6.0+cu124.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-2.6.0+cu124.html\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-2.6.0+cu124.html\n",
        "!pip install torch-spline-conv -f https://data.pyg.org/whl/torch-2.6.0+cu124.html\n",
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import math\n",
        "import os\n",
        "import os.path as osp\n",
        "from tqdm import tqdm\n",
        "from typing import List\n",
        "import random\n",
        "import time\n",
        "import zipfile\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.options.display.max_rows = 10\n",
        "from sklearn import metrics\n",
        "from tensorly import decomposition\n",
        "\n",
        "import torch\n",
        "from torch.functional import tensordot\n",
        "from torch import nn, optim, Tensor\n",
        "import torch_geometric\n",
        "from torch_geometric.data import Dataset, Data, download_url, extract_zip\n",
        "from torch_geometric.nn import MessagePassing\n",
        "from torch_geometric.typing import Adj"
      ],
      "metadata": {
        "id": "ue8ts-4k0Wvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"PyTorch has version {torch.__version__}\")\n",
        "print(f\"Torch version: {torch.__version__}\")\n",
        "print(f\"Cuda available: {torch.cuda.is_available()}\")\n",
        "print(f\"Torch geometric version: {torch_geometric.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYW0MwN31fdW",
        "outputId": "2c897350-ee95-449b-a878-91b0bd16a74d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch has version 2.6.0+cu124\n",
            "Torch version: 2.6.0+cu124\n",
            "Cuda available: True\n",
            "Torch geometric version: 2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configurations\n"
      ],
      "metadata": {
        "id": "Wl2uLQvH_Vpf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rating_threshold = 3  #@param {type: \"integer\"}: Ratings equal to or greater than 3 are positive items.\n",
        "\n",
        "config_dict = {\n",
        "    \"num_samples_per_user\": 50,\n",
        "    \"num_users\": -1,\n",
        "\n",
        "    \"epochs\": 21,\n",
        "    \"batch_size\": 256,\n",
        "    \"lr\": 0.001,\n",
        "    \"weight_decay\": 0.1,\n",
        "\n",
        "    \"embedding_size\": 32,\n",
        "    \"num_layers\": 3,\n",
        "    \"K\": 10,\n",
        "    \"mf_rank\": 8,\n",
        "\n",
        "    \"minibatch_per_print\": 500,\n",
        "    \"epochs_per_print\": 1,\n",
        "\n",
        "    \"val_frac\": 0.2,\n",
        "    \"test_frac\": 0.1,\n",
        "\n",
        "    \"model_name\": \"model.pth\"\n",
        "}"
      ],
      "metadata": {
        "id": "_nAUZ8LY0wyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset\n",
        "\n",
        "The MovieLens 1M dataset consists of 1 million movie ratings of score 1 to 5, from 6000 users and 4000 movies."
      ],
      "metadata": {
        "id": "fpZBeK9B_Z9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = \"https://files.grouplens.org/datasets/movielens/ml-1m.zip\""
      ],
      "metadata": {
        "id": "8aFE4Jbg14IS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trans_ml(dat, thres):\n",
        "    \"\"\"\n",
        "    Transform function that assign non-negative entries >= thres 1, and non-\n",
        "    negative entries <= thres 0. Keep other entries the same.\n",
        "    \"\"\"\n",
        "    thres = thres[0]\n",
        "    matrix = dat['edge_index']\n",
        "    matrix[(matrix < thres) & (matrix > -1)] = 0\n",
        "    matrix[(matrix >= thres)] = 1\n",
        "    dat['edge_index'] = matrix\n",
        "    return dat\n",
        "\n",
        "\n",
        "class MovieLens(Dataset):\n",
        "    def __init__(self, root, transform=None, pre_transform=None,\n",
        "            transform_args=None, pre_transform_args=None):\n",
        "        \"\"\"\n",
        "        root = where the dataset should be stored. This folder is split\n",
        "        into raw_dir (downloaded dataset) and processed_dir (process data).\n",
        "        \"\"\"\n",
        "        super(MovieLens, self).__init__(root, transform, pre_transform)\n",
        "        self.transform = transform\n",
        "        self.pre_transform = pre_transform\n",
        "        self.transform_args = transform_args\n",
        "        self.pre_transform_args = pre_transform_args\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        return \"ml-1m.zip\"\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        return [\"data_movielens.pt\"]\n",
        "\n",
        "    def download(self):\n",
        "        # Download to `self.raw_dir`.\n",
        "        download_url(DATA_PATH, self.raw_dir)\n",
        "\n",
        "    def _load(self):\n",
        "        print(self.raw_dir)\n",
        "        # extract_zip(self.raw_paths[0], self.raw_dir)\n",
        "        with zipfile.ZipFile(self.raw_paths[0], 'r') as zip_ref:\n",
        "            zip_ref.extractall(self.raw_dir)\n",
        "        unames = ['user_id', 'gender', 'age', 'occupation', 'zip']\n",
        "        users = pd.read_table(self.raw_dir+'/ml-1m/users.dat',\n",
        "                              sep='::', header=None, names=unames,\n",
        "                              engine='python', encoding='latin-1')\n",
        "        rnames = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
        "        ratings = pd.read_table(self.raw_dir+'/ml-1m/ratings.dat', sep='::',\n",
        "                                header=None, names=rnames, engine='python',\n",
        "                                encoding='latin-1')\n",
        "        mnames = ['movie_id', 'title', 'genres']\n",
        "        movies = pd.read_table(self.raw_dir+'/ml-1m/movies.dat', sep='::',\n",
        "                               header=None, names=mnames, engine='python',\n",
        "                               encoding='latin-1')\n",
        "        dat = pd.merge(pd.merge(ratings, users), movies)\n",
        "\n",
        "        return users, ratings, movies, dat\n",
        "\n",
        "    def process(self):\n",
        "        print('run process')\n",
        "        # load information from file\n",
        "        users, ratings, movies, dat = self._load()\n",
        "\n",
        "        users = users['user_id']\n",
        "        movies = movies['movie_id']\n",
        "\n",
        "        num_users = config_dict[\"num_users\"]\n",
        "        if num_users != -1:\n",
        "            users = users[:num_users]\n",
        "\n",
        "        user_ids = range(len(users))\n",
        "        movie_ids = range(len(movies))\n",
        "\n",
        "        user_to_id = dict(zip(users, user_ids))\n",
        "        movie_to_id = dict(zip(movies, movie_ids))\n",
        "\n",
        "        # get adjacency info\n",
        "        self.num_user = users.shape[0]\n",
        "        self.num_item = movies.shape[0]\n",
        "\n",
        "        # initialize the adjacency matrix\n",
        "        rat = torch.zeros(self.num_user, self.num_item)\n",
        "\n",
        "        for index, row in ratings.iterrows():\n",
        "            user, movie, rating = row[:3]\n",
        "            if num_users != -1:\n",
        "                if user not in user_to_id: break\n",
        "            # create ratings matrix where (i, j) entry represents the ratings\n",
        "            # of movie j given by user i.\n",
        "            rat[user_to_id[user], movie_to_id[movie]] = rating\n",
        "\n",
        "        # create Data object\n",
        "        data = Data(edge_index = rat,\n",
        "                    raw_edge_index = rat.clone(),\n",
        "                    data = ratings,\n",
        "                    users = users,\n",
        "                    items = movies)\n",
        "\n",
        "        # apply any pre-transformation\n",
        "        if self.pre_transform is not None:\n",
        "            data = self.pre_transform(data, self.pre_transform_args)\n",
        "\n",
        "        # apply any post_transformation\n",
        "        # if self.transform is not None:\n",
        "        #     # data = self.transform(data, self.transform_args)\n",
        "        data = self.transform(data, [rating_threshold])\n",
        "\n",
        "        # save the processed data into .pt file\n",
        "        torch.save(data, osp.join(self.processed_dir, f'data_movielens.pt'))\n",
        "        print('process finished')\n",
        "\n",
        "    def len(self):\n",
        "        \"\"\"\n",
        "        return the number of examples in your graph\n",
        "        \"\"\"\n",
        "        # TODO: how to define number of examples\n",
        "        return\n",
        "\n",
        "    def get(self):\n",
        "        \"\"\"\n",
        "        The logic to load a single graph\n",
        "        \"\"\"\n",
        "        data = torch.load(osp.join(self.processed_dir, 'data_movielens.pt'), weights_only=False)\n",
        "        return data\n",
        "\n",
        "    def train_val_test_split(self, val_frac=0.2, test_frac=0.1):\n",
        "        \"\"\"\n",
        "        Return two mask matrices (M, N) that represents edges present in the\n",
        "        train and validation set\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.num_user, self.num_item\n",
        "        except AttributeError:\n",
        "            data = self.get()\n",
        "            self.num_user = len(data[\"users\"].unique())\n",
        "            self.num_item = len(data[\"items\"].unique())\n",
        "        # get number of edges masked for training and validation\n",
        "        num_train_replaced = \\\n",
        "            round((test_frac+val_frac)*self.num_user*self.num_item)\n",
        "        num_val_show = round(val_frac*self.num_user*self.num_item)\n",
        "\n",
        "        # edges masked during training\n",
        "        indices_user = np.random.randint(0, self.num_user, num_train_replaced)\n",
        "        indices_item = np.random.randint(0, self.num_item, num_train_replaced)\n",
        "\n",
        "        # sample part of edges from training stage to be unmasked during\n",
        "        # validation\n",
        "        indices_val_user = np.random.choice(indices_user, num_val_show)\n",
        "        indices_val_item = np.random.choice(indices_item, num_val_show)\n",
        "\n",
        "        train_mask = torch.ones(self.num_user, self.num_item)\n",
        "        train_mask[indices_user, indices_item] = 0\n",
        "\n",
        "        val_mask = train_mask.clone()\n",
        "        val_mask[indices_val_user, indices_val_item] = 1\n",
        "\n",
        "        test_mask = torch.ones_like(train_mask)\n",
        "\n",
        "        return train_mask, val_mask, test_mask"
      ],
      "metadata": {
        "id": "IaZK6fwHzyd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LightGCN implementation\n",
        "\n"
      ],
      "metadata": {
        "id": "Fo-HN_lZ_8w1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LightGCN neiborhood aggregation layer\n",
        "\n"
      ],
      "metadata": {
        "id": "qEhZbrpVBeFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LightGCNConv(MessagePassing):\n",
        "    r\"\"\"The neighbor aggregation operator from the `\"LightGCN: Simplifying and\n",
        "    Powering Graph Convolution Network for Recommendation\"\n",
        "    <https://arxiv.org/abs/2002.02126#>`_ paper\n",
        "\n",
        "    Args:\n",
        "        in_channels (int): Size of each input sample, or :obj:`-1` to derive\n",
        "            the size from the first input(s) to the forward method.\n",
        "        out_channels (int): Size of each output sample.\n",
        "        num_users (int): Number of users for recommendation.\n",
        "        num_items (int): Number of items to recommend.\n",
        "        **kwargs (optional): Additional arguments of\n",
        "            :class:`torch_geometric.nn.conv.MessagePassing`.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels: int, out_channels: int,\n",
        "                 num_users: int, num_items: int, **kwargs):\n",
        "        super(LightGCNConv, self).__init__(**kwargs)\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "        self.num_users = num_users\n",
        "        self.num_items = num_items\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        pass  # There are no layer parameters to learn.\n",
        "\n",
        "    def forward(self, x: Tensor, edge_index: Adj) -> Tensor:\n",
        "        \"\"\"Performs neighborhood aggregation for user/item embeddings.\"\"\"\n",
        "        user_item = \\\n",
        "                torch.zeros(self.num_users, self.num_items, device=x.device)\n",
        "        user_item[edge_index[:, 0], edge_index[:, 1]] = 1\n",
        "        user_neighbor_counts = torch.sum(user_item, axis=1)\n",
        "        item_neightbor_counts = torch.sum(user_item, axis=0)\n",
        "        # Compute weight for aggregation: 1 / sqrt(N_u * N_i)\n",
        "        weights = user_item / torch.sqrt(\n",
        "                user_neighbor_counts.repeat(self.num_items, 1).T \\\n",
        "                * item_neightbor_counts.repeat(self.num_users, 1))\n",
        "        weights = torch.nan_to_num(weights, nan=0)\n",
        "        out = torch.concat((weights.T @ x[:self.num_users],\n",
        "                            weights @ x[self.num_users:]), 0)\n",
        "        return out\n",
        "\n",
        "    def __repr__(self):\n",
        "        return '{}({}, {})'.format(self.__class__.__name__, self.in_channels,\n",
        "                                   self.out_channels)\n"
      ],
      "metadata": {
        "id": "WLlXODVwzkJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LightGCN model\n",
        "\n"
      ],
      "metadata": {
        "id": "QWt5WAIjBiQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LightGCN(nn.Module):\n",
        "    def __init__(self,\n",
        "                 config: dict,\n",
        "                 device=None,\n",
        "                 **kwargs):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_users  = config[\"n_users\"]\n",
        "        self.num_items  = config[\"m_items\"]\n",
        "        self.embedding_size = config[\"embedding_size\"]\n",
        "        self.in_channels = self.embedding_size\n",
        "        self.out_channels = self.embedding_size\n",
        "        self.num_layers = config[\"num_layers\"]\n",
        "\n",
        "        # 0-th layer embedding.\n",
        "        self.embedding_user_item = torch.nn.Embedding(\n",
        "            num_embeddings=self.num_users + self.num_items,\n",
        "            embedding_dim=self.embedding_size)\n",
        "        self.alpha = None\n",
        "\n",
        "        # random normal init seems to be a better choice when lightGCN actually\n",
        "        # don't use any non-linear activation function\n",
        "        nn.init.normal_(self.embedding_user_item.weight, std=0.1)\n",
        "        print('use NORMAL distribution initilizer')\n",
        "\n",
        "        self.f = nn.Sigmoid()\n",
        "\n",
        "        self.convs = nn.ModuleList()\n",
        "        self.convs.append(LightGCNConv(\n",
        "                self.embedding_size, self.embedding_size,\n",
        "                num_users=self.num_users, num_items=self.num_items, **kwargs))\n",
        "\n",
        "        for _ in range(1, self.num_layers):\n",
        "            self.convs.append(\n",
        "                LightGCNConv(\n",
        "                        self.embedding_size, self.embedding_size,\n",
        "                        num_users=self.num_users, num_items=self.num_items,\n",
        "                        **kwargs))\n",
        "\n",
        "        self.device = None\n",
        "        if device is not None:\n",
        "            self.convs.to(device)\n",
        "            self.device = device\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "\n",
        "    def forward(self, x: Tensor, edge_index: Adj, *args, **kwargs) -> Tensor:\n",
        "        xs: List[Tensor] = []\n",
        "\n",
        "        edge_index = torch.nonzero(edge_index)\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.convs[i](x, edge_index, *args, **kwargs)\n",
        "            if self.device is not None:\n",
        "                x = x.to(self.device)\n",
        "            xs.append(x)\n",
        "        xs = torch.stack(xs)\n",
        "\n",
        "        self.alpha = 1 / (1 + self.num_layers) * torch.ones(xs.shape)\n",
        "        if self.device is not None:\n",
        "            self.alpha = self.alpha.to(self.device)\n",
        "            xs = xs.to(self.device)\n",
        "        x = (xs * self.alpha).sum(dim=0)  # Sum along K layers.\n",
        "        return x\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return (f'{self.__class__.__name__}({self.in_channels}, '\n",
        "                f'{self.out_channels}, num_layers={self.num_layers})')"
      ],
      "metadata": {
        "id": "wz80KhdizkOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utility functions\n",
        "\n",
        "Retrieve embeddings and compute user-item similarities"
      ],
      "metadata": {
        "id": "kkRJgY39BkLI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getUsersRating(model, users, data):\n",
        "    \"\"\" Get the embedding of users\n",
        "    INPUT:\n",
        "        model: the LightGCN model you are training on\n",
        "        users: this is the user index (note: use 0-indexed and not user number,\n",
        "            which is 1-indexed)\n",
        "        data: the entire data, used to fetch all users and all items\n",
        "    \"\"\"\n",
        "    all_users_items = model(model.embedding_user_item.weight.clone(),\n",
        "                            data[\"edge_index\"])\n",
        "    all_users = all_users_items[:len(data[\"users\"])]\n",
        "    items_emb = all_users_items[len(data[\"users\"]):]\n",
        "    users_emb = all_users[users.long()]\n",
        "    rating = model.f(torch.matmul(users_emb, items_emb.t()))\n",
        "    return rating\n",
        "\n",
        "def getEmbedding(model, users, pos, neg, data, mask):\n",
        "    \"\"\"\n",
        "    INPUT:\n",
        "        model: the LightGCN model you are training on\n",
        "        users: this is the user index (note: use 0-indexed and not user number,\n",
        "            which is 1-indexed)\n",
        "        pos: positive index corresponding to an item that the user like\n",
        "        neg: negative index corresponding to an item that the user doesn't like\n",
        "        data: the entire data, used to fetch all users and all items\n",
        "        mask: Masking matrix indicating edges present in the current\n",
        "            train / validation / test set.\n",
        "    \"\"\"\n",
        "    # assuming we always search for users and items by their indices (instead of\n",
        "    # user/item number)\n",
        "    all_users_items = model(model.embedding_user_item.weight.clone(),\n",
        "                            data[\"edge_index\"] * mask)\n",
        "    all_users = all_users_items[:len(data[\"users\"])]\n",
        "    all_items = all_users_items[len(data[\"users\"]):]\n",
        "    users_emb = all_users[users]\n",
        "    pos_emb = all_items[pos]\n",
        "    neg_emb = all_items[neg]\n",
        "    n_user = len(data[\"users\"])\n",
        "    users_emb_ego = model.embedding_user_item(users)\n",
        "    # offset the index to fetch embedding from user_item\n",
        "    pos_emb_ego = model.embedding_user_item(pos + n_user)\n",
        "    neg_emb_ego = model.embedding_user_item(neg + n_user)\n",
        "    return users_emb, pos_emb, neg_emb, users_emb_ego, pos_emb_ego, neg_emb_ego"
      ],
      "metadata": {
        "id": "yCHmRyqw_s0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bayesian Personalized Ranking loss (BPR loss)\n",
        "\n"
      ],
      "metadata": {
        "id": "K7ct4L3DBnFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bpr_loss(model, users, pos, neg, data, mask):\n",
        "    \"\"\"\n",
        "    INPUT:\n",
        "        model: the LightGCN model you are training on\n",
        "        users: this is the user index (note: use 0-indexed and not user number,\n",
        "            which is 1-indexed)\n",
        "        pos: positive index corresponding to an item that the user like\n",
        "            (0-indexed, note to index items starting from 0)\n",
        "        neg: negative index corresponding to an item that the user doesn't like\n",
        "        data: the entire data, used to fetch all users and all items\n",
        "        mask: Masking matrix indicating edges present in the current\n",
        "            train / validation / test set.\n",
        "    OUTPUT:\n",
        "        loss, reg_loss\n",
        "    \"\"\"\n",
        "    # assuming we always sample the same number of positive and negative sample\n",
        "    # per user\n",
        "    assert len(users) == len(pos) and len(users) == len(neg)\n",
        "    (users_emb, pos_emb, neg_emb,\n",
        "    userEmb0,  posEmb0, negEmb0) = getEmbedding(model, users.long(), pos.long(),\n",
        "                                                neg.long(), data, mask)\n",
        "    reg_loss = (1/2)*(userEmb0.norm(2).pow(2) +\n",
        "                        posEmb0.norm(2).pow(2)  +\n",
        "                        negEmb0.norm(2).pow(2))/float(len(users))\n",
        "    pos_scores = torch.mul(users_emb, pos_emb)\n",
        "    pos_scores = torch.sum(pos_scores, dim=1)\n",
        "    neg_scores = torch.mul(users_emb, neg_emb)\n",
        "    neg_scores = torch.sum(neg_scores, dim=1)\n",
        "\n",
        "    loss = torch.mean(torch.nn.functional.softplus(neg_scores - pos_scores))\n",
        "\n",
        "    return loss, reg_loss"
      ],
      "metadata": {
        "id": "dZ62Sk46_uxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Personalized top K precision and recall\n",
        "\n",
        "Compute the **top K precision and recall** scores. For each user, Rank movie items in order of decreasing similarity and choose the best K to recommend. Then, compute the precision and recall of those K recommendations against ground truth items that the user likes and dislikes"
      ],
      "metadata": {
        "id": "eni-XlbOBydp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def personalized_topk(pred, K, user_indices, edge_index):\n",
        "    \"\"\"Computes TopK precision and recall.\n",
        "\n",
        "    Args:\n",
        "        pred: Predicted similarities between user and item.\n",
        "        K: Number of items to rank.\n",
        "        user_indices: Indices of users for each prediction in `pred`.\n",
        "        edge_index: User and item connection matrix.\n",
        "\n",
        "    Returns:\n",
        "        Average Top K precision and recall for users in `user_indices`.\n",
        "    \"\"\"\n",
        "    per_user_preds = collections.defaultdict(list)\n",
        "    for index, user in enumerate(user_indices):\n",
        "        per_user_preds[user.item()].append(pred[index].item())\n",
        "    precisions = 0.0\n",
        "    recalls = 0.0\n",
        "    for user, preds in per_user_preds.items():\n",
        "        while len(preds) < K:\n",
        "            preds.append(random.choice(range(edge_index.shape[1])))\n",
        "        top_ratings, top_items = torch.topk(torch.tensor(preds), K)\n",
        "        correct_preds = edge_index[user, top_items].sum().item()\n",
        "        total_pos = edge_index[user].sum().item()\n",
        "        precisions += correct_preds / K\n",
        "        recalls += correct_preds / total_pos if total_pos != 0 else 0\n",
        "    num_users = len(user_indices.unique())\n",
        "    return precisions / num_users, recalls / num_users"
      ],
      "metadata": {
        "id": "VjHb_Cr0_0gC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training, validation and testing\n",
        "\n",
        "Train LightGCN model, and run it on the validation and test sets."
      ],
      "metadata": {
        "id": "8VVAYXeFANXe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sampling\n",
        "\n",
        "For each user, randomly sample $n$ positive-negative movie examples and add them to the training, validation or test set. $n$ is a parameter that we can specify and tune."
      ],
      "metadata": {
        "id": "Z4VffTxqAkMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _sample_pos_neg(data, mask, num_samples_per_user):\n",
        "    \"\"\"Samples (user, positive item, negative item) tuples per user.\n",
        "\n",
        "    If a user does not have a postive (negative) item, we choose an item\n",
        "    with unknown liking (an item without raw rating data).\n",
        "\n",
        "    Args:\n",
        "        data: Dataset object containing edge_index and raw ratings matrix.\n",
        "        mask: Masking matrix indicating edges present in the current\n",
        "            train / validation / test set.\n",
        "        num_samples_per_user: Number of samples to generate for each user.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor object of (user, positive item, negative item) samples.\n",
        "    \"\"\"\n",
        "    print(\"=====Starting to sample=====\")\n",
        "    start = time.time()\n",
        "    samples = []\n",
        "    all_items = set(range(len(data[\"items\"])))\n",
        "    for user_index, user in enumerate(data[\"users\"]):\n",
        "        pos_items = set(\n",
        "            torch.nonzero(data[\"edge_index\"][user_index])[:, 0].tolist())\n",
        "        unknown_items = all_items.difference(\n",
        "                set(\n",
        "                    torch.nonzero(\n",
        "                        data[\"raw_edge_index\"][user_index])[:, 0].tolist()))\n",
        "        neg_items = all_items.difference(\n",
        "            set(pos_items)).difference(set(unknown_items))\n",
        "        unmasked_items = set(torch.nonzero(mask[user_index])[:, 0].tolist())\n",
        "        if len(unknown_items.union(pos_items)) == 0 or \\\n",
        "                len(unknown_items.union(neg_items)) == 0:\n",
        "            continue\n",
        "        for _ in range(num_samples_per_user):\n",
        "            if len(pos_items.intersection(unmasked_items)) == 0:\n",
        "                pos_item_index = random.choice(\n",
        "                    list(unknown_items.intersection(unmasked_items)))\n",
        "            else:\n",
        "                pos_item_index = random.choice(\n",
        "                    list(pos_items.intersection(unmasked_items)))\n",
        "            if len(neg_items.intersection(unmasked_items)) == 0:\n",
        "                neg_item_index = random.choice(\n",
        "                    list(unknown_items.intersection(unmasked_items)))\n",
        "            else:\n",
        "                neg_item_index = random.choice(\n",
        "                    list(neg_items.intersection(unmasked_items)))\n",
        "            samples.append((user_index, pos_item_index, neg_item_index))\n",
        "    end = time.time()\n",
        "    print(f\"=====Sampling completed (took {end - start} seconds)=====\")\n",
        "    return torch.tensor(samples, dtype=torch.int32)\n",
        "\n",
        "def sample_pos_neg(data, train_mask, val_mask, test_mask, num_samples_per_user):\n",
        "    \"\"\"Samples (user, positive item, negative item) tuples per user.\n",
        "\n",
        "    If a user does not have a postive (negative) item, we choose an item\n",
        "    with unknown liking (an item without raw rating data).\n",
        "\n",
        "    Args:\n",
        "        data: Dataset object containing edge_index and raw ratings matrix.\n",
        "        train_mask: Masking matrix indicating edges present in train set.\n",
        "        val_mask: Masking matrix indicating edges present in validation set.\n",
        "        test_mask: Masking matrix indicating edges present in test set.\n",
        "        num_samples_per_user: Number of samples to generate for each user.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor object of (user, positive item, negative item) samples for\n",
        "        train, validation and test.\n",
        "    \"\"\"\n",
        "    train_samples = _sample_pos_neg(data, train_mask, num_samples_per_user)\n",
        "    val_samples = _sample_pos_neg(data, val_mask, num_samples_per_user)\n",
        "    test_samples = _sample_pos_neg(data, test_mask, num_samples_per_user)\n",
        "    return train_samples, val_samples, test_samples"
      ],
      "metadata": {
        "id": "qmAgY88nzzGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and validation\n",
        "\n",
        "Start training"
      ],
      "metadata": {
        "id": "LwxJ6gDMAmSF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "root = os.getcwd()\n",
        "movielens = MovieLens(root=root, transform=trans_ml)\n",
        "data = movielens.get()\n",
        "train_mask, val_mask, test_mask = \\\n",
        "        movielens.train_val_test_split(val_frac=config_dict[\"val_frac\"],\n",
        "                                       test_frac=config_dict[\"test_frac\"])\n",
        "\n",
        "n_users = len(data[\"users\"].unique())\n",
        "m_items = len(data[\"items\"].unique())\n",
        "print(f\"#Users: {n_users}\")\n",
        "print(f\"#Items: {m_items}\")\n",
        "\n",
        "model_config = {\n",
        "    \"n_users\": n_users,\n",
        "    \"m_items\": m_items,\n",
        "    \"embedding_size\": config_dict[\"embedding_size\"],\n",
        "    \"num_layers\": config_dict[\"num_layers\"],\n",
        "}\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "lightGCN = LightGCN(model_config, device=device)\n",
        "\n",
        "num_samples_per_user = config_dict[\"num_samples_per_user\"]\n",
        "epochs = config_dict[\"epochs\"]\n",
        "batch_size = config_dict[\"batch_size\"]\n",
        "lr = config_dict[\"lr\"]\n",
        "weight_decay = config_dict[\"weight_decay\"]\n",
        "\n",
        "K = config_dict[\"K\"]\n",
        "\n",
        "lightGCN.to(device)\n",
        "\n",
        "samples_train, samples_val, samples_test = \\\n",
        "        sample_pos_neg(data, train_mask, val_mask, test_mask,\n",
        "                       num_samples_per_user)\n",
        "\n",
        "samples_train=samples_train.to(device)\n",
        "samples_val=samples_val.to(device)\n",
        "samples_test=samples_test.to(device)\n",
        "train_mask=train_mask.to(device)\n",
        "val_mask=val_mask.to(device)\n",
        "test_mask=test_mask.to(device)\n",
        "data = data.to(device)\n",
        "\n",
        "print(f\"#Training samples: {len(samples_train)}\",\n",
        "      f\"#Validation samples: {len(samples_val)}\",\n",
        "      f\"#Test samples: {len(samples_test)}\")\n",
        "\n",
        "optimizer = optim.Adam(lightGCN.parameters(), lr=lr)\n",
        "print(\"Optimizer:\", optimizer)\n",
        "\n",
        "epochs_tracked = []\n",
        "train_topks = []\n",
        "val_topks = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(\"Training on the {} epoch\".format(epoch))\n",
        "    lightGCN.train()\n",
        "    loss_sum = 0\n",
        "    # Shuffle the order of rows.\n",
        "    samples_train = samples_train[torch.randperm(samples_train.size()[0])]\n",
        "    for batch_idx in range(math.ceil(len(samples_train) / batch_size)):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        current_batch = \\\n",
        "            samples_train[batch_idx*batch_size: (batch_idx+1)*batch_size]\n",
        "        # Shuffle the order of rows.\n",
        "        current_batch = current_batch[torch.randperm(current_batch.size()[0])]\n",
        "        users = current_batch[:, 0:1]\n",
        "        pos = current_batch[:, 1:2]\n",
        "        neg = current_batch[:, 2:3]\n",
        "\n",
        "        loss, reg_loss = bpr_loss(lightGCN, users, pos, neg, data,\n",
        "                                  train_mask)\n",
        "        reg_loss = reg_loss * weight_decay\n",
        "        loss = loss + reg_loss\n",
        "        loss_sum += loss.detach()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % config_dict[\"minibatch_per_print\"] == 0:\n",
        "            all_users = torch.linspace(start=0,\n",
        "                                       end=n_users - 1, steps=n_users).long()\n",
        "            user_indices = current_batch[:, 0]\n",
        "            user_indices = user_indices.repeat(2).long()\n",
        "            item_indices = torch.cat(\n",
        "                (current_batch[:, 1], current_batch[:, 2])).long()\n",
        "            pred = getUsersRating(lightGCN,\n",
        "                                  all_users,\n",
        "                                  data)[user_indices, item_indices]\n",
        "            truth = data[\"edge_index\"][user_indices, item_indices]\n",
        "            topk_precision, topk_recall = \\\n",
        "                personalized_topk(pred, K, user_indices, data[\"edge_index\"])\n",
        "\n",
        "            print(\"Training on epoch {} minibatch {}/{} completed\\n\".format(epoch, batch_idx+1,\n",
        "                                                                            math.ceil(len(samples_train) / batch_size)),\n",
        "                  \"bpr_loss on current minibatch is {}, and regularization loss is {}.\\n\".format(round(float(loss.detach().cpu()), 6),\n",
        "                                                                                                 round(float(reg_loss.detach().cpu()), 6)),\n",
        "                  \"Top K precision = {}, recall = {}.\".format(topk_precision, topk_recall))\n",
        "\n",
        "    if epoch % config_dict[\"epochs_per_print\"] == 0:\n",
        "        epochs_tracked.append(epoch)\n",
        "\n",
        "        # evaluation on both the trainisng and validation set\n",
        "        lightGCN.eval()\n",
        "        # predict on the training set\n",
        "        users = samples_train[:, 0:1]\n",
        "        user_indices = samples_train[:, 0]\n",
        "        user_indices = user_indices.repeat(2).long()\n",
        "        item_indices = torch.cat(\n",
        "            (samples_train[:, 1], samples_train[:, 2])).long()\n",
        "        pred = getUsersRating(lightGCN,\n",
        "                              users[:,0],\n",
        "                              data)[user_indices, item_indices]\n",
        "        truth = data[\"edge_index\"][users.long()[:,0]]\\\n",
        "            [user_indices, item_indices]\n",
        "        train_topk_precision, train_topk_recall = \\\n",
        "            personalized_topk(pred, K, user_indices, data[\"edge_index\"])\n",
        "        train_topks.append((train_topk_precision, train_topk_recall))\n",
        "\n",
        "        # predict on the validation set\n",
        "        users_val = samples_val[:, 0:1]\n",
        "        pos_val = samples_val[:, 1:2]\n",
        "        neg_val = samples_val[:, 2:3]\n",
        "\n",
        "        loss_val, reg_loss_val = bpr_loss(\n",
        "            lightGCN, users_val, pos_val, neg_val, data, val_mask)\n",
        "        reg_loss_val = reg_loss_val * weight_decay\n",
        "\n",
        "        # predict on the validation set\n",
        "        user_indices = samples_val[:, 0]\n",
        "        user_indices = user_indices.repeat(2).long()\n",
        "        item_indices = torch.cat((samples_val[:, 1], samples_val[:, 2])).long()\n",
        "        pred_val = getUsersRating(lightGCN,\n",
        "                                  users_val[:,0],\n",
        "                                  data)[user_indices, item_indices]\n",
        "        truth_val = data[\"edge_index\"][users_val.long()[:,0]]\\\n",
        "            [user_indices, item_indices]\n",
        "        val_topk_precision, val_topk_recall = \\\n",
        "            personalized_topk(pred_val, K, user_indices, data[\"edge_index\"])\n",
        "        val_topks.append((val_topk_precision, val_topk_recall))\n",
        "\n",
        "        print(\"\\nTraining on {} epoch completed.\\n\".format(epoch),\n",
        "              \"Average bpr_loss on train set is {} for the current epoch.\\n\".format(round(float(loss_sum/len(samples_train)), 6)),\n",
        "              \"Training top K precision = {}, recall = {}.\\n\".format(train_topk_precision, train_topk_recall),\n",
        "              \"Average bpr_loss on the validation set is {}, and regularization loss is {}.\\n\".format(round(float((loss_val+reg_loss_val)/len(samples_val)), 6),\n",
        "                                                                                                      round(float(reg_loss_val/len(samples_val)), 6)),\n",
        "              \"Validation top K precision = {}, recall = {}.\\n\".format(val_topk_precision, val_topk_recall))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-NbgY1GzkR7",
        "outputId": "67cb174c-787c-4013-e1ba-bbaeb3b81b9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
            "Processing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run process\n",
            "/content/raw\n",
            "process finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#Users: 6040\n",
            "#Items: 3883\n",
            "use NORMAL distribution initilizer\n",
            "=====Starting to sample=====\n",
            "=====Sampling completed (took 10.827497005462646 seconds)=====\n",
            "=====Starting to sample=====\n",
            "=====Sampling completed (took 10.893268823623657 seconds)=====\n",
            "=====Starting to sample=====\n",
            "=====Sampling completed (took 10.81920838356018 seconds)=====\n",
            "#Training samples: 302000 #Validation samples: 302000 #Test samples: 302000\n",
            "Optimizer: Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.001\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "Training on the 0 epoch\n",
            "Training on epoch 0 minibatch 1/1180 completed\n",
            " bpr_loss on current minibatch is 0.74138, and regularization loss is 0.048233.\n",
            " Top K precision = 0.07649402390438247, recall = 0.006626007357624458.\n",
            "Training on epoch 0 minibatch 501/1180 completed\n",
            " bpr_loss on current minibatch is 0.698468, and regularization loss is 0.005321.\n",
            " Top K precision = 0.08968253968253972, recall = 0.0065258404545827245.\n",
            "Training on epoch 0 minibatch 1001/1180 completed\n",
            " bpr_loss on current minibatch is 0.694264, and regularization loss is 0.001117.\n",
            " Top K precision = 0.09645669291338582, recall = 0.006674557823689925.\n",
            "\n",
            "Training on 0 epoch completed.\n",
            " Average bpr_loss on train set is 0.002743 for the current epoch.\n",
            " Training top K precision = 0.045331125827813866, recall = 0.0034121448228644023.\n",
            " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.04552980132450264, recall = 0.0033598479489205316.\n",
            "\n",
            "Training on the 1 epoch\n",
            "Training on epoch 1 minibatch 1/1180 completed\n",
            " bpr_loss on current minibatch is 0.693828, and regularization loss is 0.000681.\n",
            " Top K precision = 0.10916334661354596, recall = 0.007696546926585893.\n",
            "Training on epoch 1 minibatch 501/1180 completed\n",
            " bpr_loss on current minibatch is 0.693377, and regularization loss is 0.00023.\n",
            " Top K precision = 0.10000000000000003, recall = 0.006825752533396927.\n",
            "Training on epoch 1 minibatch 1001/1180 completed\n",
            " bpr_loss on current minibatch is 0.693193, and regularization loss is 4.6e-05.\n",
            " Top K precision = 0.0909448818897638, recall = 0.007406401290651773.\n",
            "\n",
            "Training on 1 epoch completed.\n",
            " Average bpr_loss on train set is 0.002709 for the current epoch.\n",
            " Training top K precision = 0.026142384105959777, recall = 0.0018604211383980787.\n",
            " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.02539735099337703, recall = 0.0017772452785411574.\n",
            "\n",
            "Training on the 2 epoch\n",
            "Training on epoch 2 minibatch 1/1180 completed\n",
            " bpr_loss on current minibatch is 0.6932, and regularization loss is 5.3e-05.\n",
            " Top K precision = 0.08181818181818186, recall = 0.006915567704867372.\n",
            "Training on epoch 2 minibatch 501/1180 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.08359999999999998, recall = 0.00649655987462743.\n",
            "Training on epoch 2 minibatch 1001/1180 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.08313725490196082, recall = 0.0051884052103803955.\n",
            "\n",
            "Training on 2 epoch completed.\n",
            " Average bpr_loss on train set is 0.002708 for the current epoch.\n",
            " Training top K precision = 0.02332781456953606, recall = 0.001678761213488808.\n",
            " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.022566225165562562, recall = 0.0016320942504368392.\n",
            "\n",
            "Training on the 3 epoch\n",
            "Training on epoch 3 minibatch 1/1180 completed\n",
            " bpr_loss on current minibatch is 0.69315, and regularization loss is 3e-06.\n",
            " Top K precision = 0.09681274900398407, recall = 0.007425718662125999.\n",
            "Training on epoch 3 minibatch 501/1180 completed\n",
            " bpr_loss on current minibatch is 0.693151, and regularization loss is 4e-06.\n",
            " Top K precision = 0.08611111111111115, recall = 0.007085771016064177.\n",
            "Training on epoch 3 minibatch 1001/1180 completed\n",
            " bpr_loss on current minibatch is 0.693152, and regularization loss is 5e-06.\n",
            " Top K precision = 0.09322709163346617, recall = 0.0075421076250254074.\n",
            "\n",
            "Training on 3 epoch completed.\n",
            " Average bpr_loss on train set is 0.002708 for the current epoch.\n",
            " Training top K precision = 0.022930463576158588, recall = 0.0016616865755626176.\n",
            " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.02263245033112547, recall = 0.0016422484470888545.\n",
            "\n",
            "Training on the 4 epoch\n",
            "Training on epoch 4 minibatch 1/1180 completed\n",
            " bpr_loss on current minibatch is 0.693151, and regularization loss is 4e-06.\n",
            " Top K precision = 0.08392156862745102, recall = 0.006286693863300728.\n",
            "Training on epoch 4 minibatch 501/1180 completed\n",
            " bpr_loss on current minibatch is 0.693151, and regularization loss is 4e-06.\n",
            " Top K precision = 0.0814516129032259, recall = 0.006268988310598721.\n",
            "Training on epoch 4 minibatch 1001/1180 completed\n",
            " bpr_loss on current minibatch is 0.693152, and regularization loss is 5e-06.\n",
            " Top K precision = 0.08406374501992038, recall = 0.006350001397215476.\n",
            "\n",
            "Training on 4 epoch completed.\n",
            " Average bpr_loss on train set is 0.002708 for the current epoch.\n",
            " Training top K precision = 0.02274834437086057, recall = 0.0016382481011009784.\n",
            " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.0224668874172182, recall = 0.001607681634476708.\n",
            "\n",
            "Training on the 5 epoch\n",
            "Training on epoch 5 minibatch 1/1180 completed\n",
            " bpr_loss on current minibatch is 0.693154, and regularization loss is 7e-06.\n",
            " Top K precision = 0.09601593625498014, recall = 0.006306565206868394.\n",
            "Training on epoch 5 minibatch 501/1180 completed\n",
            " bpr_loss on current minibatch is 0.693154, and regularization loss is 7e-06.\n",
            " Top K precision = 0.08373015873015878, recall = 0.006285826000515968.\n",
            "Training on epoch 5 minibatch 1001/1180 completed\n",
            " bpr_loss on current minibatch is 0.693153, and regularization loss is 6e-06.\n",
            " Top K precision = 0.0963414634146342, recall = 0.007274644720005548.\n",
            "\n",
            "Training on 5 epoch completed.\n",
            " Average bpr_loss on train set is 0.002708 for the current epoch.\n",
            " Training top K precision = 0.022533112582781102, recall = 0.001623668094850751.\n",
            " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.022599337748344023, recall = 0.0016207057716089218.\n",
            "\n",
            "Training on the 6 epoch\n",
            "Training on epoch 6 minibatch 1/1180 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.08087649402390436, recall = 0.006671578937485211.\n",
            "Training on epoch 6 minibatch 501/1180 completed\n",
            " bpr_loss on current minibatch is 0.693155, and regularization loss is 8e-06.\n",
            " Top K precision = 0.07309236947791162, recall = 0.006352424114097815.\n",
            "Training on epoch 6 minibatch 1001/1180 completed\n",
            " bpr_loss on current minibatch is 0.693155, and regularization loss is 8e-06.\n",
            " Top K precision = 0.08452380952380951, recall = 0.006346042272907799.\n",
            "\n",
            "Training on 6 epoch completed.\n",
            " Average bpr_loss on train set is 0.002708 for the current epoch.\n",
            " Training top K precision = 0.022649006622516205, recall = 0.001624102505073007.\n",
            " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.022549668874171834, recall = 0.0016310163987323018.\n",
            "\n",
            "Training on the 7 epoch\n",
            "Training on epoch 7 minibatch 1/1180 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.0827309236947791, recall = 0.006107082767216214.\n",
            "Training on epoch 7 minibatch 501/1180 completed\n",
            " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
            " Top K precision = 0.08104838709677423, recall = 0.005703477081131285.\n",
            "Training on epoch 7 minibatch 1001/1180 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.09560000000000002, recall = 0.006627305229304977.\n",
            "\n",
            "Training on 7 epoch completed.\n",
            " Average bpr_loss on train set is 0.002708 for the current epoch.\n",
            " Training top K precision = 0.022549668874171827, recall = 0.0016187740088596243.\n",
            " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.02249999999999966, recall = 0.0016113252362485488.\n",
            "\n",
            "Training on the 8 epoch\n",
            "Training on epoch 8 minibatch 1/1180 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.08968253968253978, recall = 0.006488817211224645.\n",
            "Training on epoch 8 minibatch 501/1180 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 9e-06.\n",
            " Top K precision = 0.0876984126984127, recall = 0.006321760488212082.\n",
            "Training on epoch 8 minibatch 1001/1180 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.07479999999999996, recall = 0.006044479600475676.\n",
            "\n",
            "Training on 8 epoch completed.\n",
            " Average bpr_loss on train set is 0.002708 for the current epoch.\n",
            " Training top K precision = 0.022549668874171844, recall = 0.0016302353809137388.\n",
            " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.02251655629139039, recall = 0.0016090157479893557.\n",
            "\n",
            "Training on the 9 epoch\n",
            "Training on epoch 9 minibatch 1/1180 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.09446640316205537, recall = 0.006306423350191427.\n",
            "Training on epoch 9 minibatch 501/1180 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 9e-06.\n",
            " Top K precision = 0.09055118110236224, recall = 0.007013823865375894.\n",
            "Training on epoch 9 minibatch 1001/1180 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.08893280632411069, recall = 0.005772048126142786.\n",
            "\n",
            "Training on 9 epoch completed.\n",
            " Average bpr_loss on train set is 0.002708 for the current epoch.\n",
            " Training top K precision = 0.022367549668873807, recall = 0.001601230569104824.\n",
            " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.0224668874172182, recall = 0.0016131099294402487.\n",
            "\n",
            "Training on the 10 epoch\n",
            "Training on epoch 10 minibatch 1/1180 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.07258064516129031, recall = 0.005701163521308194.\n",
            "Training on epoch 10 minibatch 501/1180 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.08503937007874016, recall = 0.006153659220085937.\n",
            "Training on epoch 10 minibatch 1001/1180 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1e-05.\n",
            " Top K precision = 0.09397590361445785, recall = 0.007440732180494334.\n",
            "\n",
            "Training on 10 epoch completed.\n",
            " Average bpr_loss on train set is 0.002708 for the current epoch.\n",
            " Training top K precision = 0.02246688741721819, recall = 0.0016138231934629912.\n",
            " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.022384105960264557, recall = 0.001599238733399288.\n",
            "\n",
            "Training on the 11 epoch\n",
            "Training on epoch 11 minibatch 1/1180 completed\n",
            " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
            " Top K precision = 0.07450199203187248, recall = 0.007248063887811076.\n",
            "Training on epoch 11 minibatch 501/1180 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.10557768924302798, recall = 0.006774384122115477.\n",
            "Training on epoch 11 minibatch 1001/1180 completed\n",
            " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
            " Top K precision = 0.08293650793650793, recall = 0.006115205269609563.\n",
            "\n",
            "Training on 11 epoch completed.\n",
            " Average bpr_loss on train set is 0.002708 for the current epoch.\n",
            " Training top K precision = 0.02251655629139038, recall = 0.0016177575071846355.\n",
            " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.022632450331125476, recall = 0.0016189650403985608.\n",
            "\n",
            "Training on the 12 epoch\n",
            "Training on epoch 12 minibatch 1/1180 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.08259109311740889, recall = 0.005558004951234782.\n",
            "Training on epoch 12 minibatch 501/1180 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.09068825910931175, recall = 0.006622489960391107.\n",
            "Training on epoch 12 minibatch 1001/1180 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.09277108433734936, recall = 0.006332956893931551.\n",
            "\n",
            "Training on 12 epoch completed.\n",
            " Average bpr_loss on train set is 0.002708 for the current epoch.\n",
            " Training top K precision = 0.022698675496688383, recall = 0.0016362613029959486.\n",
            " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.022384105960264557, recall = 0.001605756420028104.\n",
            "\n",
            "Training on the 13 epoch\n",
            "Training on epoch 13 minibatch 1/1180 completed\n",
            " bpr_loss on current minibatch is 0.693155, and regularization loss is 8e-06.\n",
            " Top K precision = 0.08228346456692918, recall = 0.005706723889290966.\n",
            "Training on epoch 13 minibatch 501/1180 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.08326693227091642, recall = 0.006694852498695728.\n",
            "Training on epoch 13 minibatch 1001/1180 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.09442231075697217, recall = 0.0065016652120876645.\n",
            "\n",
            "Training on 13 epoch completed.\n",
            " Average bpr_loss on train set is 0.002708 for the current epoch.\n",
            " Training top K precision = 0.022781456953642008, recall = 0.0016219475484112657.\n",
            " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.022433774834436742, recall = 0.0016189322593796137.\n",
            "\n",
            "Training on the 14 epoch\n",
            "Training on epoch 14 minibatch 1/1180 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.08814229249011861, recall = 0.007292409494217083.\n",
            "Training on epoch 14 minibatch 501/1180 completed\n",
            " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
            " Top K precision = 0.10520000000000009, recall = 0.007168091763605116.\n",
            "Training on epoch 14 minibatch 1001/1180 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.09635627530364373, recall = 0.006970389862763033.\n",
            "\n",
            "Training on 14 epoch completed.\n",
            " Average bpr_loss on train set is 0.002708 for the current epoch.\n",
            " Training top K precision = 0.022533112582781116, recall = 0.0016146416481396544.\n",
            " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.022483443708608924, recall = 0.0016137076274940754.\n",
            "\n",
            "Training on the 15 epoch\n",
            "Training on epoch 15 minibatch 1/1180 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.08674698795180721, recall = 0.0064231645712102.\n",
            "Training on epoch 15 minibatch 501/1180 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.08928571428571434, recall = 0.007800180462920536.\n",
            "Training on epoch 15 minibatch 1001/1180 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.09169960474308307, recall = 0.006340169260832966.\n",
            "\n",
            "Training on 15 epoch completed.\n",
            " Average bpr_loss on train set is 0.002708 for the current epoch.\n",
            " Training top K precision = 0.022715231788079097, recall = 0.00162835996581929.\n",
            " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.02249999999999965, recall = 0.0016102138448085457.\n",
            "\n",
            "Training on the 16 epoch\n",
            "Training on epoch 16 minibatch 1/1180 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.09399999999999999, recall = 0.007463313015973024.\n",
            "Training on epoch 16 minibatch 501/1180 completed\n",
            " bpr_loss on current minibatch is 0.693156, and regularization loss is 8e-06.\n",
            " Top K precision = 0.0908, recall = 0.006278346046623393.\n",
            "Training on epoch 16 minibatch 1001/1180 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1e-05.\n",
            " Top K precision = 0.08525896414342632, recall = 0.0068087417135186444.\n",
            "\n",
            "Training on 16 epoch completed.\n",
            " Average bpr_loss on train set is 0.002708 for the current epoch.\n",
            " Training top K precision = 0.022450331125827467, recall = 0.0016141578689890719.\n",
            " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.022533112582781113, recall = 0.0016137881234621772.\n",
            "\n",
            "Training on the 17 epoch\n",
            "Training on epoch 17 minibatch 1/1180 completed\n",
            " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
            " Top K precision = 0.07831325301204818, recall = 0.006122378148296986.\n",
            "Training on epoch 17 minibatch 501/1180 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.09637096774193553, recall = 0.007200955590148708.\n",
            "Training on epoch 17 minibatch 1001/1180 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.08634538152610446, recall = 0.0062639700210326416.\n",
            "\n",
            "Training on 17 epoch completed.\n",
            " Average bpr_loss on train set is 0.002708 for the current epoch.\n",
            " Training top K precision = 0.02251655629139042, recall = 0.0016079428975984832.\n",
            " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.02251655629139038, recall = 0.0016154563645618546.\n",
            "\n",
            "Training on the 18 epoch\n",
            "Training on epoch 18 minibatch 1/1180 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.09604743083003961, recall = 0.006165664625130235.\n",
            "Training on epoch 18 minibatch 501/1180 completed\n",
            " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
            " Top K precision = 0.09137254901960784, recall = 0.006854139448520309.\n",
            "Training on epoch 18 minibatch 1001/1180 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.1136000000000001, recall = 0.00612683037480622.\n",
            "\n",
            "Training on 18 epoch completed.\n",
            " Average bpr_loss on train set is 0.002708 for the current epoch.\n",
            " Training top K precision = 0.022582781456953294, recall = 0.0016281277084282404.\n",
            " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.022533112582781113, recall = 0.0016133906588057844.\n",
            "\n",
            "Training on the 19 epoch\n",
            "Training on epoch 19 minibatch 1/1180 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.09598393574297193, recall = 0.0062025938487459305.\n",
            "Training on epoch 19 minibatch 501/1180 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.08087649402390439, recall = 0.006571451714662419.\n",
            "Training on epoch 19 minibatch 1001/1180 completed\n",
            " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
            " Top K precision = 0.08690476190476194, recall = 0.006383821981084703.\n",
            "\n",
            "Training on 19 epoch completed.\n",
            " Average bpr_loss on train set is 0.002708 for the current epoch.\n",
            " Training top K precision = 0.02264900662251622, recall = 0.001626887026105448.\n",
            " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.022417218543046014, recall = 0.0016059720996582799.\n",
            "\n",
            "Training on the 20 epoch\n",
            "Training on epoch 20 minibatch 1/1180 completed\n",
            " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
            " Top K precision = 0.0980237154150198, recall = 0.006763177190199832.\n",
            "Training on epoch 20 minibatch 501/1180 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.0804, recall = 0.006805635049259207.\n",
            "Training on epoch 20 minibatch 1001/1180 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.09271255060728754, recall = 0.0065392838371096055.\n",
            "\n",
            "Training on 20 epoch completed.\n",
            " Average bpr_loss on train set is 0.002708 for the current epoch.\n",
            " Training top K precision = 0.022533112582781088, recall = 0.0016224554571425153.\n",
            " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.0224668874172182, recall = 0.0016126679444665646.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot top K precision over epochs"
      ],
      "metadata": {
        "id": "77xV_pCdAqV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(epochs_tracked, [precision for precision, _ in train_topks],\n",
        "         label=\"Train\")\n",
        "plt.plot(epochs_tracked, [precision for precision, _ in val_topks],\n",
        "         label=\"Val\")\n",
        "plt.ylabel(f\"Top {K} precision\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "DhWgVYTn6F05",
        "outputId": "3a6f54cd-2bcc-4bc4-c332-de8c9f73c5be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkgAAAGwCAYAAABSN5pGAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAVvZJREFUeJzt3Xl4U3W+P/D3yb606UpbimVH9kVAanEccagWN8TLjMgPFZArouxFR3GURUdBEcSFC8OM61XEYUaZcYNbUJCBAgLiCijIThe6JumS9fz+OGloupG0SU/Svl/Pk6fJycnJ5/Q05M33LB9BFEURREREROSlkLsAIiIionDDgERERERUBwMSERERUR0MSERERER1MCARERER1cGARERERFQHAxIRERFRHSq5C4hUbrcbFy5cQHR0NARBkLscIiIi8oMoirBYLEhNTYVC0fg4EQNSM124cAFpaWlyl0FERETNcPbsWVxxxRWNPs+A1EzR0dEApF+wyWSSuRoiIiLyh9lsRlpamvd7vDEMSM1Us1vNZDIxIBEREUWYyx0ew4O0iYiIiOpgQCIiIiKqgwGJiIiIqA4eg0RERBRGXC4XHA6H3GVELLVaDaVS2eLlMCARERGFAVEUkZ+fj7KyMrlLiXixsbFISUlp0XUKGZCIiIjCQE04SkpKgsFg4EWIm0EURVRWVqKwsBAA0LFjx2YviwGJiIhIZi6XyxuOEhIS5C4noun1egBAYWEhkpKSmr27jQdpExERyazmmCODwSBzJW1Dze+xJcdyMSARERGFCe5WC45g/B4ZkIiIiIjqYEAiIiIiqoMBiYiIiMJK165dsXr1allrYEAKN5UlQNFxwFEtdyVERERNEgShyduSJUuatdyvv/4a06dPD26xAeJp/uFm3XWA+RzwwBdAp2FyV0NERNSovLw87/0PPvgAixYtwrFjx7zToqKivPdFUYTL5YJKdfno0aFDh+AW2gwcQQo3hnjpZ2WJvHUQEZGsRFFEpd0py00URb9qTElJ8d5iYmIgCIL38dGjRxEdHY3PP/8cw4YNg1arxX/+8x+cOHECd9xxB5KTkxEVFYWrr74a27Zt81lu3V1sgiDgb3/7G+68804YDAb06tUL//73v4P5666HI0hhpkIZAyOAqvJC6OUuhoiIZFPlcKHfoq2yvPdPT2fBoAlORHj88cfx4osvonv37oiLi8PZs2dxyy234Nlnn4VWq8U777yD22+/HceOHUPnzp0bXc7SpUvxwgsvYMWKFXj11VcxadIknD59GvHx8UGpsy6OIIWZPXlSai8uvCBzJURERC339NNP48Ybb0SPHj0QHx+PwYMH48EHH8SAAQPQq1cvPPPMM+jRo8dlR4SmTJmCiRMnomfPnnjuuedgtVqxf//+kNXNEaQwU62JBaoBh6VY7lKIiEhGerUSPz2dJdt7B8vw4cN9HlutVixZsgSffvop8vLy4HQ6UVVVhTNnzjS5nEGDBnnvG41GmEwmb8+1UJB9BGnNmjXo2rUrdDod0tPTL5sGN23ahD59+kCn02HgwIH47LPPGp13xowZEASh3qmCXbt2rXek/fLly4OxOi3m1EpDhe6KIpkrISIiOQmCAINGJcstmFf0NhqNPo8feeQRfPTRR3juueewa9cuHD58GAMHDoTdbm9yOWq1ut7vx+12B63OumQNSB988AGys7OxePFiHDp0CIMHD0ZWVlajiXDPnj2YOHEipk2bhm+++Qbjxo3DuHHj8MMPP9Sb96OPPsLevXuRmpra4LKefvpp5OXleW+zZ88O6ro1l1vn2ZdaxYO0iYio7dm9ezemTJmCO++8EwMHDkRKSgpOnTold1n1yBqQVq1ahQceeABTp05Fv379sG7dOhgMBrzxxhsNzv/yyy9jzJgxePTRR9G3b18888wzGDp0KF577TWf+c6fP4/Zs2fjvffeq5c4a0RHR/scfV834cpFMEoBSVXNgERERG1Pr1698OGHH+Lw4cP49ttv8f/+3/8L6UhQc8kWkOx2Ow4ePIjMzMxLxSgUyMzMRG5uboOvyc3N9ZkfALKysnzmd7vduPfee/Hoo4+if//+jb7/8uXLkZCQgKuuugorVqyA0+lssl6bzQaz2exzCwVlVCIAQGMvC8nyiYiI5LRq1SrExcVh5MiRuP3225GVlYWhQ4fKXVY9sh2kXVRUBJfLheTkZJ/pycnJOHr0aIOvyc/Pb3D+/Px87+Pnn38eKpUKc+bMafS958yZg6FDhyI+Ph579uzBwoULkZeXh1WrVjX6mmXLlmHp0qX+rFqLaE3SxbH0zvKQvxcREVGwTJkyBVOmTPE+HjVqVIPXU+ratSu++OILn2kzZ870eVx3l1tDyykrK2t2rf5oU2exHTx4EC+//DIOHTrU5AFm2dnZ3vuDBg2CRqPBgw8+iGXLlkGr1Tb4moULF/q8zmw2Iy0tLXjFe+hjkgAAUa5yQBSBIB4oR0RERP6RbRdbYmIilEolCgoKfKYXFBQgJSWlwdekpKQ0Of+uXbtQWFiIzp07Q6VSQaVS4fTp01iwYAG6du3aaC3p6elwOp1NHiSm1WphMpl8bqEQFScFJBVcgC00u/GIiIioabIFJI1Gg2HDhmH79u3eaW63G9u3b0dGRkaDr8nIyPCZHwBycnK8899777347rvvcPjwYe8tNTUVjz76KLZubfxqpIcPH4ZCoUBSUlIQ1qxl4mJMqBQ9o1iVvBYSERGRHGTdxZadnY3Jkydj+PDhGDFiBFavXo2KigpMnToVAHDfffehU6dOWLZsGQBg7ty5uP7667Fy5Urceuut2LhxIw4cOID169cDABISEpCQkODzHmq1GikpKejduzcA6UDvffv24YYbbkB0dDRyc3Mxf/583HPPPYiLi2vFtW9YglGLEkTDABvsliJo4rvLXRIREVG7I2tAmjBhAi5evIhFixYhPz8fQ4YMwZYtW7wHYp85cwYKxaVBrpEjR2LDhg148skn8cQTT6BXr17YvHkzBgwY4Pd7arVabNy4EUuWLIHNZkO3bt0wf/58n+OL5GTSq3BWjMYVQhGspQWI7yJ3RURERO2PIPrbspd8mM1mxMTEoLy8POjHI+1d+ltcI36Lc9evwhU3TAvqsomIKPxUV1fj5MmT6NatG3Q6ndzlRLymfp/+fn/L3mqE6qtSxQAA7JaLMldCRETUPjEghSGbRjoWymnlQdpERERyYEAKQ06dFJDcFQxIRETUto0aNQrz5s2Tu4x6GJDCkKiXzsRTsGEtERGFsdtvvx1jxoxp8Lldu3ZBEAR89913rVxVcDAghSGFQWpYq7aVylwJERFR46ZNm4acnBycO3eu3nNvvvkmhg8fjkGDBslQWcsxIIUhtacfGxvWEhFROLvtttvQoUMHvPXWWz7TrVYrNm3ahHHjxmHixIno1KkTDAYDBg4ciPfff1+eYgPEgBSGahrWGl1sWEtE1G6JImCvkOfm5xWAVCoV7rvvPrz11ls+DWU3bdoEl8uFe+65B8OGDcOnn36KH374AdOnT8e9996L/fv3h+q3FjRtqlltW2GMlVqeRLvZsJaIqN1yVALPpcrz3k9cADRGv2a9//77sWLFCuzcuROjRo0CIO1eGz9+PLp06YJHHnnEO+/s2bOxdetW/P3vf8eIESNCUXnQcAQpDEXHSwFJCTdQzVEkIiIKX3369MHIkSPxxhtvAACOHz+OXbt2Ydq0aXC5XHjmmWcwcOBAxMfHIyoqClu3bsWZM2dkrvryOIIUhuJiTKgQtTAKNrgqSqDUx8pdEhERtTa1QRrJkeu9AzBt2jTMnj0ba9aswZtvvokePXrg+uuvx/PPP4+XX34Zq1evxsCBA2E0GjFv3jzY7fYQFR48DEhhKM6gQQGiYYQN1tJ8xCSyYS0RUbsjCH7v5pLbXXfdhblz52LDhg1455138NBDD0EQBOzevRt33HEH7rnnHgCA2+3Gzz//jH79+slc8eVxF1sYUisVKBek/jAVpYUyV0NERNS0qKgoTJgwAQsXLkReXh6mTJkCAOjVqxdycnKwZ88eHDlyBA8++CAKCgrkLdZPDEhhqlIpBaSqcgYkIiIKf9OmTUNpaSmysrKQmiodXP7kk09i6NChyMrKwqhRo5CSkoJx48bJW6ifuIstTFWpYwEXYDezYS0REYW/jIwMn1P9ASA+Ph6bN29u8nU7duwIXVEtwBGkMGX3NKx1sR8bERFRq2NAClNundRuBJXsx0ZERNTaGJDClacfm5INa4mIiFodA1KYUkYlAgDUdjasJSIiam0MSGFKHS0FJJ2DV9ImImov6h7kTM0TjN8jA1KY0sVI7UbYsJaIqO1Tq9UAgMrKSpkraRtqfo81v9fm4Gn+YSoqLhkAEC2aAbcbUDDLEhG1VUqlErGxsSgslK59ZzAYILBRecBEUURlZSUKCwsRGxsLpVLZ7GUxIIUpk6dhrQpuiNXlEAxxMldEREShlJKSAgDekETNFxsb6/19NhcDUpiKj4mGVdQhSqhGRXkhohiQiIjaNEEQ0LFjRyQlJcHhcMhdTsRSq9UtGjmqwYAUpgwaFc4hGlGohrWkEFEde8tdEhERtQKlUhmUL3hqGR7YEsYsihgAQEVpZDT2IyIiaisYkMJYpUpqWGtjPzYiIqJWxYAUxqrV0nFHdkuRzJUQERG1LwxIYcyplQKSyIa1RERErYoBKYy59VI/NqGKAYmIiKg1MSCFMcHoaVhbzX5sRERErYkBKYypPA1rtfYyeQshIiJqZxiQwpjW1AEAoHeWyVsIERFRO8OAFMYMsVK7kSiXWeZKiIiI2hcGpDAWFScFJFNNw1oiIiJqFQxIYSwmPhkAoBRE2CpKZK6GiIio/WBACmOmqChYRD0AwFzM7s5ERESthQEpjCkUAsqFaACApTRf5mqIiIjaDwakMGdVSg1rq8o4gkRERNRaGJDCXLVKCkh2NqwlIiJqNQxIYc6ukfqxOa1sN0JERNRaGJDCnFPnaVhbyYBERETUWhiQwpxbnwAAEKp4mj8REVFrYUAKc0pPw1q1jQ1riYiIWgsDUphTR0v92NiwloiIqPUwIIU5nadhrcFVLnMlRERE7QcDUpgz1PRjc7NhLRERUWthQApzpjipH5tJtMDlcslcDRERUfvAgBTmYhIvNaw1lxbJXA0REVH7wIAU5tQaHSzwNKwtYT82IiKi1sCAFAHMggkAUFHKfmxEREStgQEpAlTWNKwtZ0AiIiJqDQxIEaBaHQuADWuJiIhaCwNSBLBrpX5srgr2YyMiImoNDEgRwKWT2o0IbFhLRETUKhiQIoBgkBrWKqvZj42IiKg1MCBFAKVRCkhsWEtERNQ6GJAigMaUCADQOdiPjYiIqDUwIEUAXYzUjy3KzYBERETUGhiQIoCxph+b2wxRFGWuhoiIqO1jQIoAMQnSCFIMrKiotstcDRERUdvHgBQB9KYOAACFIKKsmBeLJCIiCjUGpAggqDSwwAAAsJQWyFwNERFR2yd7QFqzZg26du0KnU6H9PR07N+/v8n5N23ahD59+kCn02HgwIH47LPPGp13xowZEAQBq1ev9pleUlKCSZMmwWQyITY2FtOmTYPVag3G6oSMRSH1Y6ssY0AiIiIKNVkD0gcffIDs7GwsXrwYhw4dwuDBg5GVlYXCwoabsu7ZswcTJ07EtGnT8M0332DcuHEYN24cfvjhh3rzfvTRR9i7dy9SU1PrPTdp0iT8+OOPyMnJwSeffIKvvvoK06dPD/r6BVOVSgpI1eXcxUZERBRqsgakVatW4YEHHsDUqVPRr18/rFu3DgaDAW+88UaD87/88ssYM2YMHn30UfTt2xfPPPMMhg4ditdee81nvvPnz2P27Nl47733oFarfZ47cuQItmzZgr/97W9IT0/Hb37zG7z66qvYuHEjLly40GitNpsNZrPZ59aaahrWOq1Frfq+RERE7ZFsAclut+PgwYPIzMy8VIxCgczMTOTm5jb4mtzcXJ/5ASArK8tnfrfbjXvvvRePPvoo+vfv3+AyYmNjMXz4cO+0zMxMKBQK7Nu3r9F6ly1bhpiYGO8tLS3N73UNBicb1hIREbUa2QJSUVERXC4XkpOTfaYnJycjPz+/wdfk5+dfdv7nn38eKpUKc+bMaXQZSUlJPtNUKhXi4+MbfV8AWLhwIcrLy723s2fPNrl+wSYapIa1isqSVn1fIiKi9kgldwHBdPDgQbz88ss4dOgQBEEI6rK1Wi20Wm1QlxmImoa1KhsDEhERUajJNoKUmJgIpVKJggLfs7IKCgqQkpLS4GtSUlKanH/Xrl0oLCxE586doVKpoFKpcPr0aSxYsABdu3b1LqPuQeBOpxMlJSWNvm84UEZJ/dg0drYbISIiCjXZApJGo8GwYcOwfft27zS3243t27cjIyOjwddkZGT4zA8AOTk53vnvvfdefPfddzh8+LD3lpqaikcffRRbt271LqOsrAwHDx70LuOLL76A2+1Genp6sFczaHQx0sUi9c4yeQshIiJqB2TdxZadnY3Jkydj+PDhGDFiBFavXo2KigpMnToVAHDfffehU6dOWLZsGQBg7ty5uP7667Fy5Urceuut2LhxIw4cOID169cDABISEpCQkODzHmq1GikpKejduzcAoG/fvhgzZgweeOABrFu3Dg6HA7NmzcLdd9/d4CUBwoU+1tOw1sURJCIiolCTNSBNmDABFy9exKJFi5Cfn48hQ4Zgy5Yt3gOxz5w5A4Xi0iDXyJEjsWHDBjz55JN44okn0KtXL2zevBkDBgwI6H3fe+89zJo1C6NHj4ZCocD48ePxyiuvBHXdgi3a07A2FhbYnC5oVUqZKyIiImq7BJHt4ZvFbDYjJiYG5eXlMJlMIX8/t7kAilVXwi0KuDj/PJJjjSF/TyIiorbG3+9v2VuNkH8URs9p/oKIshJeTZuIiCiUGJAihVINC6RRI2sJ+7ERERGFEgNSBLEqPQ1ryxmQiIiIQokBKYJUq6WA5DBzFxsREVEoMSBFEJtG6sfmtLIfGxERUSgxIEUQl04KSO5KBiQiIqJQYkCKIKJeugimsor92IiIiEKJASmCKIxSQFLbSmWuhIiIqG1jQIogmmipYa3WwXYjREREocSAFEFqGtYa2LCWiIgopBiQIoghVurHZnKb4XazQwwREVGoMCBFkKh4KSDFCRaUVzlkroaIiKjtYkCKIJoo6RgkEypRbKmUuRoiIqK2iwEpkuil6yApBBHmUl5Nm4iIKFQYkCKJUgWLEAUAqCgtlLkYIiKitosBKcJUeBrWVpczIBEREYUKA1KEsaljAQAOC3exERERhQoDUoRxaD0NayvYj42IiChUGJAiTE3DWoENa4mIiEKGASnSGKVT/ZXV7MdGREQUKgxIEUblaVirYcNaIiKikGFAijAakzSCpHOyYS0REVGoMCBFGH1MEgDA6CqHKLIfGxERUSgwIEUYY5zUjy1WNKPS7pK5GiIioraJASnC6Dy72OIFC0oq7DJXQ0RE1DYxIEUYwXMWW4zAhrVEREShomrOi8rKyrB//34UFhbC7Xb7PHffffcFpTBqhC4WbghQQIS19CLQJVHuioiIiNqcgAPSxx9/jEmTJsFqtcJkMkEQBO9zgiAwIIWaUoUKRRSi3RZUlBUA6Ct3RURERG1OwLvYFixYgPvvvx9WqxVlZWUoLS313kpKSkJRI9VRpYoFANjYsJaIiCgkAg5I58+fx5w5c2AwGEJRD/nBpo4BADitDKREREShEHBAysrKwoEDB0JRC/nJ6WlY664okrkSIiKitingY5BuvfVWPProo/jpp58wcOBAqNVqn+fHjh0btOKoYW691G5EqGLDWiIiolAIOCA98MADAICnn3663nOCIMDl4sULQ03w9GNTsWEtERFRSAQckOqe1k+tTx0lndqvdZTJWwgREVEbxQtFRiCNqQMAQM+GtURERCHRrIC0c+dO3H777ejZsyd69uyJsWPHYteuXcGujRphjJUa1prcZtidHNEjIiIKtoAD0rvvvovMzEwYDAbMmTMHc+bMgV6vx+jRo7Fhw4ZQ1Eh1GDwBKQ4WlFayHxsREVGwCaIoioG8oG/fvpg+fTrmz5/vM33VqlX461//iiNHjgS1wHBlNpsRExOD8vJymEym1n3ziz8Da66GWTTg/Ixj6Nuxld+fiIgoQvn7/R3wCNKvv/6K22+/vd70sWPH4uTJk4EujprDIJ3FZhIqUWqpkLkYIiKitifggJSWlobt27fXm75t2zakpaUFpSi6DL3UsBYALKUXZS6GiIio7Qn4NP8FCxZgzpw5OHz4MEaOHAkA2L17N9566y28/PLLQS+QGqBQolIRjSi3GVVlBXJXQ0RE1OYEHJAeeughpKSkYOXKlfj73/8OQDou6YMPPsAdd9wR9AKpYVXqGETZzLBb2G6EiIgo2AIOSABw55134s477wx2LRQAuyYOsJ2F08p2I0RERMHGC0VGKJcuHgAgVjIgERERBZtfI0jx8fH4+eefkZiYiLi4OAiC0Oi8JSUlQSuOGifqpYCkqOLvm4iIKNj8CkgvvfQSoqOjvfebCkjUOpSefmwaGxvWEhERBZtfAWny5Mne+1OmTAlVLRQANqwlIiIKnYCPQTp06BC+//577+N//etfGDduHJ544gnY7Wx70Vp0sVLDWqOrHG53QBdDJyIiossIOCA9+OCD+PnnnwFIV9WeMGECDAYDNm3ahD/+8Y9BL5AaVrsfm7naIXM1REREbUvAAennn3/GkCFDAACbNm3C9ddfjw0bNuCtt97CP//5z2DXR41QR0kjSHGwoLiCI3dERETBFHBAEkURbrcbgNRe5JZbbgEgtSApKuJFC1uNQTqLLU6wooQBiYiIKKgCDkjDhw/Hn//8Z/zv//4vdu7ciVtvvRUAcPLkSSQnJwe9QGpErYa1JWY2rCUiIgqmgAPS6tWrcejQIcyaNQt/+tOf0LNnTwDAP/7xD29vNmoFuhi4PZuvspwNa4mIiIIp4FYjgwYN8jmLrcaKFSugVCqDUhT5QaFEpTIaUa5yVJcXyl0NERFRmxK0ViM6nQ5qtTpYiyM/2NSxAAC7mcd+ERERBRNbjUQwhzYOqD4Nl5UBiYiIKJjYaiSCuXTxQDkgsB8bERFRULHVSAQTjNKp/spqBiQiIqJgCvgYpM8++wxbt26tN/3//u//8PnnnwelKPKP0uhpWGtnw1oiIqJgCjggPf7443C5XPWmu91uPP7440EpivyjNUlX09Y5yiGK7MdGREQULAEHpF9++QX9+vWrN71Pnz44fvx4UIoi/9Q0rI0Rzahy1A+tRERE1DwBB6SYmBj8+uuv9aYfP34cRqMx4ALWrFmDrl27QqfTIT09Hfv3729y/k2bNqFPnz7Q6XQYOHAgPvvsM5/nlyxZgj59+sBoNCIuLg6ZmZnYt2+fzzxdu3aFIAg+t+XLlwdcu9y00Z5+bIIFxVa2GyEiIgqWgAPSHXfcgXnz5uHEiRPeacePH8eCBQswduzYgJb1wQcfIDs7G4sXL8ahQ4cwePBgZGVlobCw4Qsf7tmzBxMnTsS0adPwzTffYNy4cRg3bhx++OEH7zxXXnklXnvtNXz//ff4z3/+g65du+Kmm27CxYu+V5t++umnkZeX573Nnj07oNrDgeA5BikeFvZjIyIiCiJBDPDglfLycowZMwYHDhzAFVdcAQA4d+4crrvuOnz44YeIjY31e1np6em4+uqr8dprrwGQjmNKS0vD7NmzGzyeacKECaioqMAnn3zinXbNNddgyJAhWLduXYPvYTabERMTg23btmH06NEApBGkefPmYd68eX7X2thyy8vLYTKZmr2cFik6Drw2DGZRj4MTv8MNfZLkqYOIiChC+Pv93axdbHv27MGnn36Khx9+GAsWLMD27dvxxRdfBBSO7HY7Dh48iMzMzEvFKBTIzMxEbm5ug6/Jzc31mR8AsrKyGp3fbrdj/fr1iImJweDBg32eW758ORISEnDVVVdhxYoVcDqdTdZrs9lgNpt9brIzSKf5m4QqlFqsMhdDRETUdgTciw0ABEHATTfdhN/+9rfQarXNunBkUVERXC4XkpOTfaYnJyfj6NGjDb4mPz+/wfnz8/N9pn3yySe4++67UVlZiY4dOyInJweJiYne5+fMmYOhQ4ciPj4ee/bswcKFC5GXl4dVq1Y1Wu+yZcuwdOnSQFcztHSxcEMBBdyoLLsIoLvcFREREbUJAY8gud1uPPPMM+jUqROioqJw8uRJAMBTTz2F119/PegFNscNN9yAw4cPY8+ePRgzZgzuuusun+OasrOzMWrUKAwaNAgzZszAypUr8eqrr8JmszW6zIULF6K8vNx7O3v2bGusStMUClSppOFBm/niZWYmIiIifwUckP785z/jrbfewgsvvACNRuOdPmDAAPztb3/zezmJiYlQKpUoKCjwmV5QUICUlJQGX5OSkuLX/EajET179sQ111yD119/HSqVqsnwlp6eDqfTiVOnTjU6j1arhclk8rmFg5qGtU5LsbyFEBERtSEBB6R33nkH69evx6RJk6BUKr3TBw8e3OiusYZoNBoMGzYM27dv905zu93Yvn07MjIyGnxNRkaGz/wAkJOT0+j8tZfb1OjQ4cOHoVAokJQUeQc5O3VxAAB3JRvWEhERBUvAxyCdP38ePXv2rDfd7XbD4XAEtKzs7GxMnjwZw4cPx4gRI7B69WpUVFRg6tSpAID77rsPnTp1wrJlywAAc+fOxfXXX4+VK1fi1ltvxcaNG3HgwAGsX78eAFBRUYFnn30WY8eORceOHVFUVIQ1a9bg/Pnz+MMf/gBAOtB73759uOGGGxAdHY3c3FzMnz8f99xzD+Li4gL9dchO1CcApYBQxREkIiKiYAk4IPXr1w+7du1Cly5dfKb/4x//wFVXXRXQsiZMmICLFy9i0aJFyM/Px5AhQ7BlyxbvgdhnzpyBQnFpkGvkyJHYsGEDnnzySTzxxBPo1asXNm/ejAEDBgAAlEoljh49irfffhtFRUVISEjA1VdfjV27dqF///4ApF1lGzduxJIlS2Cz2dCtWzfMnz8f2dnZgf4qwoJgTAAAqKvZj42IiChYAg5IixYtwuTJk3H+/Hm43W58+OGHOHbsGN555x2f6xP5a9asWZg1a1aDz+3YsaPetD/84Q/e0aC6dDodPvzwwybfb+jQodi7d2/AdYYrdZQUkLSOMnkLISIiakOadSXtjz/+GNu2bYPRaMSiRYtw5MgRfPzxx7jxxhtDUSM1QWuSjpsyuMxwuNwyV0NERNQ2BDSC5HQ68dxzz+H+++9HTk5OqGqiAOhipH5s8bCgtMKOJJNO5oqIiIgiX0AjSCqVCi+88MJlrzpNrUfh6ccWJ1hQzH5sREREQRHwLrbRo0dj586doaiFmsMgHYNUM4JERERELRfwQdo333wzHn/8cXz//fcYNmwYjEajz/Njx44NWnHkB08/tljBisMMSEREREERcEB6+OGHAaDBvmWCIMDlcrW8KvKfJyBFC1UoY8NaIiKioAg4ILndPFMqrGhj4IISSrg8DWuvlLsiIiKiiBfwMUgUZhQKVKtjAAAOCxvWEhERBUOzAtL27dtx2223oUePHujRowduu+02bNu2Ldi1kZ8cmlgAgNPKdiNERETBEHBA+p//+R+MGTMG0dHRmDt3LubOnQuTyYRbbrkFa9asCUWNdBk1DWtFNqwlIiIKioCPQXruuefw0ksv+bQHmTNnDq699lo899xzmDlzZlALJD8YEoBiQFlVInclREREbULAI0hlZWUYM2ZMvek33XQTysvLg1IUBUZR07DWXiZvIURERG1EwAFp7Nix+Oijj+pN/9e//oXbbrstKEVRYDTR0tW0dY4yuN2izNUQERFFvoB3sfXr1w/PPvssduzYgYyMDADA3r17sXv3bixYsACvvPKKd945c+YEr1JqVE0/tlhYYK52INagkbkiIiKiyCaIohjQkEO3bt38W7Ag4Ndff21WUZHAbDYjJiYG5eXlMJlM8hZzeAOw+SHsdA1C2pzP0b1DlLz1EBERhSl/v78DHkE6efJkiwqjEPD0Y4sTLCipsKN7B5nrISIiinC8UGRboJfajcTBimL2YyMiImoxBqS2wNOPrWYEiYiIiFqGAakt8OxiixKqUW6xyFwMERFR5GNAagt0MXBDCQCoLmc/NiIiopZiQGoLBAHVnn5sDgvbjRAREbVUwGex7d+/H7m5ucjPzwcApKSkICMjAyNGjAh6ceQ/hyYWsBfDWcGGtURERC3ld0AqLCzE+PHjsXv3bnTu3BnJyckAgIKCAsyfPx/XXnst/vnPfyIpKSlkxVLj3Pp4wHoCikr2YyMiImopv3exPfzww3C5XDhy5AhOnTqFffv2Yd++fTh16hSOHDkCt9vNRrUyEjwHaiurGZCIiIhayu8RpK1bt+Krr75C79696z3Xu3dvvPLKKxg1alQwa6MAKKOkfmwae6nMlRAREUU+v0eQtFotzGZzo89bLBZotdqgFEWB05qkgBTtNqPS7pS5GiIiosjmd0CaMGECJk+ejI8++sgnKJnNZnz00UeYOnUqJk6cGJIi6fLU0VJA4sUiiYiIWs7vXWyrVq2C2+3G3XffDafTCY1G6hhvt9uhUqkwbdo0vPjiiyErlJomGKSAFA8pIF0RZ5C5IiIiosjld0DSarVYu3Ytnn/+eRw8eNDnNP9hw4bJ39G+vavVsLaII0hEREQtEvB1kEwmE2644YZQ1EIt4e3HZsUvDEhEREQtErQraRcUFODpp58O1uIoUDUBCTwGiYiIqKWCFpDy8/OxdOnSYC2OAuXZxWYUbCi3NH62IREREV2e37vYvvvuuyafP3bsWIuLoRbQmuASlFCKLtjK2Y+NiIioJfwOSEOGDIEgCBBFsd5zNdMFQQhqcRQAQYBdHQu9vRgOK/uxERERtYTfASk+Ph4vvPACRo8e3eDzP/74I26//fagFUaBc+riAXsxxAqOIBEREbWE3wFp2LBhuHDhArp06dLg82VlZQ2OLlHrEfXxgBlQVLEfGxERUUv4HZBmzJiBioqKRp/v3Lkz3nzzzaAURc2jMHoa1toYkIiIiFrC74B05513Nvl8XFwcJk+e3OKCqPlUnnYjBkc5HC431MqgnaRIRETUrvAbtA3RRHcAAMQKVpRW8lpIREREzcWA1IbU7GKLZ8NaIiKiFmFAaktq+rHBghIrAxIREVFzMSC1JYZaI0jcxUZERNRsDEhtiV7qxxYrWLmLjYiIqAX8PoutttLSUrz++us4cuQIAKBv3764//77ER8fH9TiKECehrXxsKCYu9iIiIiaLeARpK+++grdunXDK6+8gtLSUpSWluLVV19Ft27d8NVXX4WiRvKXZxebQbDBwoa1REREzRbwCNLMmTNx1113Ye3atVAqlQAAl8uFhx9+GDNnzsT3338f9CLJT9pouAQVlKITNgvbjRARETVXwCNIx48fx4IFC7zhCACUSiWys7Nx/PjxoBZHARIEODSxAAAXG9YSERE1W8ABaejQod5jj2o7cuQIBg8eHJSiqPlcOs9xYJUMSERERM0V8C62OXPmYO7cuTh+/DiuueYaAMDevXuxZs0aLF++HN9995133kGDBgWvUvKPIQEoBxTV7MdGRETUXAEHpIkTJwIA/vjHPzb4nCAIEEURgiDA5XK1vEIKiCJKOlBbayv1bgciIiIKTMAB6eTJk6Gog4JE42lYaxItMFc5EWNQy1wRERFR5Ak4IHXp0iUUdVCQKI1SQIoTLCiusDEgERERNUOzLhR54sQJrF692nuwdr9+/TB37lz06NEjqMVRM9RqN1LKdiNERETNEvBZbFu3bkW/fv2wf/9+DBo0CIMGDcK+ffvQv39/5OTkhKJGCkSthrW8mjYREVHzBDyC9Pjjj2P+/PlYvnx5vemPPfYYbrzxxqAVR81QawTpe/ZjIyIiapaAR5COHDmCadOm1Zt+//3346effgpKUdQChjgAUsPaYgYkIiKiZgk4IHXo0AGHDx+uN/3w4cNISkoKRk3UEjUjSLCglAGJiIioWfzexfb000/jkUcewQMPPIDp06fj119/xciRIwEAu3fvxvPPP4/s7OyQFUp+8gQkvWBnw1oiIqJm8jsgLV26FDNmzMBTTz2F6OhorFy5EgsXLgQApKamYsmSJZgzZ07ICiU/aaLgUqihdDtgZ8NaIiKiZvE7IImiCAAQBAHz58/H/PnzYbFYAADR0dGhqY4CJwhwauKgrC6Eu4L92IiIiJojoLPY6ratYDAKT259PFBdCIENa4mIiJoloIB05ZVXXra3V0kJm6TKTTAmAKWA0lYqdylEREQRKaCAtHTpUsTExAS1gDVr1mDFihXIz8/H4MGD8eqrr2LEiBGNzr9p0yY89dRTOHXqFHr16oXnn38et9xyi/f5JUuWYOPGjTh79iw0Gg2GDRuGZ599Funp6d55SkpKMHv2bHz88cdQKBQYP348Xn75ZURFRQV13eSijJLajUS5ylFld0GvUcpcERERUWQJKCDdfffdQT2V/4MPPkB2djbWrVuH9PR0rF69GllZWTh27FiD77Nnzx5MnDgRy5Ytw2233YYNGzZg3LhxOHToEAYMGABAGuV67bXX0L17d1RVVeGll17CTTfdhOPHj6NDhw4AgEmTJiEvLw85OTlwOByYOnUqpk+fjg0bNgRt3eSkMnqupu3px3aFxiBzRURERJFFEGuOvr4MpVKJvLy8oAak9PR0XH311XjttdcAAG63G2lpaZg9ezYef/zxevNPmDABFRUV+OSTT7zTrrnmGgwZMgTr1q1r8D3MZjNiYmKwbds2jB49GkeOHEG/fv3w9ddfY/jw4QCALVu24JZbbsG5c+eQmpra4HJsNhtsNpvPctPS0lBeXg6TydTs30FIfPFn4KsVeNt5I4bOeB0DrwjuqB8REVGkqskFl/v+9vtCkX7mKL/Z7XYcPHgQmZmZl4pRKJCZmYnc3NwGX5Obm+szPwBkZWU1Or/dbsf69esRExODwYMHe5cRGxvrDUcAkJmZCYVCgX379jVa77JlyxATE+O9paWl+b2ura5Wu5HiCttlZiYiIqK6/A5Ibrc7qKNHRUVFcLlcSE5O9pmenJyM/Pz8Bl+Tn5/v1/yffPIJoqKioNPp8NJLLyEnJweJiYneZdRdD5VKhfj4+EbfFwAWLlyI8vJy7+3s2bN+r2urq9WwtoRX0yYiIgpYwK1GIsENN9yAw4cPY8+ePRgzZgzuuusuFBYWtmiZWq0WJpPJ5xa2DPEAgDjByoBERETUDLIFpMTERCiVShQUFPhMLygoQEpKSoOvSUlJ8Wt+o9GInj174pprrsHrr78OlUqF119/3buMumHJ6XSipKSk0feNOPqagMQRJCIiouaQLSDVnIK/fft27zS3243t27cjIyOjwddkZGT4zA8AOTk5jc5fe7k1B1hnZGSgrKwMBw8e9D7/xRdfwO12+1wKIKLValhbYuUxSERERIEK6DT/YMvOzsbkyZMxfPhwjBgxAqtXr0ZFRQWmTp0KALjvvvvQqVMnLFu2DAAwd+5cXH/99Vi5ciVuvfVWbNy4EQcOHMD69esBABUVFXj22WcxduxYdOzYEUVFRVizZg3Onz+PP/zhDwCAvn37YsyYMXjggQewbt06OBwOzJo1C3fffXejZ7BFHE9A0gkOWKxsWEtERBQoWQPShAkTcPHiRSxatAj5+fkYMmQItmzZ4j0Q+8yZM1AoLg1yjRw5Ehs2bMCTTz6JJ554Ar169cLmzZu910BSKpU4evQo3n77bRQVFSEhIQFXX301du3ahf79+3uX895772HWrFkYPXq090KRr7zySuuufChpjHApNFC67XBZ2W6EiIgoUH5fB4l8+XsdBbnYn78SmqoCPKhfhb88Nk3ucoiIiMJC0K+DRJFF9JzJJlSxNx4REVGgGJDaKIVRuu6Txl4Kh8stczVERESRhQGpjappWBsvWFBW6ZC5GiIiosjCgNRGKXixSCIiomZjQGqrarUbYT82IiKiwDAgtVW1GtZyBImIiCgwDEhtVa0RpFIGJCIiooAwILVVhjgA0jFIxQxIREREAWFAaqtqRpC4i42IiChgDEhtVa2GtcVsWEtERBQQBqS2yhOQtIIDlWxYS0REFBAGpLZKbYBLqQUAuCrYsJaIiCgQDEhtlSDArZMO1BYrGZCIiIgCwYDUlnl2s6mqSiCKoszFEBERRQ4GpDaspmGtSTTDXO2UuRoiIqLIwYDUhimNNaf6sx8bERFRIBiQ2jJvw1oLStiPjYiIyG8MSG1ZrWshlVQ4ZC6GiIgocjAgtWU+V9PmCBIREZG/GJDastpX0+YxSERERH5jQGrL9Jca1pZYGZCIiIj8xYDUltXexVbJgEREROQvBqS2rCYgwYISNqwlIiLyGwNSW+ZtWOtElbVc5mKIiIgiBwNSW6YxwO1pWOu0lshcDBERUeRgQGrj3HrpYpGKajasJSIi8hcDUhsnGKR+bAZnOaodLpmrISIiigwMSG2cIurSgdq8FhIREZF/GJDaOKH2qf68FhIREZFfGJDaOn2thrW8FhIREZFfGJDaOp+GtbwWEhERkT8YkNq6WrvYirmLjYiIyC8MSG2dwbOLDVaUchcbERGRXxiQ2jpDrWOQeBYbERGRXxiQ2rqaY5C4i42IiMhvDEhtHRvWEhERBYwBqa3znOavEVyormTDWiIiIn8wILV1GgPcKh0AwF3BfmxERET+YEBqB0S9tJtNVV0Kp8stczVEREThjwGpHVAYLx2oXVrpkLkaIiKi8MeA1A4ItQ7U5rWQiIiILo8BqT3wXgvJylP9iYiI/MCA1B7UajfCi0USERFdHgNSe8CGtURERAFhQGoPfEaQeJA2ERHR5TAgtQe1GtZyBImIiOjyGJDaA/2lhrXFPAaJiIjoshiQ2gM2rCUiIgoIA1J7UOs6SF+fKsbJogqZCyIiIgpvDEjtgecYJLXggs5diRe2HJW5ICIiovDGgNQeqPWA2gAASBAs+PyHfBw4VSJzUUREROGLAam98Oxm+0M/KSg999kRiKIoZ0VERERhiwGpvfDsZrtnYBT0aiUOnSnD5z/ky1wUERFReGJAai88I0ixghUP/LY7AOD5LUdhd7rlrIqIiCgsMSC1F55rIaGyGA/+tjsSo7Q4XVyJd/eelrcuIiKiMMSA1F54RpBQWQyjVoXsG68EALzyxS8or2L7ESIiotoYkNqLWgEJAO4afgV6JkWhrNKB//nyuIyFERERhR8GpPbCcGkXGwColAo8cUsfAMCbe07hbEmlXJURERGFHQak9qImIFkunbl2Q+8kZHRPgN3pxov/d0ymwoiIiMIPA1J70XEIICiAc18DZ/YBAARBwJ9u7QsA+NfhC/juXJl89REREYURBqT2IqEHcNU90v2cpwDPRSIHdIrBnVd1AsCLRxIREdWQPSCtWbMGXbt2hU6nQ3p6Ovbv39/k/Js2bUKfPn2g0+kwcOBAfPbZZ97nHA4HHnvsMQwcOBBGoxGpqam47777cOHCBZ9ldO3aFYIg+NyWL18ekvULK6OekFqOnN0HHPnYO3nBTVdCo1Jg768l2H6kUMYCiYiIwoOsAemDDz5AdnY2Fi9ejEOHDmHw4MHIyspCYWHDX9J79uzBxIkTMW3aNHzzzTcYN24cxo0bhx9++AEAUFlZiUOHDuGpp57CoUOH8OGHH+LYsWMYO3ZsvWU9/fTTyMvL895mz54d0nUNC6aOQMYs6f62JYBLOr3/ijgD7r+2GwBg2edH4HTx4pFERNS+CaKM+1TS09Nx9dVX47XXXgMAuN1upKWlYfbs2Xj88cfrzT9hwgRUVFTgk08+8U675pprMGTIEKxbt67B9/j6668xYsQInD59Gp07dwYgjSDNmzcP8+bNa3btZrMZMTExKC8vh8lkavZyWp3NArxyFVBxEbjlRWDEAwAAc7UD17/wJUorHXj2zgGYlN5F5kKJiIiCz9/vb9lGkOx2Ow4ePIjMzMxLxSgUyMzMRG5uboOvyc3N9ZkfALKyshqdHwDKy8shCAJiY2N9pi9fvhwJCQm46qqrsGLFCjidzibrtdlsMJvNPreIpI0GRnnC547lQLW0HiadGnNG9wIAvJTzM6y2pn8fREREbZlsAamoqAgulwvJyck+05OTk5Gf33AT1fz8/IDmr66uxmOPPYaJEyf6pMQ5c+Zg48aN+PLLL/Hggw/iueeewx//+Mcm6122bBliYmK8t7S0NH9WMzwNnQwk9AQqi4DdL3snT0rvgq4JBhRZ7Vi/84SMBRIREclL9oO0Q8XhcOCuu+6CKIpYu3atz3PZ2dkYNWoUBg0ahBkzZmDlypV49dVXYbPZGl3ewoULUV5e7r2dPXs21KsQOko1kLlUup+7BjBLB7FrVAo8Nka6eOT6Xb8iv7xargqJiIhkJVtASkxMhFKpREFBgc/0goICpKSkNPialJQUv+avCUenT59GTk7OZY8RSk9Ph9PpxKlTpxqdR6vVwmQy+dwiWp9bgbRrAGcV8OWz3sljBqRgWJc4VDvcWJXDi0cSEVH7JFtA0mg0GDZsGLZv3+6d5na7sX37dmRkZDT4moyMDJ/5ASAnJ8dn/ppw9Msvv2Dbtm1ISEi4bC2HDx+GQqFAUlJSM9cmAgkCcNOfpfuHNwAFP3omC3jiFunikZsOnsPR/Ag91oqIiKgFZN3Flp2djb/+9a94++23ceTIETz00EOoqKjA1KlTAQD33XcfFi5c6J1/7ty52LJlC1auXImjR49iyZIlOHDgAGbNkk5ddzgc+P3vf48DBw7gvffeg8vlQn5+PvLz82G32wFIB3qvXr0a3377LX799Ve89957mD9/Pu655x7ExcW1/i9BTmlXA/3uAEQ3kLPYO3lYlzjcMjAFoggs++yojAUSERHJQyXnm0+YMAEXL17EokWLkJ+fjyFDhmDLli3eA7HPnDkDheJShhs5ciQ2bNiAJ598Ek888QR69eqFzZs3Y8CAAQCA8+fP49///jcAYMiQIT7v9eWXX2LUqFHQarXYuHEjlixZApvNhm7dumH+/PnIzs5unZUON6MXA0c/BY7nAL/uALqPAgD8MasPcn4qwM6fL2LXLxdxXa8OspZJRETUmmS9DlIki9jrIDXksz8C+/8CpAwCpu8EPKF06cc/4s3dp9AnJRqfzrkOSoUgc6FEREQtE/bXQaIwcv0fAa0JyP8O+H6Td/Kc3/VCtE6Fo/kWfHjonIwFEhERtS4GJAKMicBv5kn3v3gGcEin98cZNZh1Q08AwMr/+xlVdpdMBRIREbUuBiSSXPMwYOoElJ+Vdrd5TB7ZFZ1i9cg3V+ON3SdlLJCIiKj1MCCRRK0HbviTdP+rlUBlCQBAp1bij2N6AwDW7jiBImvjF9MkIiJqKxiQ6JLBdwPJAwBbOfDVi97Jtw9KxcBOMbDanHh52y8yFkhERNQ6GJDoEoUSuNHTgmT/eqD0lDRZcenikRv2n8GJi1aZCiQiImodDEjkq2cm0P0GwO0Atj/tnZzRIwGZfZPgcotY/jkvHklERG0bAxLVd+PTAATgh38C5w96Jz9+cx8oFQJyfirA/pMl8tVHREQUYgxIVF/HQdLxSADwf4sAz7VEeyZFY8LVaQCAZz/9CW43rzFKRERtEwMSNeyGPwFKLXD6P8DPW72T52X2glGjxLfnyvHJ93kyFkhERBQ6DEjUsNg04JqHpPs5iwCXEwCQFK3Dg9f3AAC8sOUobE5ePJKIiNoeBiRq3G/mA/p4oOgYcPhd7+T/vq4bkk1anCutwv/mnpaxQCIiotBgQKLG6WOlPm0A8OVzgE06vd+gUWHBjdLFI1/Z/gvKKu0yFUhERBQaDEjUtOHTgLiugLUAyF3jnTx+2BXokxINc7UTr31xXL76iIiIQoABiZqm0gCjF0v3d78MWAoAAEqFgIWei0e+nXsKZ4or5aqQiIgo6BiQ6PL63wl0GgY4KoAdy7yTr7+yA67rlQiHS8QLW3nxSCIiajsYkOjyBAG46c/S/UPvABePeZ9aeHNfCALwyXd5uPN/duOFLUfxn1+KUGXn2W1ERBS5BFEUebW/ZjCbzYiJiUF5eTlMJpPc5bSO9/8fcOxToPctwMT3vZOf33IUa3ec8JlVo1RgSOdYZHRPwMgeCRjSORZalbK1KyYiIvLh7/c3A1IztcuAdPFn4H+uAUQXMOUzoOu13qfOlVYi90Qxcn8tRu6JYuSVV/u8VKdWYHiXeGT0SEBGjwQM6hQDlZIDmERE1LoYkEKsXQYkAPhkPnDgDemYpP/eLu1+q0MURZwursQeb2AqQpHV91IARo0SI7pJgWlkj0T07WiCUlF/WURERMHEgBRi7TYgWQqAV66SDtj+/ZvAgP+67EtEUcTxQqsUmE4UY+/JYpRVOnzmMelUuKZ7gjcwXZkcBaGB8EVERNQSDEgh1m4DEgDseB7Y8Zx0faSZ+wGVNqCXu90ijuSbpV1yJ4qx72QJrDanzzwJRg2u6ZGAjO4J6J9qQqdYPRKjtFBwlImIiFqAASnE2nVAslmBV4dKF48cs/xSz7Zmcrrc+OGCFJj2nCjCgVOlqHLUPwtOrRTQMUaP1FgdUmP16BSrR6rn1ilWh44xehi1qhbVQkREbRsDUoi164AEAAffAj6eC+jjgDmHpbYkQWJ3uvHtuTJpd9yvxThdXIl8czVc7sv/qcbo1d7AlFonQKXG6pEUreOxTkR+EEURNqcbVpsToggkRmm425vaBAakEGv3AcnlBNaOlBrZXjsPuHFpSN/O6XKj0GLDhbIqnC+rwoWyalwoq6r1uArmaudll6NSCEg26dApVo9OcXqkxRvQNcGALgkGdEkwIsHILwGKbA6XGxU2JyzVTlhtTum+zQlrtXTf6nnOe98zj9Uzf82twuaEw3Xp6yFaq0L3pCj07BCFnklR6NHBiJ5JUegcbwirM1JFUUR5lQPmKic6xuqgDqPaKDwwIIVYuw9IAHBsC/D+BECpBWYfBGLTZC3HUu1AXnm1NzBd8ASpmsf55dVwXmYUyqhRokuC0RuYutQKTx1NOlmOgRJFEeZqJ8oq7bBUOxGlVcGkV8OkU4XVFxOFliiKKKmw+/xNXyirwoXyKpwvq0ZeWRXKqxywOd1Bf29BABr7ptAoFeiaaEBPT3jqkVQToKKgUwf/2md2pxv5dT/nnt9BzeNKz4VqNUoFuncw4srkaPROiUavpCj0TolGWpyBxzM2Q82oYqXdhUq7E1V2F2xON6K0KsQZNTDpVBHxH0wGpBBjQIL0L+ZbtwGn/wMMmgDcsgKwVwIOz81eKZ3tVjPNXtHw9KbmdVQBGiNgSgWiUwFTRyC6I2Dq5LnvmaaNvmy5LreIixab9x/Wc6VVOFNSgVNFlThTUokL5VWNfgkA0j+2afH6S8Ep3oCucSp001chVVUBdXUxUHERqCwC3E5ApZMOYPf+1MOp0MDiUsLiUKLMoUCZXYkyuxLFNgVKbMDFagHFlW6UVjpQWmlHWaUDZVWORncvGjVKmPRqxOjVMOnUUnDSq2DSeaZ5gtSl+2rEGKRpUdrI+McsYlWWAEW/SKOsF48BRT9LP+1WIKEnkNgLSOwNdOgNJF6J6qgrkGe2+4yKXqg1Wnq+rCqg8KNTKxClVSNKq0SUZ3t7bzoVjFoVorXSzyitCtG6hu8bNSo43G6cLq7E8UKr93bionSrdjRckyAAV8Tp0aPDpVGnmlusQdPga0RRRGmlo8HfQc3ji1Zbk5/TGhqVAvZGfl96tRI9k6JwZXI0rkyOwpUp0eidHI2OMbqI/0y43KI3vFR6blUO56X7dheqHDX3fadXOupPqz1vlcOFpv6PqVQIiNWrEWtQI86gQaxBgziDGnFGjXdanEGNWIMG8Z5psXoNNKrW/Y8eA1KIMSB5nD8I/PV3clcBaE2e4OQJTzX3o1OlcGVKBQyJgKLxD2K1w4VzxRbk5Z1HUcF5mIvzUFmaD6e5EMqqIsSKZiQInhvKkSCYYRKqgr4qLlGADRpUQw0bNLCJatighkPQwKnQoMqtRoVbBVut56uh8TxWe+e31UwTpZ/eeTzP2wU11FojNDoDtDo9NCo1lIIbCrghwA2FKN1v6LHiMs8LoggFXJ7HgNFoQFx0NOJM0YiPNaFDXAyS42IQY4qCoNJLATISv5hEETBf8ISgnyFePAbRE4YUlRcDWlS1qMavYiqOi6k47u4k/RQ74ZSYAjvUAKRfUVK0ttaxdXqkxlw63i7WoEa0Vg2jVtkqo4tut4jzZVU4ftGKE7XC0/GL1nqX8qgtMUqDHp7RJpdL9IwASQGoscBVm1alqHWShmf9Y3ToFKNFaowGHaPV0ChEXCix4NeCMpwqKMPpi+U4c7EMF0osgMsONVxQwwmVIP1Uw4loNZAWo0JajAodo1RIjVYhySggSiVCcDukQwvcDmm7CwpAoQQEpfTviqDw3FfWul93uhKiIMAhKmB3ATY3pJ8uATYXUO0CHA4HbA4nHA4H7J6fDpdL+ul0wlnr5nJ5fjpdcLqln3C7IMANJdzez7MCIuyiGqWIQpkYhVJEo1S8dL8SWgCBff40KgUMGiU0SgWsNqd31K45orSqWqHKN0hNuqYzkqJ1zV52QxiQQowBqZZ/zwEOvS3dFxSA2gio9YDGIN3XGAC1QRoJUhvqT29oWs28aj1gMwPmPMByQfoy8t7Pkx7bLf7VqVAD0Sme0aiO0gHmVaVARZE06lNxUfpfPwL7SDhEJYphQrHoucEEh6iCVnBACwd0sEMLB7SC5yccMCgc0Hme14h2qNH4l0l74RA0cCm1EJVaCCodFBo9VFo9FHVH4tT6S4/Veikca6KkUURtNKCNamBatPQFBWmUosrh8h6nYq52oLzSAXO1A+YqB8o906od0u4Dm9MNh90OU/U5dKg+hWT7GaQ6zuAK51mkuc/BiMZD8nkxASfcUtA5LnbCCXcqLNCju5CHnorz6ClcQA/hPLoL+dAKDf8NiFCgOjoNYmJvaFP6QJnUxzvqBF0I/+0RRcDlAJzVtW62Sz8dVbUe1zwnTRMd1aiqqkCZ2QKzxYqKCiuqqiphq66E21EtfSY8f/9q1PpC9wRstQJQK0RoFCKUggiVIEIFNxSC6AngbghuFyC6pSv7u10I9HNLlzgFDarVMbBrYuHQxMKli4NLFwfo4wFDHBTGRKiMCVBHJ0BjSoQuugNUxnif/3BWez5TpZV2lFhtMFsrYLZaUGG1oqKiAhWVFaiurEBVdSUcVZWw2yrhsFdBIzqgFWr9O1nr30od7Pjtg6vQLa1zUNeXASnEGJDqqC6XjkWSYyTAZqkToC4AljxPgDov3bcWwv9/QAXAEA8YO0g3Q8Kl+8bEWvc7AMYEiNoYXLTacbqkEqeLK3G6uAIut+gZQr70P6E4z/+MTHp1/TPp3G7AZfd+wfh8GTnqfgHVna+hLyxbvS+t2tNFh3SDqxoKZ3XDvwYAbkH637AoKCFCAdFzX5rW0GPlpWkQPK8T4HbaITql91K47VCLdmhFOxRC6/3zUwUtrNDDKupgEfWwinpUQA8L9KgQdbBCD4tnWjU06CRcRE/hAnoK59FVyIdGaPh/yE5RgdNisicE1Yz+dMJJpMKtNkKrUkCnVkKrUkCrUsKoVda7TEWqSY00oRDRll8hFP18aXdc0c/SfxAaE91RCko1gUmlbSK8NP730OjfT1sJHQo1oNQASpX0U6Guc18Nt0KNarcSFU4BVqcAsx0otwkot4uwQwWnqIITSjgg/U0ragU6BUTpvlDrPnzvKz2Pa99XCW6oFCLUghsqAVAKIgSFNOJ06ad0X1CqoFAooVAqpZ8KFRRKJZRKJRRKFZRKJZQqFVRKJZRKFZRKlXcZUCil7VtVAlSWen6WSD9d9sv//hokSGcv62KlkOq0Xfq3ymUL2qazTt+LqNS+QVsewIAUcgxIEcblkK7bVDs0VZVK/0Pyhh7PT3289I9ne1EzUuB21tploAx50K22O5FfakFBcRkKSstRVGpBcXk5ysxmlFossFisEFy2WiNwdUfkHNDDhihUIUqoQhSqYBSqEY0qGGtN0wqXP7vRH06lHtbobqgy9UR1bE8443vBFd8TSOgOrVbvCUCXwlBQdnGJImDJl4KSNzRJu/NgzW/58gPhM5Kn832s1jV4zJ3v/HVG/2p+KlR1dkvV3UWl9N2dJSganu59Xa1pSrW0/Bb8LVfZXThx0YqfCyw4VmDBz/kW2JxuGDRK6DUqGNRK6DXSrea+QaPyPK+UfjY0Xd06u0GbJIrS8Z6VxbVCU+ml8FT7p3eeUv9H7QEAQq3t3sD2b/Bvp9bf2IjpQFSHoK42A1KIMSARhdblDtg9X1aFarvLc2C6GjGeg9N9D1pXIU4jIk5lQ6zShhiFDVFCJaJQDa27AoLNIh00bbNIF0C1maX7jkppdKZDb8+B1FcCpiuaPIat1VWV+R4EXnxC+p98Y19E9QJKE4Gn7peXUhOZx4hRaDjtUpCqKpH2HijUjf+dtTCghgIDUogxIBEREUUef7+/w+i/Q0REREThgQGJiIiIqA4GJCIiIqI6GJCIiIiI6mBAIiIiIqqDAYmIiIioDgYkIiIiojoYkIiIiIjqYEAiIiIiqoMBiYiIiKgOBiQiIiKiOhiQiIiIiOpgQCIiIiKqgwGJiIiIqA6V3AVEKlEUAQBms1nmSoiIiMhfNd/bNd/jjWFAaiaLxQIASEtLk7kSIiIiCpTFYkFMTEyjzwvi5SIUNcjtduPChQuIjo6GIAhBW67ZbEZaWhrOnj0Lk8kUtOWGk7a+jly/yNfW15HrF/na+jqGcv1EUYTFYkFqaioUisaPNOIIUjMpFApcccUVIVu+yWRqk3/0tbX1deT6Rb62vo5cv8jX1tcxVOvX1MhRDR6kTURERFQHAxIRERFRHQxIYUar1WLx4sXQarVylxIybX0duX6Rr62vI9cv8rX1dQyH9eNB2kRERER1cASJiIiIqA4GJCIiIqI6GJCIiIiI6mBAIiIiIqqDAUkGa9asQdeuXaHT6ZCeno79+/c3Of+mTZvQp08f6HQ6DBw4EJ999lkrVRq4ZcuW4eqrr0Z0dDSSkpIwbtw4HDt2rMnXvPXWWxAEweem0+laqeLALFmypF6tffr0afI1kbT9unbtWm/9BEHAzJkzG5w/ErbdV199hdtvvx2pqakQBAGbN2/2eV4URSxatAgdO3aEXq9HZmYmfvnll8suN9DPcag0tX4OhwOPPfYYBg4cCKPRiNTUVNx33324cOFCk8tszt95KF1uG06ZMqVevWPGjLnsciNhGwJo8DMpCAJWrFjR6DLDaRv6871QXV2NmTNnIiEhAVFRURg/fjwKCgqaXG5zP7v+YkBqZR988AGys7OxePFiHDp0CIMHD0ZWVhYKCwsbnH/Pnj2YOHEipk2bhm+++Qbjxo3DuHHj8MMPP7Ry5f7ZuXMnZs6cib179yInJwcOhwM33XQTKioqmnydyWRCXl6e93b69OlWqjhw/fv396n1P//5T6PzRtr2+/rrr33WLScnBwDwhz/8odHXhPu2q6iowODBg7FmzZoGn3/hhRfwyiuvYN26ddi3bx+MRiOysrJQXV3d6DID/RyHUlPrV1lZiUOHDuGpp57CoUOH8OGHH+LYsWMYO3bsZZcbyN95qF1uGwLAmDFjfOp9//33m1xmpGxDAD7rlZeXhzfeeAOCIGD8+PFNLjdctqE/3wvz58/Hxx9/jE2bNmHnzp24cOEC/uu//qvJ5TbnsxsQkVrViBEjxJkzZ3ofu1wuMTU1VVy2bFmD8991113irbfe6jMtPT1dfPDBB0NaZ7AUFhaKAMSdO3c2Os+bb74pxsTEtF5RLbB48WJx8ODBfs8f6dtv7ty5Yo8ePUS3293g85G07URRFAGIH330kfex2+0WU1JSxBUrVninlZWViVqtVnz//fcbXU6gn+PWUnf9GrJ//34RgHj69OlG5wn077w1NbSOkydPFu+4446AlhPJ2/COO+4Qf/e73zU5Tzhvw7rfC2VlZaJarRY3bdrknefIkSMiADE3N7fBZTT3sxsIjiC1IrvdjoMHDyIzM9M7TaFQIDMzE7m5uQ2+Jjc312d+AMjKymp0/nBTXl4OAIiPj29yPqvVii5duiAtLQ133HEHfvzxx9Yor1l++eUXpKamonv37pg0aRLOnDnT6LyRvP3sdjveffdd3H///U02ZI6kbVfXyZMnkZ+f77ONYmJikJ6e3ug2as7nOJyUl5dDEATExsY2OV8gf+fhYMeOHUhKSkLv3r3x0EMPobi4uNF5I3kbFhQU4NNPP8W0adMuO2+4bsO63wsHDx6Ew+Hw2R59+vRB586dG90ezfnsBooBqRUVFRXB5XIhOTnZZ3pycjLy8/MbfE1+fn5A84cTt9uNefPm4dprr8WAAQMana93795444038K9//Qvvvvsu3G43Ro4ciXPnzrVitf5JT0/HW2+9hS1btmDt2rU4efIkrrvuOlgslgbnj+Ttt3nzZpSVlWHKlCmNzhNJ264hNdshkG3UnM9xuKiursZjjz2GiRMnNtkANNC/c7mNGTMG77zzDrZv347nn38eO3fuxM033wyXy9Xg/JG8Dd9++21ER0dfdvdTuG7Dhr4X8vPzodFo6oX2y3031szj72sCpQrKUogaMHPmTPzwww+X3e+dkZGBjIwM7+ORI0eib9+++Mtf/oJnnnkm1GUG5Oabb/beHzRoENLT09GlSxf8/e9/9+t/dJHk9ddfx80334zU1NRG54mkbdfeORwO3HXXXRBFEWvXrm1y3kj7O7/77ru99wcOHIhBgwahR48e2LFjB0aPHi1jZcH3xhtvYNKkSZc9GSJct6G/3wvhgCNIrSgxMRFKpbLekfkFBQVISUlp8DUpKSkBzR8uZs2ahU8++QRffvklrrjiioBeq1arcdVVV+H48eMhqi54YmNjceWVVzZaa6Ruv9OnT2Pbtm347//+74BeF0nbDoB3OwSyjZrzOZZbTTg6ffo0cnJymhw9asjl/s7DTffu3ZGYmNhovZG4DQFg165dOHbsWMCfSyA8tmFj3wspKSmw2+0oKyvzmf9y34018/j7mkAxILUijUaDYcOGYfv27d5pbrcb27dv9/lfeG0ZGRk+8wNATk5Oo/PLTRRFzJo1Cx999BG++OILdOvWLeBluFwufP/99+jYsWMIKgwuq9WKEydONFprpG2/Gm+++SaSkpJw6623BvS6SNp2ANCtWzekpKT4bCOz2Yx9+/Y1uo2a8zmWU004+uWXX7Bt2zYkJCQEvIzL/Z2Hm3PnzqG4uLjReiNtG9Z4/fXXMWzYMAwePDjg18q5DS/3vTBs2DCo1Wqf7XHs2DGcOXOm0e3RnM9ucwqnVrRx40ZRq9WKb731lvjTTz+J06dPF2NjY8X8/HxRFEXx3nvvFR9//HHv/Lt37xZVKpX44osvikeOHBEXL14sqtVq8fvvv5drFZr00EMPiTExMeKOHTvEvLw8762ystI7T911XLp0qbh161bxxIkT4sGDB8W7775b1Ol04o8//ijHKjRpwYIF4o4dO8STJ0+Ku3fvFjMzM8XExESxsLBQFMXI336iKJ3N07lzZ/Gxxx6r91wkbjuLxSJ+88034jfffCMCEFetWiV+88033rO4li9fLsbGxor/+te/xO+++0684447xG7duolVVVXeZfzud78TX331Ve/jy32Ow2X97Ha7OHbsWPGKK64QDx8+7POZtNlsja7f5f7OW1tT62ixWMRHHnlEzM3NFU+ePClu27ZNHDp0qNirVy+xurrau4xI3YY1ysvLRYPBIK5du7bBZYTzNvTne2HGjBli586dxS+++EI8cOCAmJGRIWZkZPgsp3fv3uKHH37ofezPZ7clGJBk8Oqrr4qdO3cWNRqNOGLECHHv3r3e566//npx8uTJPvP//e9/F6+88kpRo9GI/fv3Fz/99NNWrth/ABq8vfnmm9556q7jvHnzvL+P5ORk8ZZbbhEPHTrU+sX7YcKECWLHjh1FjUYjdurUSZwwYYJ4/Phx7/ORvv1EURS3bt0qAhCPHTtW77lI3HZffvllg3+TNevhdrvFp556SkxOTha1Wq04evToeuvepUsXcfHixT7Tmvoct6am1u/kyZONfia//PJL7zLqrt/l/s5bW1PrWFlZKd50001ihw4dRLVaLXbp0kV84IEH6gWdSN2GNf7yl7+Ier1eLCsra3AZ4bwN/fleqKqqEh9++GExLi5ONBgM4p133inm5eXVW07t1/jz2W0JwfOmREREROTBY5CIiIiI6mBAIiIiIqqDAYmIiIioDgYkIiIiojoYkIiIiIjqYEAiIiIiqoMBiYiIiKgOBiQiIiKiOhiQiIiaSRAEbN68We4yiCgEGJCIKCJNmTIFgiDUu40ZM0bu0oioDVDJXQARUXONGTMGb775ps80rVYrUzVE1JZwBImIIpZWq0VKSorPLS4uDoC0+2vt2rW4+eabodfr0b17d/zjH//wef3333+P3/3ud9Dr9UhISMD06dNhtVp95nnjjTfQv39/aLVadOzYEbNmzfJ5vqioCHfeeScMBgN69eqFf//7397nSktLMWnSJHTo0AF6vR69evWqF+iIKDwxIBFRm/XUU09h/Pjx+PbbbzFp0iTcfffdOHLkCACgoqICWVlZiIuLw9dff41NmzZh27ZtPgFo7dq1mDlzJqZPn47vv/8e//73v9GzZ0+f91i6dCnuuusufPfdd7jlllswadIklJSUeN//p59+wueff44jR45g7dq1SExMbL1fABE1n0hEFIEmT54sKpVK0Wg0+tyeffZZURRFEYA4Y8YMn9ekp6eLDz30kCiKorh+/XoxLi5OtFqt3uc//fRTUaFQiPn5+aIoimJqaqr4pz/9qdEaAIhPPvmk97HVahUBiJ9//rkoiqJ4++23i1OnTg3OChNRq+IxSEQUsW644QasXbvWZ1p8fLz3fkZGhs9zGRkZOHz4MADgyJEjGDx4MIxGo/f5a6+9Fm63G8eOHYMgCLhw4QJGjx7dZA2DBg3y3jcajTCZTCgsLAQAPPTQQxg/fjwOHTqEm266CePGjcPIkSObta5E1LoYkIgoYhmNxnq7vIJFr9f7NZ9arfZ5LAgC3G43AODmm2/G6dOn8dlnnyEnJwejR4/GzJkz8eKLLwa9XiIKLh6DRERt1t69e+s97tu3LwCgb9+++Pbbb1FRUeF9fvfu3VAoFOjduzeio6PRtWtXbN++vUU1dOjQAZMnT8a7776L1atXY/369S1aHhG1Do4gEVHEstlsyM/P95mmUqm8B0Jv2rQJw4cPx29+8xu899572L9/P15//XUAwKRJk7B48WJMnjwZS5YswcWLFzF79mzce++9SE5OBgAsWbIEM2bMQFJSEm6++WZYLBbs3r0bs2fP9qu+RYsWYdiwYejfvz9sNhs++eQTb0AjovDGgEREEWvLli3o2LGjz7TevXvj6NGjAKQzzDZu3IiHH34YHTt2xPvvv49+/foBAAwGA7Zu3Yq5c+fi6quvhsFgwPjx47Fq1SrvsiZPnozq6mq89NJLeOSRR5CYmIjf//73ften0WiwcOFCnDp1Cnq9Htdddx02btwYhDUnolATRFEU5S6CiCjYBEHARx99hHHjxsldChFFIB6DRERERFQHAxIRERFRHTwGiYjaJB49QEQtwREkIiIiojoYkIiIiIjqYEAiIiIiqoMBiYiIiKgOBiQiIiKiOhiQiIiIiOpgQCIiIiKqgwGJiIiIqI7/D9SKvwXqMKySAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot top K recall over epochs\n"
      ],
      "metadata": {
        "id": "LRyN5RWZAtJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(epochs_tracked, [recall for _, recall in train_topks],\n",
        "         label=\"Train\")\n",
        "plt.plot(epochs_tracked, [recall for _, recall in val_topks],\n",
        "         label=\"Val\")\n",
        "plt.ylabel(f\"Top {K} recall\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "ryhaVfnL9cf3",
        "outputId": "4c5ad0b6-a0f0-4640-8edb-ee995319d775"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAloAAAG1CAYAAAAhoVogAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAZeVJREFUeJzt3Xl8U1XeP/DPTdos3dKWQtNiKZVdZHGqra04yFCnKCPURwUZB5DpCCo6IDoqPkLdnqkCjjwwDMso4PxUtgHBUQenVtB5oBRlkZ2hyN6mBdombbqkTc7vjzQhoWmblKTp8nm/vK8k957cfNO05sO5954jCSEEiIiIiMjrZP4ugIiIiKizYtAiIiIi8hEGLSIiIiIfYdAiIiIi8hEGLSIiIiIfYdAiIiIi8hEGLSIiIiIfYdAiIiIi8hEGLSIiIiIfYdAiIiIi8pF2EbSWLVuG3r17Q6VSITk5GXv37m22/aZNmzBw4ECoVCoMGTIEX375pdN2IQTmz5+PmJgYqNVqpKWl4dSpU05txo0bh169ekGlUiEmJgaTJ09GYWGhffvZs2chSVKjZc+ePR7VQkRERF2X34PWhg0bMGfOHGRlZWH//v0YNmwY0tPTUVJS4rL97t27MWnSJGRmZuLAgQPIyMhARkYGjhw5Ym+zYMECLFmyBCtWrEB+fj6Cg4ORnp6Ompoae5tRo0Zh48aNOHnyJDZv3ozTp0/j4YcfbvR6X3/9NYqKiuxLYmKiR7UQERFR1yX5e1Lp5ORk3HHHHfjzn/8MALBYLIiLi8Ozzz6Ll19+uVH7iRMnwmg04vPPP7evu/POOzF8+HCsWLECQgjExsbi+eefxwsvvAAA0Ov1iI6Oxtq1a/Hoo4+6rOOzzz5DRkYGamtrERgYiLNnzyIhIQEHDhzA8OHDXT6npVpaYrFYUFhYiNDQUEiS1GJ7IiIi8j8hBCoqKhAbGwuZrPk+q4A2qsklk8mEffv2Ye7cufZ1MpkMaWlpyMvLc/mcvLw8zJkzx2ldeno6tm7dCgA4c+YMdDod0tLS7Ns1Gg2Sk5ORl5fnMmiVlpbi448/RmpqKgIDA522jRs3DjU1Nejfvz9efPFFjBs3zu1arldbW4va2lr740uXLuGWW25x2ZaIiIjatwsXLuCmm25qto1fg9aVK1dgNpsRHR3ttD46OhonTpxw+RydTueyvU6ns2+3rWuqjc1LL72EP//5z6iqqsKdd97p1DMVEhKCd999F3fddRdkMhk2b96MjIwMbN261R62WqrletnZ2Xj99dcbrb9w4QLCwsJcPoeIiIjaF4PBgLi4OISGhrbY1q9By9/+8Ic/IDMzE+fOncPrr7+OKVOm4PPPP4ckSYiKinLqrbrjjjtQWFiIhQsXOvVqeWLu3LlO+7R9UGFhYQxaREREHYw7p/34NWhFRUVBLpejuLjYaX1xcTG0Wq3L52i12mbb226Li4sRExPj1Ob6c62ioqIQFRWF/v37Y9CgQYiLi8OePXuQkpLi8rWTk5ORk5Pjdi3XUyqVUCqVLrcRERFR5+PXqw4VCgUSExORm5trX2exWJCbm9tk2ElJSXFqDwA5OTn29gkJCdBqtU5tDAYD8vPzm9yn7XUBOJ1Ddb2DBw86hbeWaiEiIqKuze+HDufMmYOpU6fi9ttvR1JSEhYvXgyj0Yhp06YBAKZMmYKePXsiOzsbADBr1iyMHDkS7777LsaOHYv169fjhx9+wKpVqwBYu/Fmz56Nt956C/369UNCQgLmzZuH2NhYZGRkAADy8/Px/fffY8SIEYiIiMDp06cxb9489OnTxx6SPvzwQygUCtx2220AgC1btmD16tV4//337bW3VAsRERF1bX4PWhMnTsTly5cxf/586HQ6DB8+HNu3b7efZH7+/HmnSydTU1PxySef4NVXX8Urr7yCfv36YevWrbj11lvtbV588UUYjUZMnz4d5eXlGDFiBLZv3w6VSgUACAoKwpYtW5CVlQWj0YiYmBiMGTMGr776qtOhvTfffBPnzp1DQEAABg4ciA0bNjiNteVOLURERP5gNptRV1fn7zI6LIVC0eLQDe7w+zhaXZnBYIBGo4Fer+fJ8ERE5BVCCOh0OpSXl/u7lA5NJpMhISEBCoWi0TZPvr/93qNFRERE3mMLWT169EBQUBAHxG4F24DiRUVF6NWr1w39DBm0iIiIOgmz2WwPWd26dfN3OR1a9+7dUVhYiPr6+kaDmXvC73MdEhERkXfYzskKCgrycyUdn+2QodlsvqH9MGgRERF1MjxceOO89TNk0CIiIiLyEQYtIiIi6nR69+6NxYsX+7sMBi0iIiLyH0mSml1ee+21Vu33+++/x/Tp071bbCvwqsNOqN5swVWjCTV1ZsR3C/Z3OURERE0qKiqy39+wYQPmz5+PkydP2teFhITY7wshYDabERDQcnzp3r27dwttJfZodUJ7z5Qi+Y+5yPzwB3+XQkRE1CytVmtfNBoNJEmyPz5x4gRCQ0Pxz3/+E4mJiVAqlfi///s/nD59GuPHj0d0dDRCQkJwxx134Ouvv3ba7/WHDiVJwvvvv48HH3wQQUFB6NevHz777DOfvz8GrU4oIth6SWqZ0eTnSoiIyJ+EEKgy1ftl8ebEMy+//DLefvttHD9+HEOHDkVlZSXuv/9+5Obm4sCBAxgzZgweeOABnD9/vtn9vP7665gwYQIOHTqE+++/H4899hhKS0u9VqcrPHTYCUXaglaVCRaLgEzGy3yJiLqi6jozbpn/lV9e+9gb6QhSeCdmvPHGG7j33nvtjyMjIzFs2DD74zfffBOffvopPvvsMzzzzDNN7ufxxx/HpEmTAAB//OMfsWTJEuzduxdjxozxSp2usEerEwoPso5gaxGAoYYTihIRUcd2++23Oz2urKzECy+8gEGDBiE8PBwhISE4fvx4iz1aQ4cOtd8PDg5GWFgYSkpKfFKzDXu0OiFlgBwhygBU1taj1GhCeFDjCTGJiKjzUwfKceyNdL+9trcEBztf2PXCCy8gJycHixYtQt++faFWq/Hwww/DZGr+lJnrp9KRJAkWi8VrdbrCoNVJRQYrUFlbj7IqnqdFRNRVSZLktcN37cmuXbvw+OOP48EHHwRg7eE6e/asf4tqAg8ddlK2E+JLjTx0SEREnUu/fv2wZcsWHDx4ED/++CN+/etf+7xnqrUYtDqpyIbztHjlIRERdTZ/+tOfEBERgdTUVDzwwANIT0/Hz372M3+X5VLn608kAA49Wjx0SEREHcTjjz+Oxx9/3P74nnvucTlMRO/evfHNN984rZs5c6bT4+sPJbraT3l5eatrdReDVmdkKEJa5eeQy/UoM97s72qIiIi6LB467IzKzuL+8wvxtHwbSnnokIiIyG8YtDqjoG4AgEipglcdEhER+RGDVmcUFAkA0EhVKK+s9nMxREREXReDVmekCoeAddods9G3czgRERFR0xi0OiN5ACxKDQBAVF31czFERERdF4NWZ9Vw+FBRW4Y6c/scxI2IiKizY9DqpGTB1hPiI6RKlFdxdHgiIiJ/YNDqpKSgKABABK88JCIi8hsGrc6q4dBhJCo4lhYREXVq99xzD2bPnu3vMlxi0OqsGoJWhFTB+Q6JiKjdeuCBBzBmzBiX2/79739DkiQcOnSojavyHgatziro2jlanO+QiIjaq8zMTOTk5ODixYuNtq1Zswa33347hg4d6ofKvINBq7NSN/RogT1aRETUfv3qV79C9+7dsXbtWqf1lZWV2LRpEzIyMjBp0iT07NkTQUFBGDJkCNatW+efYluBQauzcpiGp9TIqw6JiLokIQCT0T+LEG6VGBAQgClTpmDt2rUQDs/ZtGkTzGYzfvOb3yAxMRFffPEFjhw5gunTp2Py5MnYu3evr35qXhXg7wLIRxqCVjh41SERUZdVVwX8MdY/r/1KIaAIdqvpb3/7WyxcuBDffvst7rnnHgDWw4YPPfQQ4uPj8cILL9jbPvvss/jqq6+wceNGJCUl+aJyr2KPVmdlu+pQ4lWHRETUvg0cOBCpqalYvXo1AKCgoAD//ve/kZmZCbPZjDfffBNDhgxBZGQkQkJC8NVXX+H8+fN+rto97NHqrBp6tDRSFfRGTixNRNQlBQZZe5b89doeyMzMxLPPPotly5ZhzZo16NOnD0aOHIl33nkH//u//4vFixdjyJAhCA4OxuzZs2EydYxOBAatzqphYmkJAvVGzndIRNQlSZLbh+/8bcKECZg1axY++eQT/O1vf8NTTz0FSZKwa9cujB8/Hr/5zW8AABaLBf/5z39wyy23+Lli97SLQ4fLli1D7969oVKpkJyc3OIJbps2bcLAgQOhUqkwZMgQfPnll07bhRCYP38+YmJioFarkZaWhlOnTjm1GTduHHr16gWVSoWYmBhMnjwZhYXXUv/OnTsxfvx4xMTEIDg4GMOHD8fHH3/stI+1a9dCkiSnRaVS3eBPw0vkAbAowwEAsqpS/9ZCRETUgpCQEEycOBFz585FUVERHn/8cQBAv379kJOTg927d+P48eOYMWMGiouL/VusB/wetDZs2IA5c+YgKysL+/fvx7Bhw5Ceno6SkhKX7Xfv3o1JkyYhMzMTBw4cQEZGBjIyMnDkyBF7mwULFmDJkiVYsWIF8vPzERwcjPT0dNTU1NjbjBo1Chs3bsTJkyexefNmnD59Gg8//LDT6wwdOhSbN2/GoUOHMG3aNEyZMgWff/65Uz1hYWEoKiqyL+fOnfPyT+gGBEUAAFR15aipM/u5GCIiouZlZmairKwM6enpiI21nsT/6quv4mc/+xnS09Nxzz33QKvVIiMjw7+FekL4WVJSkpg5c6b9sdlsFrGxsSI7O9tl+wkTJoixY8c6rUtOThYzZswQQghhsViEVqsVCxcutG8vLy8XSqVSrFu3rsk6tm3bJiRJEiaTqck2999/v5g2bZr98Zo1a4RGo2n2/TVHr9cLAEKv17d6H82x/DVNiKwwMX1uligsr/LJaxARUftRXV0tjh07Jqqrq/1dSofX3M/Sk+9vv/ZomUwm7Nu3D2lpafZ1MpkMaWlpyMvLc/mcvLw8p/YAkJ6ebm9/5swZ6HQ6pzYajQbJyclN7rO0tBQff/wxUlNTERgY2GS9er0ekZGRTusqKysRHx+PuLg4jB8/HkePHm3y+bW1tTAYDE6LL0n20eF55SEREZE/+DVoXblyBWazGdHR0U7ro6OjodPpXD5Hp9M12952684+X3rpJQQHB6Nbt244f/48tm3b1mStGzduxPfff49p06bZ1w0YMACrV6/Gtm3b8NFHH8FisSA1NdXlNAIAkJ2dDY1GY1/i4uKafD2vcJhYuoyDlhIREbU5v5+j5U9/+MMfcODAAfzrX/+CXC7HlClTnEaltdmxYwemTZuGv/71rxg8eLB9fUpKCqZMmYLhw4dj5MiR2LJlC7p3746VK1e6fL25c+dCr9fblwsXLvjsvQGwB61wzndIRETkF34d3iEqKgpyubzR1QPFxcXQarUun6PVapttb7stLi5GTEyMU5vhw4c3ev2oqCj0798fgwYNQlxcHPbs2YOUlBR7m2+//RYPPPAA3nvvPUyZMqXZ9xMYGIjbbrsNBQUFLrcrlUoolcpm9+FVDtPwcL5DIiKitufXHi2FQoHExETk5uba11ksFuTm5jqFHUcpKSlO7QEgJyfH3j4hIQFardapjcFgQH5+fpP7tL0uYD2Pymbnzp0YO3Ys3nnnHUyfPr3F92M2m3H48GGngOdXDhNL8xwtIqKuw9XRGfKMt36Gfh+wdM6cOZg6dSpuv/12JCUlYfHixTAajfZzoaZMmYKePXsiOzsbADBr1iyMHDkS7777LsaOHYv169fjhx9+wKpVqwAAkiRh9uzZeOutt9CvXz8kJCRg3rx5iI2NtV8Omp+fj++//x4jRoxAREQETp8+jXnz5qFPnz72MLZjxw786le/wqxZs/DQQw/Zz+9SKBT2E+LfeOMN3Hnnnejbty/Ky8uxcOFCnDt3Dr/73e/a8kfYNIeT4TnfIRFR52e7oKuqqgpqtdrP1XRstpHn5XL5De3H70Fr4sSJuHz5MubPnw+dTofhw4dj+/bt9pPZz58/D5nsWsdbamoqPvnkE7z66qt45ZVX0K9fP2zduhW33nqrvc2LL74Io9GI6dOno7y8HCNGjMD27dvtg4kGBQVhy5YtyMrKgtFoRExMDMaMGYNXX33Vfmjvww8/RFVVFbKzs+0hDwBGjhyJnTt3AgDKysrwxBNPQKfTISIiAomJidi9e3f7Ga3WFrTYo0VE1CXI5XKEh4fbx6IMCgqCJEl+rqrjsVgsuHz5MoKCghAQcGNRSRLsX/Qbg8EAjUYDvV6PsLAw77/A5ZPAsiToRRCejvsUH//uTu+/BhERtStCCOh0OpSXl/u7lA5NJpMhISEBCoWi0TZPvr/93qNFPuQwsXR5ZU0LjYmIqDOQJAkxMTHo0aMH6uo4tE9rKRQKpyNqrcWg1Zk5TCxt4cTSRERdilwuv+Hzi+jGdelxtDo9eQCEUmO9X13Kq1CIiIjaGINWZxdsPXwYYjagysSJpYmIiNoSg1YnJzkMWsorD4mIiNoWg1YnJzVMw8OJpYmIiNoeg1ZnZx9Li/MdEhERtTUGrc7OoUeL8x0SERG1LQatzq5hvkOeo0VERNT2GLQ6O4dpeDjfIRERUdti0OrsHCaWLjVyhGAiIqK2xKDV2dnO0QLP0SIiImprDFqdneM4Wjx0SERE1KYYtDo7h4ml9ZXVfi6GiIioa2HQ6uwaJpYGAEtVqZ+LISIi6loYtDo7h4mlZdWlsFg4sTQREVFbYdDqChomlg4TFaioqfdzMURERF0Hg1YXIOMJ8URERH7BoNUVcGJpIiIiv2DQ6gocJpbmWFpERERth0GrK2CPFhERkV8waHUFjhNL8xwtIiKiNsOg1RU0HDoM5zQ8REREbYpBqytwvOqQQYuIiKjNMGh1BY4TS/PQIRERUZth0OoKbFcdSpXs0SIiImpDDFpdge0cLckIvbHGz8UQERF1HQxaXYEq3H7XYuTE0kRERG2FQasrkAfA0hC2ZLVlqDdb/FsPERFRF8Gg1UVItisPUYHy6jo/V0NERNQ1MGh1EVLQtUFLOZYWERFR22DQ6irsJ8TzykMiIqK2wqDVVTgcOuRYWkRERG2DQaurUEcAsE0szXO0iIiI2gKDVldhG7SUPVpERERthkGrq7CPDl+Bq5UMWkRERG2hXQStZcuWoXfv3lCpVEhOTsbevXubbb9p0yYMHDgQKpUKQ4YMwZdffum0XQiB+fPnIyYmBmq1GmlpaTh16pRTm3HjxqFXr15QqVSIiYnB5MmTUVhY6NTm0KFDuPvuu6FSqRAXF4cFCxZ4XEu74XjVIXu0iIiI2oTfg9aGDRswZ84cZGVlYf/+/Rg2bBjS09NRUlLisv3u3bsxadIkZGZm4sCBA8jIyEBGRgaOHDlib7NgwQIsWbIEK1asQH5+PoKDg5Geno6ammvTz4waNQobN27EyZMnsXnzZpw+fRoPP/ywfbvBYMAvf/lLxMfHY9++fVi4cCFee+01rFq1yqNa2g2HQ4e86pCIiKiNCD9LSkoSM2fOtD82m80iNjZWZGdnu2w/YcIEMXbsWKd1ycnJYsaMGUIIISwWi9BqtWLhwoX27eXl5UKpVIp169Y1Wce2bduEJEnCZDIJIYT4y1/+IiIiIkRtba29zUsvvSQGDBjgdi3Xq6mpEXq93r5cuHBBABB6vb7Jurym5IQQWWGibH6MeGDpv33/ekRERJ2UXq93+/vbrz1aJpMJ+/btQ1pamn2dTCZDWloa8vLyXD4nLy/PqT0ApKen29ufOXMGOp3OqY1Go0FycnKT+ywtLcXHH3+M1NRUBAYG2l/n5z//ORQKhdPrnDx5EmVlZW7Vcr3s7GxoNBr7EhcX57KdTzhOLF1Z3XavS0RE1IX5NWhduXIFZrMZ0dHRTuujo6Oh0+lcPken0zXb3nbrzj5feuklBAcHo1u3bjh//jy2bdvW4us4vkZLtVxv7ty50Ov19uXChQsu2/mE48TSVZxYmoiIqC34/Rwtf/rDH/6AAwcO4F//+hfkcjmmTJkCIYTPXk+pVCIsLMxpaTMOE0sr6vSoqTO33WsTERF1UQH+fPGoqCjI5XIUFxc7rS8uLoZWq3X5HK1W22x7221xcTFiYmKc2gwfPrzR60dFRaF///4YNGgQ4uLisGfPHqSkpDT5Oo6v0VIt7Y0U1A2oKbdOLF1VB61G7u+SiIiIOjW/9mgpFAokJiYiNzfXvs5isSA3NxcpKSkun5OSkuLUHgBycnLs7RMSEqDVap3aGAwG5OfnN7lP2+sCQG1trf11vvvuO9TVXRtFPScnBwMGDEBERIRbtbQ3jhNL88pDIiKiNuD7c/Obt379eqFUKsXatWvFsWPHxPTp00V4eLjQ6XRCCCEmT54sXn75ZXv7Xbt2iYCAALFo0SJx/PhxkZWVJQIDA8Xhw4ftbd5++20RHh4utm3bJg4dOiTGjx8vEhISRHV1tRBCiD179oilS5eKAwcOiLNnz4rc3FyRmpoq+vTpI2pqaoQQ1isVo6OjxeTJk8WRI0fE+vXrRVBQkFi5cqVHtTTHk6sWvOLjCUJkhYkXX3le/N+py23zmkRERJ2MJ9/ffg9aQgixdOlS0atXL6FQKERSUpLYs2ePfdvIkSPF1KlTndpv3LhR9O/fXygUCjF48GDxxRdfOG23WCxi3rx5Ijo6WiiVSjF69Ghx8uRJ+/ZDhw6JUaNGicjISKFUKkXv3r3Fk08+KS5evOi0nx9//FGMGDFCKJVK0bNnT/H22283qr2lWprT5kHr06eEyAoTb78yXXx28FLbvCYREVEn48n3tySED8/+pmYZDAZoNBro9fq2OTH+q/8G8v6MVfVjoRr7R0xJ6e371yQiIupkPPn+7tJXHXY5HB2eiIioTTFodSUOE0uXMWgRERH5HINWV+Jw1eFVBi0iIiKfY9DqSmzT8KASZVUMWkRERL7GoNWVNAQt6zhadS00JiIiohvFoNWVqK2HDsMlIwycWJqIiMjnGLS6EnWE/W59dZlP53UkIiIiBq2uRR4A0TCxdIhZjyoTJ5YmIiLyJQatrsZ25SHH0iIiIvI5Bq0uRnIcS4tXHhIREfkUg1ZXYw9alezRIiIi8jEGra5Gfe3QIXu0iIiIfItBq6sJsg3xwLG0iIiIfI1Bq6uxDVoKzndIRETkawxaXU1Dj1aEVIFSHjokIiLyKQatrsbhZHj2aBEREfkWg1ZXYwtaHEeLiIjI5xi0uhqniaUZtIiIiHyJQaurcZxY2siJpYmIiHyJQaurcZhY2lJdDouFE0sTERH5CoNWV+MwsXSYMKCipt6/9RAREXViDFpdkOQ4sTSHeCAiIvIZBq2uyGFiaZ4QT0RE5DsMWl0Rx9IiIiJqEwxaXZGahw6JiIjaAoNWV+QwsTR7tIiIiHyHQasrcphYmj1aREREvsOg1RU5TCzNHi0iIiLfYdDqihxOhi811vm5GCIios6LQasrcphYuoyHDomIiHyGQasrsl11yEOHREREPsWg1RU19GiFoQrllZxYmoiIyFcYtLqihomlZZIAaspRb7b4uSAiIqLOiUGrK5IHQKg0AKxXHpZX84R4IiIiX2DQ6qIkxxPieZ4WERGRT7SLoLVs2TL07t0bKpUKycnJ2Lt3b7PtN23ahIEDB0KlUmHIkCH48ssvnbYLITB//nzExMRArVYjLS0Np06dsm8/e/YsMjMzkZCQALVajT59+iArKwsm07XA8dprr0GSpEZLcHCwvc3atWsbbVepVF76qfiYbdBSTixNRETkM34PWhs2bMCcOXOQlZWF/fv3Y9iwYUhPT0dJSYnL9rt378akSZOQmZmJAwcOICMjAxkZGThy5Ii9zYIFC7BkyRKsWLEC+fn5CA4ORnp6OmpqagAAJ06cgMViwcqVK3H06FG89957WLFiBV555RX7Pl544QUUFRU5LbfccgseeeQRp3rCwsKc2pw7d84HPyUfUNsGLa3kEA9ERES+IvwsKSlJzJw50/7YbDaL2NhYkZ2d7bL9hAkTxNixY53WJScnixkzZgghhLBYLEKr1YqFCxfat5eXlwulUinWrVvXZB0LFiwQCQkJTW4/ePCgACC+++47+7o1a9YIjUbT7Ptrjl6vFwCEXq9v9T5abcuTQmSFiexXpouP95xr+9cnIiLqoDz5/vZrj5bJZMK+ffuQlpZmXyeTyZCWloa8vDyXz8nLy3NqDwDp6en29mfOnIFOp3Nqo9FokJyc3OQ+AUCv1yMyMrLJ7e+//z769++Pu+++22l9ZWUl4uPjERcXh/Hjx+Po0aNN7qO2thYGg8Fp8RvHaXjYo0VEROQTfg1aV65cgdlsRnR0tNP66Oho6HQ6l8/R6XTNtrfderLPgoICLF26FDNmzHC5vaamBh9//DEyMzOd1g8YMACrV6/Gtm3b8NFHH8FisSA1NRUXL150uZ/s7GxoNBr7EhcX57Jdm2gIWpHgOVpERES+4vdztPzt0qVLGDNmDB555BE88cQTLtt8+umnqKiowNSpU53Wp6SkYMqUKRg+fDhGjhyJLVu2oHv37li5cqXL/cydOxd6vd6+XLhwwevvx20NJ8OHS5W86pCIiMhH/Bq0oqKiIJfLUVxc7LS+uLgYWq3W5XO0Wm2z7W237uyzsLAQo0aNQmpqKlatWtVkne+//z5+9atfNeolu15gYCBuu+02FBQUuNyuVCoRFhbmtPiN41WHPHRIRETkE34NWgqFAomJicjNzbWvs1gsyM3NRUpKisvnpKSkOLUHgJycHHv7hIQEaLVapzYGgwH5+flO+7x06RLuueceJCYmYs2aNZDJXP8ozpw5gx07djQ6bOiK2WzG4cOHERMT02Jbv+M4WkRERD4X4E6jOXPmuL3DP/3pTx4VMGfOHEydOhW33347kpKSsHjxYhiNRkybNg0AMGXKFPTs2RPZ2dkAgFmzZmHkyJF49913MXbsWKxfvx4//PCDvUdKkiTMnj0bb731Fvr164eEhATMmzcPsbGxyMjIAHAtZMXHx2PRokW4fPmyvZ7re71Wr16NmJgY3HfffY1qf+ONN3DnnXeib9++KC8vx8KFC3Hu3Dn87ne/8+hn4BcOE0uzR4uIiMg33ApaBw4ccGtnkiR5XMDEiRNx+fJlzJ8/HzqdDsOHD8f27dvth+nOnz/v1NuUmpqKTz75BK+++ipeeeUV9OvXD1u3bsWtt95qb/Piiy/CaDRi+vTpKC8vx4gRI7B9+3b7YKI5OTkoKChAQUEBbrrpJqd6hBD2+xaLBWvXrsXjjz8OuVzeqPaysjI88cQT0Ol0iIiIQGJiInbv3o1bbrnF459Dm3OYWNpgrPFzMURERJ2TJByTBbUpg8EAjUYDvV7f9udrmeuBN61h62c1K5D31gQoAxqHSSIiInLmyfd3l7/qsMu6bmLpMiMnliYiIvI2tw4d/td//ZfbO9yyZUuri6G2JQV1A2r0iGgYS0ur6SDzNBIREXUQbgUtjUbj6zrIH4K6AaU/IZKjwxMREfmEW0FrzZo1vq6D/MFhYmmODk9EROR9PEerK3McS4s9WkRERF7nVo/W9f7+979j48aNOH/+PEwm5y/o/fv3e6UwagMOE0uzR4uIiMj7PO7RWrJkCaZNm4bo6GgcOHAASUlJ6NatG3766SeXg3pSO+YwsTRHhyciIvI+j4PWX/7yF6xatQpLly6FQqHAiy++iJycHPz+97+HXq/3RY3kKw4TS5dWcXgHIiIib/M4aJ0/fx6pqakAALVajYqKCgDA5MmTsW7dOu9WR77lMLE0e7SIiIi8z+OgpdVqUVpaCgDo1asX9uzZA8A6+TIHme9gbFcdgudoERER+YLHQesXv/gFPvvsMwDAtGnT8Nxzz+Hee+/FxIkT8eCDD3q9QPIh21WHUiWvOiQiIvIBj686XLVqFSwWCwBg5syZ6NatG3bv3o1x48ZhxowZXi+QfKghaGlghN5YDSFEqyYGJyIiItc8DloymQwy2bWOsEcffRSPPvqoV4uiNqKOAADIJAFVfQWq68wIUrRqxA8iIiJyweNDh2vWrMGmTZsard+0aRM+/PBDrxRFbeS6iaV5nhYREZF3eRy0srOzERUV1Wh9jx498Mc//tErRVHbkRxHhzdyiAciIiJvatXwDgkJCY3Wx8fH4/z5814pitpQw5WHkVIFrhpr/VwMERFR5+Jx0OrRowcOHTrUaP2PP/6Ibt26eaUoakMOg5byykMiIiLv8jhoTZo0Cb///e+xY8cOmM1mmM1mfPPNN5g1axZPiu+IbIOWogKlPHRIRETkVR5fYvbmm2/i7NmzGD16NAICrE+3WCyYMmUKz9HqiBwmlubo8ERERN7lcdBSKBTYsGED3nzzTfz4449Qq9UYMmQI4uPjfVEf+ZotaKES53jokIiIyKtaPWhS7969IYRAnz597D1b1AHZR4dnjxYREZG3eXyOVlVVFTIzMxEUFITBgwfbrzR89tln8fbbb3u9QPIxh4mlOY4WERGRd3kctObOnYsff/wRO3fuhEqlsq9PS0vDhg0bvFoctYGG4R3CwasOiYiIvM3jY35bt27Fhg0bcOeddzrNizd48GCcPn3aq8VRG3Dq0eJVh0RERN7kcY/W5cuX0aNHj0brjUYjJyTuiBwmljZUWSeWJiIiIu/wOGjdfvvt+OKLL+yPbeHq/fffR0pKivcqo7bhMLF0iKUShpp6PxdERETUeXh86PCPf/wj7rvvPhw7dgz19fX43//9Xxw7dgy7d+/Gt99+64sayZfkAYBKA9To7VceatSB/q6KiIioU/C4R2vEiBH48ccfUV9fjyFDhuBf//oXevTogby8PCQmJvqiRvI1h4mlS3lCPBERkdd41KNVV1eHGTNmYN68efjrX//qq5qorakjAfyESI6lRURE5FUe9WgFBgZi8+bNvqqF/MVhYumrDFpERERe4/Ghw4yMDGzdutUHpZDfOEwszR4tIiIi7/H4ZPh+/frhjTfewK5du5CYmIjg4GCn7b///e+9Vhy1EYeJpXmOFhERkfd4HLQ++OADhIeHY9++fdi3b5/TNkmSGLQ6IoeJpU+zR4uIiMhrPA5aZ86c8UUd5E8OE0tzdHgiIiLv8fgcLeqEGuY7jJQqON8hERGRF7WLoLVs2TL07t0bKpUKycnJ2Lt3b7PtN23ahIEDB0KlUmHIkCH48ssvnbYLITB//nzExMRArVYjLS0Np06dsm8/e/YsMjMzkZCQALVajT59+iArKwsmk8mpjSRJjZY9e/Z4VEuHYLvqEJU8GZ6IiMiL/B60NmzYgDlz5iArKwv79+/HsGHDkJ6ejpKSEpftd+/ejUmTJiEzMxMHDhxARkYGMjIycOTIEXubBQsWYMmSJVixYgXy8/MRHByM9PR01NTUAABOnDgBi8WClStX4ujRo3jvvfewYsUKvPLKK41e7+uvv0ZRUZF9cRyU1Z1aOgTHiaXZo0VEROQ1kvDzLMLJycm444478Oc//xkAYLFYEBcXh2effRYvv/xyo/YTJ06E0WjE559/bl935513Yvjw4VixYgWEEIiNjcXzzz+PF154AQCg1+sRHR2NtWvX4tFHH3VZx8KFC7F8+XL89NNPAKw9WgkJCThw4ACGDx/u8jkt1dISg8EAjUYDvV6PsLCwFtv7TGUJsKgfLEJCP9P/w8m3xiJA7vcMTkRE1C558v3t129Tk8mEffv2IS0tzb5OJpMhLS0NeXl5Lp+Tl5fn1B4A0tPT7e3PnDkDnU7n1Eaj0SA5ObnJfQLWMBYZGdlo/bhx49CjRw+MGDECn332mUe1XK+2thYGg8FpaRccJpYOE5XQV/OEeCIiIm/w+KrDvXv3Ii8vDzqdDgCg1WqRkpKCpKQkj1/8ypUrMJvNiI6OdlofHR2NEydOuHyOTqdz2d5Wj+22uTbXKygowNKlS7Fo0SL7upCQELz77ru46667IJPJsHnzZvtgrePGjXOrlutlZ2fj9ddfd7nNr+SB9omlbSfEdwtR+rsqIiKiDs/toFVSUoKHHnoIu3btQq9evewBo7i4GM899xzuuusubN68GT169PBZsb5w6dIljBkzBo888gieeOIJ+/qoqCjMmTPH/viOO+5AYWEhFi5caA9anpo7d67TPg0GA+Li4lpfvDepI4EavXViaQ7xQERE5BVuHzp8+umnYTabcfz4cZw9exb5+fnIz8/H2bNncfz4cVgsFsycOdOjF4+KioJcLkdxcbHT+uLiYmi1WpfP0Wq1zba33bqzz8LCQowaNQqpqalYtWpVi/UmJyejoKDA7Vqup1QqERYW5rS0G/axtCpRyisPiYiIvMLtoPXVV19h2bJlGDBgQKNtAwYMwJIlS7B9+3aPXlyhUCAxMRG5ubn2dRaLBbm5uUhJSXH5nJSUFKf2AJCTk2Nvn5CQAK1W69TGYDAgPz/faZ+XLl3CPffcg8TERKxZswYyWcs/ioMHDyImJsbtWjoUh0FLOZYWERGRd7h96FCpVDZ78nZFRQWUSs/P65kzZw6mTp2K22+/HUlJSVi8eDGMRiOmTZsGAJgyZQp69uyJ7OxsAMCsWbMwcuRIvPvuuxg7dizWr1+PH374wd4jJUkSZs+ejbfeegv9+vVDQkIC5s2bh9jYWGRkZAC4FrLi4+OxaNEiXL582V6PrTfqww8/hEKhwG233QYA2LJlC1avXo3333/f3ralWjoUh4ml2aNFRETkJcJNTz/9tIiPjxdbtmwRer3evl6v14stW7aI3r17i2eeecbd3TlZunSp6NWrl1AoFCIpKUns2bPHvm3kyJFi6tSpTu03btwo+vfvLxQKhRg8eLD44osvnLZbLBYxb948ER0dLZRKpRg9erQ4efKkffuaNWsEAJeLzdq1a8WgQYNEUFCQCAsLE0lJSWLTpk2Nam+plubo9XoBwOnn6TfbXxEiK0ws/+9fizf+cdTf1RAREbVbnnx/uz2OVm1tLWbPno3Vq1ejvr4eCoUCgHWIhoCAAGRmZuK9995rVa9WV9VuxtECgH+/C+S+gY31I7FnyBv408Th/q2HiIionfLk+9ujQ4fLly/HO++8g3379jkN75CYmOj/oEA3xnFiaZ6jRURE5BUej6MVFhaGUaNG+aIW8qeGiaUjJM53SERE5C1eGxm+uLgYb7zxhrd2R23N1qMF9mgRERF5i9eClk6na5+jnpN7HCaWLuOApURERF7h9qHDQ4cONbv95MmTN1wM+VGQ9dChBkZU1ZpQW2+GMkDu56KIiIg6NreD1vDhwyFJElxdpGhbL0mSV4ujNuQwsbQGlSivqkN0GIMWERHRjXA7aEVGRmLBggUYPXq0y+1Hjx7FAw884LXCqI1dN7F0qdGE6DCVv6siIiLq0NwOWomJiSgsLER8fLzL7eXl5S57u6gDcZhYmlceEhER3Ti3g9aTTz4Jo9HY5PZevXphzZo1XimK/CSoG1B2xjqxNK88JCIiumFuB60HH3yw2e0RERGYOnXqDRdEfuQ4sTR7tIiIiG6Y14Z3oE6g4cpD68TSHOKBiIjoRjFo0TUNPVrhUiXKeOiQiIjohjFo0TUOPVpXeeiQiIjohjFo0TX2+Q55jhYREZE3MGjRNfaT4StRyqBFRER0w9y+6tBRWVkZPvjgAxw/fhwAMGjQIPz2t79FZGSkV4ujNuYwsTTP0SIiIrpxHvdofffdd0hISMCSJUtQVlaGsrIyLF26FAkJCfjuu+98USO1Fds5Wg0jw3MAWiIiohvjcY/WzJkzMWHCBCxfvhxyuXUuPLPZjKeffhozZ87E4cOHvV4ktZGGHi0NjKirr0d1nRlBilZ1ehIRERFa0aNVUFCA559/3h6yAEAul2POnDkoKCjwanHUxq6bWJrnaREREd0Yj4PWz372M/u5WY6OHz+OYcOGeaUo8hN5IKDUALAePizjoKVEREQ3xOPjQr///e8xa9YsFBQU4M477wQA7NmzB8uWLcPbb7+NQ4cO2dsOHTrUe5VS2wiKBGr1CAfnOyQiIrpRHgetSZMmAQBefPFFl9skSYIQApIkwWw233iF1LYaJpaO5FhaREREN8zjoHXmzBlf1EHthcPE0jxHi4iI6MZ4HLTi4+N9UQe1Fw1DPESA8x0SERHdqFZdu3/69GksXrzYflL8LbfcglmzZqFPnz5eLY78wKFH6wJ7tIiIiG6Ix1cdfvXVV7jllluwd+9eDB06FEOHDkV+fj4GDx6MnJwcX9RIbclhYmn2aBEREd0Yj3u0Xn75ZTz33HN4++23G61/6aWXcO+993qtOPID+8TSHEeLiIjoRnnco3X8+HFkZmY2Wv/b3/4Wx44d80pR5Ec8GZ6IiMhrPA5a3bt3x8GDBxutP3jwIHr06OGNmsifHCaWLuWApURERDfE7UOHb7zxBl544QU88cQTmD59On766SekpqYCAHbt2oV33nkHc+bM8Vmh1EZsVx1K1nO0bGOiERERkeckIYRwp6FcLkdRURG6d++OxYsX491330VhYSEAIDY2Fn/4wx/w+9//nl/KHjAYDNBoNNDr9QgLC/N3OVaVJcCifrAICX1r/x8OZI2BRh3o76qIiIjaDU++v93u0bLlMUmS8Nxzz+G5555DRUUFACA0NPQGyqV25bqJpcuMJgYtIiKiVvLoHK3re6tCQ0MZsjobh4mlIyTOd0hERHQjPBreoX///i0eGiwtLb2hgqgdaJhYOgKc75CIiOhGeBS0Xn/9dWg0Gl/VQu2Fw8TSHOKBiIio9TwKWo8++iiHcOgKrrvykIiIiFrH7XO0fHk14bJly9C7d2+oVCokJydj7969zbbftGkTBg4cCJVKhSFDhuDLL7902i6EwPz58xETEwO1Wo20tDScOnXKvv3s2bPIzMxEQkIC1Go1+vTpg6ysLJhM10LFzp07MX78eMTExCA4OBjDhw/Hxx9/7PQ6a9euhSRJTotKpfLCT8TP7GNpVXIsLSIiohvgdtBycxQIj23YsAFz5sxBVlYW9u/fj2HDhiE9PR0lJSUu2+/evRuTJk1CZmYmDhw4gIyMDGRkZODIkSP2NgsWLMCSJUuwYsUK5OfnIzg4GOnp6aipqQEAnDhxAhaLBStXrsTRo0fx3nvvYcWKFXjllVecXmfo0KHYvHkzDh06hGnTpmHKlCn4/PPPneoJCwtDUVGRfTl37pwPfkptzGF0eJ6jRURE1Hpuj6PlK8nJybjjjjvw5z//GQBgsVgQFxeHZ599Fi+//HKj9hMnToTRaHQKPHfeeSeGDx+OFStWQAiB2NhYPP/883jhhRcAAHq9HtHR0Vi7di0effRRl3UsXLgQy5cvx08//dRkrWPHjkV0dDRWr14NwNqjNXv2bJSXl7v1Xmtra1FbW2t/bDAYEBcX177G0QKA7xYB37yJjfUjkdN/Pv465XZ/V0RERNRueDKOlsdT8HiTyWTCvn37kJaWZl8nk8mQlpaGvLw8l8/Jy8tzag8A6enp9vZnzpyBTqdzaqPRaJCcnNzkPgFrGIuMjGy2XldtKisrER8fj7i4OIwfPx5Hjx5t8vnZ2dnQaDT2JS4urtnX8xt7j1Yle7SIiIhugF+D1pUrV2A2mxEdHe20Pjo6GjqdzuVzdDpds+1tt57ss6CgAEuXLsWMGTOarHXjxo34/vvvMW3aNPu6AQMGYPXq1di2bRs++ugjWCwWpKam4uLFiy73MXfuXOj1evty4cKFJl/PrxwnlubJ8ERERK3m0VWHndGlS5cwZswYPPLII3jiiSdcttmxYwemTZuGv/71rxg8eLB9fUpKClJSUuyPU1NTMWjQIKxcuRJvvvlmo/0olUoolUrvvwlvs111yHG0iIiIbohfe7SioqIgl8tRXFzstL64uBhardblc7RabbPtbbfu7LOwsBCjRo1CamoqVq1a5fL1vv32WzzwwAN47733MGXKlGbfT2BgIG677TYUFBQ0267dc+jRKq+ug9ni19P4iIiIOiy/Bi2FQoHExETk5uba11ksFuTm5jr1FDlKSUlxag8AOTk59vYJCQnQarVObQwGA/Lz8532eenSJdxzzz1ITEzEmjVrIJM1/lHs3LkTY8eOxTvvvIPp06e3+H7MZjMOHz6MmJiYFtu2aw1BKxxGSMKCch4+JCIiahW/HzqcM2cOpk6dittvvx1JSUlYvHgxjEaj/VyoKVOmoGfPnsjOzgYAzJo1CyNHjsS7776LsWPHYv369fjhhx/sPVKSJGH27Nl466230K9fPyQkJGDevHmIjY1FRkYGgGshKz4+HosWLcLly5ft9dh6vXbs2IFf/epXmDVrFh566CH7+V0KhcJ+Qvwbb7yBO++8E3379kV5eTkWLlyIc+fO4Xe/+12b/Ox85vqJpatM6BbSAQ55EhERtTN+D1oTJ07E5cuXMX/+fOh0OgwfPhzbt2+3n8x+/vx5p96m1NRUfPLJJ3j11VfxyiuvoF+/fti6dStuvfVWe5sXX3wRRqMR06dPR3l5OUaMGIHt27fbBxPNyclBQUEBCgoKcNNNNznVYxvt4sMPP0RVVRWys7PtIQ8ARo4ciZ07dwIAysrK8MQTT0Cn0yEiIgKJiYnYvXs3brnlFp/8rNqMbWLpWr11YmkOWkpERNQqfh9HqyvzZByONve/w4GyM3ioNgtPPPZrjLnV9TlzREREXU2HGUeL2rGG87QiOd8hERFRqzFokWsNQzyES5Uo5RAPRERErcKgRa7ZerQ4lhYREVGrMWiRaxwdnoiI6IYxaJFrDUM8RIDzHRIREbUWgxa55nAyfGkVh3cgIiJqDQYtcs3h0CF7tIiIiFqHQYtc48TSREREN4xBi1xz6NGqqK2Hqd7i54KIiIg6HgYtcs1hYmkZLBy0lIiIqBUYtMg1h4mlw2DkoKVEREStwKBFrtkmlkbDNDwMWkRERB5j0KKmOZwQz0FLiYiIPMegRU2zBS2Jg5YSERG1BoMWNc1xGh4jBy0lIiLyFIMWNc1xYmkeOiQiIvIYgxY1TW07dFjBqw6JiIhagUGLmmY/Gb6SPVpEREStwKBFTXOcWJo9WkRERB5j0KKmBV07dMirDomIiDzHoEVNs111yHG0iIiIWoVBi5rmMLxDTZ0F1SaznwsiIiLqWBi0qGkNVx3aJpZmrxYREZFnGLSoaQ3naNkmluZ5WkRERJ5h0KKmXTex9FUGLSIiIo8waFHzHCaWZo8WERGRZxi0qHkOE0tzLC0iIiLPMGhR8xyuPOTo8ERERJ5h0KLmOUwszR4tIiIizzBoUfPU1w4dskeLiIjIMwxa1DyHk+HZo0VEROQZBi1qnsPE0mXGOj8XQ0RE1LEwaFHzGnq0wiXOd0hEROQpBi1qnsPJ8GVGE4QQfi6IiIio42DQouY5DO9QbxGoqK33c0FEREQdR7sIWsuWLUPv3r2hUqmQnJyMvXv3Ntt+06ZNGDhwIFQqFYYMGYIvv/zSabsQAvPnz0dMTAzUajXS0tJw6tQp+/azZ88iMzMTCQkJUKvV6NOnD7KysmAyOR8aO3ToEO6++26oVCrExcVhwYIFHtfS4TVcdahpmFiao8MTERG5z+9Ba8OGDZgzZw6ysrKwf/9+DBs2DOnp6SgpKXHZfvfu3Zg0aRIyMzNx4MABZGRkICMjA0eOHLG3WbBgAZYsWYIVK1YgPz8fwcHBSE9PR01NDQDgxIkTsFgsWLlyJY4ePYr33nsPK1aswCuvvGLfh8FgwC9/+UvEx8dj3759WLhwIV577TWsWrXKo1o6vIZztOQNE0vzykMiIiIPCD9LSkoSM2fOtD82m80iNjZWZGdnu2w/YcIEMXbsWKd1ycnJYsaMGUIIISwWi9BqtWLhwoX27eXl5UKpVIp169Y1WceCBQtEQkKC/fFf/vIXERERIWpra+3rXnrpJTFgwAC3a2mJXq8XAIRer3ervd/8MU6IrDAx6uVVIve4zt/VEBER+ZUn399+7dEymUzYt28f0tLS7OtkMhnS0tKQl5fn8jl5eXlO7QEgPT3d3v7MmTPQ6XRObTQaDZKTk5vcJwDo9XpERkY6vc7Pf/5zKBQKp9c5efIkysrK3KrlerW1tTAYDE5LhxAUAQAIRyVKOcQDERGR2/watK5cuQKz2Yzo6Gin9dHR0dDpdC6fo9Ppmm1vu/VknwUFBVi6dClmzJjR4us4vkZLtVwvOzsbGo3GvsTFxbls1+44jKVVaqz1czFEREQdh9/P0fK3S5cuYcyYMXjkkUfwxBNP+PS15s6dC71eb18uXLjg09fzGocrD9mjRURE5D6/Bq2oqCjI5XIUFxc7rS8uLoZWq3X5HK1W22x72607+ywsLMSoUaOQmprqdJJ7c6/j+Bot1XI9pVKJsLAwp6VDUF+bhodXHRIREbnPr0FLoVAgMTERubm59nUWiwW5ublISUlx+ZyUlBSn9gCQk5Njb5+QkACtVuvUxmAwID8/32mfly5dwj333IPExESsWbMGMpnzjyIlJQXfffcd6uqu9eDk5ORgwIABiIiIcKuWTsN+6LCSo8MTERF5og1Ozm/W+vXrhVKpFGvXrhXHjh0T06dPF+Hh4UKns17dNnnyZPHyyy/b2+/atUsEBASIRYsWiePHj4usrCwRGBgoDh8+bG/z9ttvi/DwcLFt2zZx6NAhMX78eJGQkCCqq6uFEEJcvHhR9O3bV4wePVpcvHhRFBUV2Reb8vJyER0dLSZPniyOHDki1q9fL4KCgsTKlSs9qqU5Heaqw28XCpEVJtb/9zjx0F92+bsaIiIiv/Lk+9vvQUsIIZYuXSp69eolFAqFSEpKEnv27LFvGzlypJg6dapT+40bN4r+/fsLhUIhBg8eLL744gun7RaLRcybN09ER0cLpVIpRo8eLU6ePGnfvmbNGgHA5eLoxx9/FCNGjBBKpVL07NlTvP32241qb6mW5nSYoPX9B0JkhYl/vTpKjFq0w9/VEBER+ZUn39+SEJy8zl8MBgM0Gg30en37Pl/r2DZg4xR8b+mP6QH/gwPzf+nvioiIiPzGk+/vLn/VIbnBYWLp8uo6mC3M5kRERO5g0KKWOQzvIASgr+YQD0RERO5g0KKW2SaWlqwTS3O+QyIiIvcwaFHLbBNLwzqxdBmHeCAiInILgxa1TB4IKDUAbNPwMGgRERG5g0GL3OMwsTRHhyciInIPgxa5x3FiaR46JCIicguDFrnHcWLpSgYtIiIidzBokXscJpZmjxYREZF7GLTIPQ4TS/McLSIiIvcwaJF7ghx7tDhgKRERkTsYtMg9tqAlVbBHi4iIyE0MWuQeh5PhGbSIiIjcw6BF7nGYWLqith6meoufCyIiImr/GLTIPQ1XHYZLlQCAcl55SERE1CIGLXJPQ49WuG1iaQYtIiKiFjFokXvsE0tbEAYj5zskIiJyA4MWuUceCCjDAAARUiXKjBzigYiIqCUMWuQ+h7G0dpws8XMxRERE7R+DFrmv4TytbrIK/H3fRYYtIiKiFjBokfsarjz8VV8VAGDu5sPQV/MQIhERUVMYtMh9DT1a9/cJREJUMHSGGrz5+TE/F0VERNR+MWiR+xqCVmBtGRY+PBSSBPx930V8c6LYz4URERG1Twxa5L6gCOttVSlu7x2JzLsSAABztxyGnhNNExERNcKgRe5r6NFCVSkA4IX0Abg5KhjFhlq8/vlRPxZGRETUPjFokfvsQesqAEAVKMfCR4ZBJgFb9l/C18d4CJGIiMgRgxa577qgBQCJ8RF44u6bAQBzPz3MORCJiIgcMGiR+xqGd0B1qdPq5+7tjz7dg3G5ohav/4NXIRIREdkwaJH7bD1a1WWAxWxfrQqUY1HDIcRPD1zCv47q/FQgERFR+8KgRe5rmIIHwgLU6J023dYrAtN/3gcA8MqnR1DGSaeJiIgYtMgDDhNL2648dDQ7rR/69QjBlcpavPYPXoVIRETEoEWesfVqOZwQb2M7hCiXSdh2sBDbj/AQIhERdW0MWuQZF1ceOhoWF44ZP7dehfjq1sMo5SFEIiLqwhi0yDO2Kw8vn2iyyay0fugfHYIrlSbM33akjQojIiJqfxi0yDN9fmG93fFH4FyeyybKADnefWQ45DIJnx8qwj8PF7VhgURERO2H34PWsmXL0Lt3b6hUKiQnJ2Pv3r3Ntt+0aRMGDhwIlUqFIUOG4Msvv3TaLoTA/PnzERMTA7VajbS0NJw6dcqpzf/8z/8gNTUVQUFBCA8Pb/Qaa9euhSRJLpeSkhIAwM6dO11u1+k6+XlJyU8Cg8YBljpgw2NA2VmXzYbcpMFTI61XIb669QiuVta2YZFERETtg1+D1oYNGzBnzhxkZWVh//79GDZsGNLT0+1h5nq7d+/GpEmTkJmZiQMHDiAjIwMZGRk4cuTa4akFCxZgyZIlWLFiBfLz8xEcHIz09HTU1NTY25hMJjzyyCN46qmnXL7OxIkTUVRU5LSkp6dj5MiR6NGjh1PbkydPOrW7fnunI5MBD64AYoZZz9P65FGgxuCy6bOj+2KgNhRXjSbM38arEImIqAsSfpSUlCRmzpxpf2w2m0VsbKzIzs522X7ChAli7NixTuuSk5PFjBkzhBBCWCwWodVqxcKFC+3by8vLhVKpFOvWrWu0vzVr1giNRtNinSUlJSIwMFD87W9/s6/bsWOHACDKyspafH5T9Hq9ACD0en2r9+E3+ktCLOwvRFaYEB89LIS53mWzwxfLxc1zvxDxL30u/vHjpTYukoiIyPs8+f72W4+WyWTCvn37kJaWZl8nk8mQlpaGvDzX5/7k5eU5tQeA9PR0e/szZ85Ap9M5tdFoNEhOTm5yn+7429/+hqCgIDz88MONtg0fPhwxMTG49957sWvXrmb3U1tbC4PB4LR0WGGxwKR1QIAKOPUv4F/zXDa7tacGM0f1BQDM33YUV3gIkYiIuhC/Ba0rV67AbDYjOjraaX10dHST5znpdLpm29tuPdmnOz744AP8+te/hlqttq+LiYnBihUrsHnzZmzevBlxcXG45557sH///ib3k52dDY1GY1/i4uJaXVO70PNn1sOIALBnGbBvrctmz4zqi0ExYSg1mjBv6xEIIdquRiIiIj/y+8nw7V1eXh6OHz+OzMxMp/UDBgzAjBkzkJiYiNTUVKxevRqpqal47733mtzX3Llzodfr7cuFCxd8Xb7vDX4QGPXf1vtfPA+c+a5RE0WADIseGYoAmYR/HtHh80O8CpGIiLoGvwWtqKgoyOVyFBcXO60vLi6GVqt1+RytVttse9utJ/tsyfvvv4/hw4cjMTGxxbZJSUkoKChocrtSqURYWJjT0in8/A/ArQ8Dlnpgw2Tg6ulGTQbHavDML2yHEI/gcgUPIRIRUefnt6ClUCiQmJiI3Nxc+zqLxYLc3FykpKS4fE5KSopTewDIycmxt09ISIBWq3VqYzAYkJ+f3+Q+m1NZWYmNGzc26s1qysGDBxETE+Px63R4kgSM/zPQ83agphz4ZAJQXdao2cxRfXFLTBjKqurw6tbDPIRIRESdnl8PHc6ZMwd//etf8eGHH+L48eN46qmnYDQaMW3aNADAlClTMHfuXHv7WbNmYfv27Xj33Xdx4sQJvPbaa/jhhx/wzDPPAAAkScLs2bPx1ltv4bPPPsPhw4cxZcoUxMbGIiMjw76f8+fP4+DBgzh//jzMZjMOHjyIgwcPorKy0qm+DRs2oL6+Hr/5zW8a1b548WJs27YNBQUFOHLkCGbPno1vvvkGM2fO9MFPqgMIVAOPfgKE3QRcLQA2TgXMdc5N5DIsemQYAuUSvjpajM9+LPRTsURERG3E59dAtmDp0qWiV69eQqFQiKSkJLFnzx77tpEjR4qpU6c6td+4caPo37+/UCgUYvDgweKLL75w2m6xWMS8efNEdHS0UCqVYvTo0eLkyZNObaZOnSoANFp27Njh1C4lJUX8+te/dln3O++8I/r06SNUKpWIjIwU99xzj/jmm288eu8deniHphQdEuKtGOuwD/94TgiLpVGT//36PyL+pc/F0Ne+EsX6aj8USURE1HqefH9LQvD4jb8YDAZoNBro9frOc74WAJz4Elj/awACuG8hkDzdaXOd2YIH/7ILRy4ZkDYoGn+dkghJkvxTKxERkYc8+f7mVYfkfQPvB9Jes97f/hJQ8LXTZsdDiF8fL8bWg5favkYiIqI2wKBFvnHXLGD4bwBhATZNAy6fdNo8UBuGWaP7AQBe++wYig01rvZCRETUoTFokW9IEvCrPwG9UoFag/VKRONVpyZPjuyDIT010FfX4ZUtvAqRiIg6HwYt8p0AJTDxIyA8Hig7C2ycDNSbrm2Wy/DuhGFQyGXIPVGCLft5CJGIiDoXBi3yreBuwK83Asow4Nwu4PPnAIeeq/7RoZh9b8MhxH8chU7PQ4hERNR58KpDP+q0Vx26cupr4JNHrOds3fsmcNfv7ZvqzRY8tCIPP14oR6/IINzWKxzx3YLRu1sQ4rsFIb5bMLoFK3hlIhERtQuefH8zaPlRlwpaALBnhfUqREjApHXAgPvsm04VV+DBv+xGZW29y6eGKAMQ3y0IvbsFO99GBaNHqJIhjIiI2gyDVgfR5YKWEMAXc4AfVgOKEOC3XwHaW+2bSypqsP9cOc5dNeLs1Sqcu2rEuatVKNRXo7nfUlWgzB684q8LYjEaNeQyhjAiIvIeBq0OossFLcA6Lc9HDwFnvgU0ccAT3wAhPZp9Sk2dGRfLqp0CmO32Ylk1zJamf4UVchniItVIiArGQG0Ybu0ZhsGxGtwUoWYvGBERtQqDVgfRJYMWYJ1w+v0065yINyUBU/8BBKpatas6swWXyqpxtqH3y/H2Ymk1TGaLy+eFqQIwOFaDwbFhGNwzDLfGanBz9xD2fhERUYsYtDqILhu0AOBKAfD+aKCmHBgyAfivVdaxt7zIbBEo0lfj3NUqnL5ciaOXDDhapMd/dJUuA5gqUObU6zU4Ngz9o0OhCpR7tS4iIurYGLQ6iC4dtADgp2+Bj/4LsNQDv3gV+PkffPM65jqgrgpQaQAApnoLTpVU4GihAccKDThySY9jRQZUmcyNnhogk9C3RwgGx2rsAeyW2DCEKAN8UysREbV7DFodRJcPWoD1xPjPn7Pef+RDYHBGy88x1wFVVwHjZcB45br7V6y3xivWdVVXgBq99XlR/YG+9wL90qwj1jscrrRYBM5eNeJIoQFHC/X2AFZWVeeyhISoYNwSG2bt9eoRip4RavSMUCNMFXiDPxAiImrvGLQ6CAatBv98GchfDgSogXFLrYcQHYOSLThVNayzBacbERgE9L4b6Hcv0DcNiExo1EQIgSJ9DY42hK6jDSGsqJlBVUOVAdbQFa5GbLja6f5NEWp0D1FC5u/zwGx/8rwYoMsSQqDYUIufLlfi9BUjzlw24qcrlfjpshFXKmvRI1SJ2Ibf29hwNXqGqxpurY95OJ26OgatDoJBq4G5Hlj3KFCQ4/5zJBkQ1A0I7t5wG9VwP8o6Gr39fnfrNgA48531NQpygYoi5/1F9mkIXfcCve8CAtVNvnSp0YSjhXocuWQNXmevGnGprLrJ3i9HgXIJMRrrF1bPiIYA5nA/RqNq3ZdYXbVDOLX18F1u3Ltnuy/JrD183Qc03A603o9IAORte1hUCAGjyYwSQw0uV9TicmWt9da2NDwGgNt6heOO3pFISohEjKbpz4isqkz1+OmyET9dMeKny5UN9ytx5rIRRheHyt3VLVjREMKcA5jtfrdghf//QdEKtfVmFOtrUaivRpG+GkX6GkiQ7O8zNlyN6FAlAuRdZ1IVs0XgYlkVThVX4swVI+osFsglCXKZBEmSIJcAmUyCrGGdTILDfalhGyC335cgl6Hhubb9AIFyGVQBcqgVMigD5FAFyqEKlEEdKG+XP28GrQ6CQctBjR74+28B/aWG0BTVEJQc73e/dl8dAcha+ccnBFB81Bq6Tn0NXNhjPU/MJkBl7e3qm2YNX936uLXbKlM9CsurcbGsGoXlNbhUXoVLZdW4VG59XKSvRjMjUdh1D1XiJo0C/UNqEC7KEVJfjtD6MoSY9QgxlyHUXI6QeuutbVGJ6tb9LK5jlgJREdwLlWF9UaPpA1NEf4io/pCi+kIdFIIghRxqhRxBbvzPz1RvwVWjNSSVGJoOUJcralFd5/mXflyk2hq6ekfijoRI3BwV3CWH7DBbBArLq3HaIUj9dNmIM1eMzfa+ymUS4iLUuLl7CG6OCrbedrcOAHy5who2rL/H1Sgsr8alMuutOwFNESBDrEbVqFcsKkSJUFUgwtQBCFUFIlQVgBBFQJuEsnqzBcUVtSgqr0ahvgZF5dYgVVheDZ2hBoXlNbhSWdvifmQSoA279t5iwlXWoKm5FjTD1AEd7nfRbBG4UFqF/xRX4FRJJU413J6+XImaOtdXb7eVAJnUELys4UsVKIfa4b59CZBBrbh2X6WQQxUgR4xGhfuGxHi1JgatDoJBq52oMQA/7QQKvrYuhusmt45IuHaIsffdgCKoVS9Tb7ZAZ6hB0ZVylBWfRWXJeZjKLgEVhVAYdQgxlaC7KEW0VIoeKEeA5Nn/3ExCjqvQ4KoIsy4Ia/K+EnXoKxWij3QJ/WSX0Fe6hL5SIdSSyeW+zULCedEDBaKndbH0xDnZTSgM7AUoQqBWyBGsDIAyQAZ9dR0uV9S61cPnKEQZgO6hSnQPUVpvr1uqTWZ8f7YU358txbFCQ6PQGhWiwO3x1tCV1DsSg2JC2+W/hIUQMJktqK23oKbOjNo66/3aejNq6qy3tfUW1NY13JrMQNVlBOkLEFJxGprKn6AxnkWVWcL5ugicqgnDRUsEikUEikQ36EQkKqAGYP2ijwxWICEq2ClM9ekejF6RwVAEePbzEULAUF1vD1+F+mv/kCgsr0ZhWRXqKi4jGtbf4xipFNqG22iUIlAyo0ooUQUlqm23UMEcoIYlIAgiMAiSIghyZTBkyhAEqIKhUIdCoQ6BKjgUqqBQBIWEITRIbQ1sqgCEqQOhkMtwubIWhY7hSV9jva+vRlF5DUoqatz6h44tJMZorCEKAvbQWaSvRp255Z0EK+QNIazhsKvGucdPq1F5/LNv+ACs05hZzNZ/HIqGW4vF+TEAyAIAWSAgk1vvywMBWQDMkON8WTX+U1yBgpJKa7Aqtgaq2nrX/89RBMjQp3sI+vYIgSpABosALELAbBGwCOFw33q+q1lcu+/cDtc9x/o7ZbYI1FsEaurMqK4zo6bO7NVwd1uvcHz69F1e2x/AoNVhMGi1Q0IAJccbDjF+DZzLAywOgUGutB5a7JtmPcwY1e/auU5CWIerMBQChiJrYKsoanhc2HD/knUcMTdYIEONIgI1ikjUKCJQq4hEjSIStYoI1Ci72e/XKiNRq+iG+sAQSJK1G16ChIb/rOtgLdNWar1ZoLrOjCpTw1Jbj2pTHZTGQoQbf0JU9Vn0qD2H2LpziDNfQCiMTdZZKCJRYLEGsNMiFhUiCHWQox5yCEmOILUaoUEqhASpERasRlhwEDQhQQgPViMiNAgRocHoFhYEtUrt9IVg/ZJw8WVkrkeFsQKHzxbj8NliHLtQgjNFVyEz10IlmaCCCUrUQRNoRv9IOfpGBiIhXI7YEAmBllqgrgaod1xqAXU4EHYToOkJaG66dl8R3OxnVFtvRomhFsWGGugMNSi23dfXoNhQg1Kj6Vqgqr8Wolz/X1cgFlcdgu8l9JVdQj/pEsKlpn/+rtTJg1AfEoOA8JsQGN4TCIttWBzuB3Xz7Dw9cz1gLGn4fb507ffavlwCKnSAueVeoRtlEnJUQ4kqqFAllKiGErUIhEkEwoQA630EohYBqBW2+4EwS4EIVKqhUgchSB2E4KAghISEICwkGJrQUESEhiA0JAhSgBoIUFj/3iXJ/ntiqauBoaISpYYK6Csqoa80otJYCaPRiOrqKtRUV8NcVw0l6qBAvfVWqmt43HAr1UMFE9QyMxQyCwIkCwJgvZXDel8GC+QwQyYskMEMSZghE9Zbb6gXMpghRz1kqG/4WzU33MrkAZAFKBAQEIjAwEAoFEooFApItr9NRYj1Cm5VWMOtBlA63FeFAarwa+sCFK2qUQhh/9upqbM4BDAzqk31qK+uRH21HuZqPSw1FRA1BojaCshqKyCrq4TMVAF5XSUC6o0Qmjjc/dtsr/zsbBi0OggGrQ6gtsJ6btephuClv+C8PbwXEB5/7cum3s1DeAFqhy+/WCA0xuF+w21ID+u/Rv1NCKCyGLh8EuLySZhLTkBcPgnZlZOQV1327WtLMmvgkjdczVlf43yY18fqlRpUq7TQK6JxRdYdReiG8/URKKjV4JgxDP+pDkMdPDunTQYLeknF6CddQl9ZIQbIrLc34xKC4PpQnwUSrgbG4rKqN0rVvVEenIAwlQxx8nJEiasIqS2BZAs7NeXuFSJXAmEx18JXaMN9dbj187YHqoZ/LFTqrL0p7gju4RDsYq79XgcoAFOVdbgVkxH1NZUw1VRavzRrjbDUGiFMRqCuCrK6KsjqqxFgti4KSzXk8O8hrPbMAglmyGGB9R8nMmFGoOSdYHZDAtQthLKG+7JAwFRp/X9ubQVQa7De1hgc1jUspgr3fxcB4KY7gN997dW3xaDVQTBodTBCAFf+0xC6coBzuwGzi0Nt6gjrF4xjeLIHqIZ1qvDOcdVfVan1Z3L5pPX2aoH1S9Rcb+0JNNdZg5Ht1lLXxLY6z/7HaSNXWP9HHqC0DtcRYF1EgBpVlgCUmmS4XCODzihQXidHLRSohQI1CEQtFNCEhiK2mwYh5nIEVhYhqEaH8PoS9LBcQajUcmi2CAlXoMFVeXcYAnvAqI6BOSQWUvhNUHaLQ2hIGMKqziLEUAB1eQGU5QUILD8NydXvDWD9sunWp+EihQHW2+4DgG59m71Aw4mp6lrvqVPvk8M6Y4kHP2TH+gKu/V6HOoQ0x8AWom11L0azhLD+vTUEMZiqIExGVFdVoK66EiFyM+TCBNSbrIHc3HBbb7L2sjndb1jsbWpdtG9YIBp+xxTW3y95w22jx0rrIldeux+gbNRGyBWoqJfjag1QbZahqk6gyiyhqk7AWA8Y64CqOsBoEqioA4wmCyrrJFSYLKioE6isFdCbBKrqADNk9kWgce+vOlCG/t2DMKC7Cv26B6FflBJ9o1SICQ2EXNQ3/E2arX9/lobH5vpr9y111u32v1WTNQzVGKzn1dborYHIdt+2vtZgXXxNkgPKUGt4U4ZeW1SOj8Os/xgeNtGrL82g1UEwaHVwJiNwdpf1fyxhDl8+7n4hkjPbeSauQpi54fBtgMr687V9sbnZ4yeEwPnSKuw9Yz3Ha++ZUpy9WtXsczRSFQYFV2Cg2oCbFeWIk5dCiyuINF9GaG0xVNU6yFp7mCxAbT3s3H0g0L3hqs+oAdZhRmy9d75Ub7KGMadA1hDKqsuBUO11QaphCe7ePnpZCfVmC4y1ZlSa6mGsrUdlrfXWWFsPRYAM/XqEome42n9Xf1rMDSHMVShzXNdwa65zDkv2ABXmYl3D/UC13/7ByqDVQTBoEflPSUUNvj9ThoMXyqAIkCE6TGVftGEqRIUomj+ZXgjrUBr6C9arZQ2XAP3FhtuG+3VGa2+UvYeqIVhperX+qlki8jsGrQ6CQYuIiKjj8eT7m/+kIiIiIvIRBi0iIiIiH2HQIiIiIvIRBi0iIiIiH2HQIiIiIvIRBi0iIiIiH2HQIiIiIvIRBi0iIiIiH2HQIiIiIvIRBi0iIiIiH2HQIiIiIvIRBi0iIiIiH2HQIiIiIvIRBi0iIiIiHwnwdwFdmRACAGAwGPxcCREREbnL9r1t+x5vDoOWH1VUVAAA4uLi/FwJEREReaqiogIajabZNpJwJ46RT1gsFhQWFiI0NBSSJHl13waDAXFxcbhw4QLCwsK8uu/2oLO/P6Dzv0e+v46vs79Hvr+Oz1fvUQiBiooKxMbGQiZr/iws9mj5kUwmw0033eTT1wgLC+u0f0BA539/QOd/j3x/HV9nf498fx2fL95jSz1ZNjwZnoiIiMhHGLSIiIiIfIRBq5NSKpXIysqCUqn0dyk+0dnfH9D53yPfX8fX2d8j31/H1x7eI0+GJyIiIvIR9mgRERER+QiDFhEREZGPMGgRERER+QiDFhEREZGPMGh1YMuWLUPv3r2hUqmQnJyMvXv3Ntt+06ZNGDhwIFQqFYYMGYIvv/yyjSr1THZ2Nu644w6EhoaiR48eyMjIwMmTJ5t9ztq1ayFJktOiUqnaqGLPvfbaa43qHThwYLPP6SifHwD07t270fuTJAkzZ8502b69f37fffcdHnjgAcTGxkKSJGzdutVpuxAC8+fPR0xMDNRqNdLS0nDq1KkW9+vp37AvNfce6+rq8NJLL2HIkCEIDg5GbGwspkyZgsLCwmb32Zrfc19p6TN8/PHHG9U6ZsyYFvfbUT5DAC7/JiVJwsKFC5vcZ3v5DN35XqipqcHMmTPRrVs3hISE4KGHHkJxcXGz+23t364nGLQ6qA0bNmDOnDnIysrC/v37MWzYMKSnp6OkpMRl+927d2PSpEnIzMzEgQMHkJGRgYyMDBw5cqSNK2/Zt99+i5kzZ2LPnj3IyclBXV0dfvnLX8JoNDb7vLCwMBQVFdmXc+fOtVHFrTN48GCnev/v//6vybYd6fMDgO+//97pveXk5AAAHnnkkSaf054/P6PRiGHDhmHZsmUuty9YsABLlizBihUrkJ+fj+DgYKSnp6OmpqbJfXr6N+xrzb3Hqqoq7N+/H/PmzcP+/fuxZcsWnDx5EuPGjWtxv578nvtSS58hAIwZM8ap1nXr1jW7z470GQJwem9FRUVYvXo1JEnCQw891Ox+28Nn6M73wnPPPYd//OMf2LRpE7799lsUFhbiv/7rv5rdb2v+dj0mqENKSkoSM2fOtD82m80iNjZWZGdnu2w/YcIEMXbsWKd1ycnJYsaMGT6t0xtKSkoEAPHtt9822WbNmjVCo9G0XVE3KCsrSwwbNszt9h358xNCiFmzZok+ffoIi8XicntH+vwAiE8//dT+2GKxCK1WKxYuXGhfV15eLpRKpVi3bl2T+/H0b7gtXf8eXdm7d68AIM6dO9dkG09/z9uKq/c3depUMX78eI/209E/w/Hjx4tf/OIXzbZpr5/h9d8L5eXlIjAwUGzatMne5vjx4wKAyMvLc7mP1v7teoo9Wh2QyWTCvn37kJaWZl8nk8mQlpaGvLw8l8/Jy8tzag8A6enpTbZvT/R6PQAgMjKy2XaVlZWIj49HXFwcxo8fj6NHj7ZFea126tQpxMbG4uabb8Zjjz2G8+fPN9m2I39+JpMJH330EX772982O3l6R/v8bM6cOQOdTuf0+Wg0GiQnJzf5+bTmb7i90ev1kCQJ4eHhzbbz5Pfc33bu3IkePXpgwIABeOqpp3D16tUm23b0z7C4uBhffPEFMjMzW2zbHj/D678X9u3bh7q6OqfPY+DAgejVq1eTn0dr/nZbg0GrA7py5QrMZjOio6Od1kdHR0On07l8jk6n86h9e2GxWDB79mzcdddduPXWW5tsN2DAAKxevRrbtm3DRx99BIvFgtTUVFy8eLENq3VfcnIy1q5di+3bt2P58uU4c+YM7r77blRUVLhs31E/PwDYunUrysvL8fjjjzfZpqN9fo5sn4Enn09r/obbk5qaGrz00kuYNGlSsxP1evp77k9jxozB3/72N+Tm5uKdd97Bt99+i/vuuw9ms9ll+47+GX744YcIDQ1t8dBae/wMXX0v6HQ6KBSKRsG/pe9FWxt3n9MaAV7bE5EPzJw5E0eOHGnxnICUlBSkpKTYH6empmLQoEFYuXIl3nzzTV+X6bH77rvPfn/o0KFITk5GfHw8Nm7c6Na/MDuSDz74APfddx9iY2ObbNPRPr+urK6uDhMmTIAQAsuXL2+2bUf6PX/00Uft94cMGYKhQ4eiT58+2LlzJ0aPHu3Hynxj9erVeOyxx1q86KQ9fobufi+0F+zR6oCioqIgl8sbXU1RXFwMrVbr8jlardaj9u3BM888g88//xw7duzATTfd5NFzAwMDcdttt6GgoMBH1XlXeHg4+vfv32S9HfHzA4Bz587h66+/xu9+9zuPnteRPj/bZ+DJ59Oav+H2wBayzp07h5ycnGZ7s1xp6fe8Pbn55psRFRXVZK0d9TMEgH//+984efKkx3+XgP8/w6a+F7RaLUwmE8rLy53at/S9aGvj7nNag0GrA1IoFEhMTERubq59ncViQW5urlOvgKOUlBSn9gCQk5PTZHt/EkLgmWeewaeffopvvvkGCQkJHu/DbDbj8OHDiImJ8UGF3ldZWYnTp083WW9H+vwcrVmzBj169MDYsWM9el5H+vwSEhKg1WqdPh+DwYD8/PwmP5/W/A37my1knTp1Cl9//TW6devm8T5a+j1vTy5evIirV682WWtH/AxtPvjgAyQmJmLYsGEeP9dfn2FL3wuJiYkIDAx0+jxOnjyJ8+fPN/l5tOZvt7XFUwe0fv16oVQqxdq1a8WxY8fE9OnTRXh4uNDpdEIIISZPnixefvlle/tdu3aJgIAAsWjRInH8+HGRlZUlAgMDxeHDh/31Fpr01FNPCY1GI3bu3CmKiorsS1VVlb3N9e/v9ddfF1999ZU4ffq02Ldvn3j00UeFSqUSR48e9cdbaNHzzz8vdu7cKc6cOSN27dol0tLSRFRUlCgpKRFCdOzPz8ZsNotevXqJl156qdG2jvb5VVRUiAMHDogDBw4IAOJPf/qTOHDggP2Ku7fffluEh4eLbdu2iUOHDonx48eLhIQEUV1dbd/HL37xC7F06VL745b+httac+/RZDKJcePGiZtuukkcPHjQ6e+ytrbWvo/r32NLv+ft5f1VVFSIF154QeTl5YkzZ86Ir7/+WvzsZz8T/fr1EzU1NU2+v470Gdro9XoRFBQkli9f7nIf7fUzdOd74cknnxS9evUS33zzjfjhhx9ESkqKSElJcdrPgAEDxJYtW+yP3fnbvVEMWh3Y0qVLRa9evYRCoRBJSUliz5499m0jR44UU6dOdWq/ceNG0b9/f6FQKMTgwYPFF1980cYVuweAy2XNmjX2Nte/v9mzZ9t/FtHR0eL+++8X+/fvb/vi3TRx4kQRExMjFAqF6Nmzp5g4caIoKCiwb+/In5/NV199JQCIkydPNtrW0T6/HTt2uPydtL0Hi8Ui5s2bJ6Kjo4VSqRSjR49u9L7j4+NFVlaW07rm/obbWnPv8cyZM03+Xe7YscO+j+vfY0u/522pufdXVVUlfvnLX4ru3buLwMBAER8fL5544olGgakjf4Y2K1euFGq1WpSXl7vcR3v9DN35XqiurhZPP/20iIiIEEFBQeLBBx8URUVFjfbj+Bx3/nZvlNTwwkRERETkZTxHi4iIiMhHGLSIiIiIfIRBi4iIiMhHGLSIiIiIfIRBi4iIiMhHGLSIiIiIfIRBi4iIiMhHGLSIiIiIfIRBi4jIzyRJwtatW/1dBhH5AIMWEXVpjz/+OCRJarSMGTPG36URUScQ4O8CiIj8bcyYMVizZo3TOqVS6adqiKgzYY8WEXV5SqUSWq3WaYmIiABgPay3fPly3HfffVCr1bj55pvx97//3en5hw8fxi9+8Quo1Wp069YN06dPR2VlpVOb1atXY/DgwVAqlYiJicEzzzzjtP3KlSt48MEHERQUhH79+uGzzz6zbysrK8Njjz2G7t27Q61Wo1+/fo2CIRG1TwxaREQtmDdvHh566CH8+OOPeOyxx/Doo4/i+PHjAACj0Yj09HRERETg+++/x6ZNm/D11187Banly5dj5syZmD59Og4fPozPPvsMffv2dXqN119/HRMmTMChQ4dw//3347HHHkNpaan99Y8dO4Z//vOfOH78OJYvX46oqKi2+wEQUesJIqIubOrUqUIul4vg4GCn5X/+53+EEEIAEE8++aTTc5KTk8VTTz0lhBBi1apVIiIiQlRWVtq3f/HFF0ImkwmdTieEECI2Nlb893//d5M1ABCvvvqq/XFlZaUAIP75z38KIYR44IEHxLRp07zzhomoTfEcLSLq8kaNGoXly5c7rYuMjLTfT0lJcdqWkpKCgwcPAgCOHz+OYcOGITg42L79rrvugsViwcmTJyFJEgoLCzF69Ohmaxg6dKj9fnBwMMLCwlBSUgIAeOqpp/DQQw9h//79+OUvf4mMjAykpqa26r0SUdti0CKiLi84OLjRoTxvUavVbrULDAx0eixJEiwWCwDgvvvuw7lz5/Dll18iJycHo0ePxsyZM7Fo0SKv10tE3sVztIiIWrBnz55GjwcNGgQAGDRoEH788UcYjUb79l27dkEmk2HAgAEIDQ1F7969kZube0M1dO/eHVOnTsVHH32ExYsXY9WqVTe0PyJqG+zRIqIur7a2FjqdzmldQECA/YTzTZs24fbbb8eIESPw8ccfY+/evfjggw8AAI899hiysrIwdepUvPbaa7h8+TKeffZZTJ48GdHR0QCA1157DU8++SR69OiB++67DxUVFdi1axeeffZZt+qbP38+EhMTMXjwYNTW1uLzzz+3Bz0iat8YtIioy9u+fTtiYmKc1g0YMAAnTpwAYL0icP369Xj66acRExODdevW4ZZbbgEABAUF4auvvsKsWbNwxx13ICgoCA899BD+9Kc/2fc1depU1NTU4L333sMLL7yAqKgoPPzww27Xp1AoMHfuXJw9exZqtRp333031q9f74V3TkS+JgkhhL+LICJqryRJwqeffoqMjAx/l0JEHRDP0SIiIiLyEQYtIiIiIh/hOVpERM3g2RVEdCPYo0VERETkIwxaRERERD7CoEVERETkIwxaRERERD7CoEVERETkIwxaRERERD7CoEVERETkIwxaRERERD7y/wGqeCgZGhbe8QAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test\n",
        "\n",
        "Test model on the test set."
      ],
      "metadata": {
        "id": "b7odzij5Av3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# predict on the test set\n",
        "lightGCN.eval()\n",
        "print(\"Training completed after {} epochs\".format(epochs))\n",
        "\n",
        "users_test = samples_test[:, 0:1]\n",
        "pos_test = samples_test[:, 1:2]\n",
        "neg_test = samples_test[:, 2:3]\n",
        "\n",
        "loss_test, reg_loss_test = bpr_loss(\n",
        "    lightGCN, users_test, pos_test, neg_test, data, test_mask)\n",
        "reg_loss_test = reg_loss_test * weight_decay\n",
        "\n",
        "# predict on the test set\n",
        "user_indices = samples_test[:, 0]\n",
        "user_indices = user_indices.repeat(2).long()\n",
        "item_indices = torch.cat((samples_test[:, 1], samples_test[:, 2])).long()\n",
        "pred_test = getUsersRating(lightGCN, users_test[:,0], data)\\\n",
        "    [user_indices, item_indices]\n",
        "truth_test = data[\"edge_index\"][users_test.long()[:,0]]\\\n",
        "    [user_indices, item_indices]\n",
        "test_topk_precision, test_topk_recall = personalized_topk(\n",
        "    pred_test, K, user_indices, data[\"edge_index\"])\n",
        "\n",
        "print(\"Average bpr_loss on the test set is {}, and regularization loss is {}.\\n\".format(round(float((loss_test+reg_loss_test)/len(samples_test)), 6),\n",
        "                                                                                                round(float(reg_loss_test/len(samples_test)), 6)),\n",
        "      \"Top K precision = {}, recall = {}.\".format(test_topk_precision, test_topk_recall))\n",
        "\n",
        "# Save model embeddings.\n",
        "torch.save(lightGCN, config_dict[\"model_name\"])\n",
        "\n",
        "print(f\"Model state dictionary saved to {config_dict['model_name']}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJnetNBG6C_k",
        "outputId": "a3e35bb4-8d76-47e4-b938-6672c73a69bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed after 21 epochs\n",
            "Average bpr_loss on the test set is 2e-06, and regularization loss is 0.0.\n",
            " Top K precision = 0.022367549668873832, recall = 0.0016056076799480653.\n",
            "Model state dictionary saved to model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run matrix factorization as baseline performance\n",
        "\n",
        "As a baseline, Run [PARAFAC matrix factorization](https://www.sciencedirect.com/science/article/abs/pii/S0169743997000324) on the dataset. Use the [TensorLy](http://tensorly.org/dev/modules/generated/tensorly.decomposition.parafac.html#tensorly.decomposition.parafac) library."
      ],
      "metadata": {
        "id": "LrNgRqvJAxdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def matrix_factorization(user_item, rank):\n",
        "    \"\"\"Runs matrix factorization on `user_item` and get user-item similarities.\n",
        "\n",
        "    Args:\n",
        "        user_item: User-item connectivity matrix.\n",
        "        rank: Number of numbers to represent a user / item.\n",
        "\n",
        "    Returns:\n",
        "        User-item similarities.\n",
        "    \"\"\"\n",
        "    weights, (user_factors, item_factors) = \\\n",
        "        decomposition.parafac(user_item, rank)\n",
        "    similarities = user_factors @ item_factors.T\n",
        "    return 1 / (1 + np.exp(- similarities))"
      ],
      "metadata": {
        "id": "ivMeZ8SP6sAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observe that LightGCN model delivers betters performance than matrix factorization."
      ],
      "metadata": {
        "id": "Z0GhZI3cQ7D1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute baseline metrics using matrix factorization.\n",
        "baseline_pred = matrix_factorization(\n",
        "        data[\"edge_index\"].detach().cpu().numpy(),\n",
        "        config_dict[\"mf_rank\"])[user_indices.cpu(), item_indices.cpu()]\n",
        "baseline_topk_precision, baseline_topk_recall = \\\n",
        "        personalized_topk(baseline_pred, K, user_indices, data[\"edge_index\"])\n",
        "print(\"Baseline (PARAFAC matrix factorization) produces \",\n",
        "      \"Top K precision = {}, recall = {}.\".format(baseline_topk_precision,\n",
        "                                                  baseline_topk_recall))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G30yzPzf6A36",
        "outputId": "233d8389-dd50-41fa-87bd-662b9f4319ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline (PARAFAC matrix factorization) produces  Top K precision = 0.06466887417218621, recall = 0.004758460762752693.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo"
      ],
      "metadata": {
        "id": "D_Tq2IfP1ctp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Dy8VW7d41eMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root = os.getcwd()\n",
        "movielens = MovieLens(root=root, transform=trans_ml)\n",
        "data = movielens.get()\n",
        "\n",
        "def get_top_movie_recommendations(user_id, num_recommendations=10):\n",
        "    \"\"\"\n",
        "    Generate movie recommendations for a specific user\n",
        "\n",
        "    Args:\n",
        "        user_id: ID of the user to generate recommendations for (1-indexed)\n",
        "        num_recommendations: Number of recommendations to return\n",
        "\n",
        "    Returns:\n",
        "        List of dictionaries containing recommended movie information\n",
        "    \"\"\"\n",
        "    # Load the trained model\n",
        "    model = torch.load(config_dict[\"model_name\"], weights_only=False)\n",
        "    model.eval()\n",
        "\n",
        "    # Adjust user_id to 0-indexed\n",
        "    user_index = user_id - 1\n",
        "\n",
        "    # Load movie data\n",
        "    with zipfile.ZipFile(os.path.join(root, \"raw/ml-1m.zip\"), 'r') as zip_ref:\n",
        "        if not os.path.exists(os.path.join(root, \"raw/ml-1m/movies.dat\")):\n",
        "            zip_ref.extract(\"ml-1m/movies.dat\", os.path.join(root, \"raw\"))\n",
        "\n",
        "    # Load movie information\n",
        "    mnames = ['movie_id', 'title', 'genres']\n",
        "    movies_df = pd.read_table(os.path.join(root, \"raw/ml-1m/movies.dat\"),\n",
        "                          sep='::', header=None, names=mnames,\n",
        "                          engine='python', encoding='latin-1')\n",
        "\n",
        "    # Get user-item ratings\n",
        "    all_ratings = getUsersRating(model, torch.tensor([user_index]), data)\n",
        "    user_ratings = all_ratings[0]  # Ratings for this specific user\n",
        "\n",
        "    # Find movies the user has already watched (from raw ratings matrix)\n",
        "    watched_movies = set(torch.nonzero(data[\"raw_edge_index\"][user_index] > 0).squeeze().cpu().tolist())\n",
        "    if not isinstance(watched_movies, set):\n",
        "        watched_movies = {watched_movies}\n",
        "\n",
        "    # Create a mask to filter out already watched movies\n",
        "    mask = torch.ones_like(user_ratings, dtype=torch.bool)\n",
        "    for idx in watched_movies:\n",
        "        mask[idx] = False\n",
        "\n",
        "    # Get top K recommendations (excluding watched movies)\n",
        "    filtered_ratings = user_ratings * mask\n",
        "    _, top_indices = torch.topk(filtered_ratings, min(num_recommendations, int(mask.sum())))\n",
        "    top_indices = top_indices.cpu().tolist()\n",
        "\n",
        "    # Format recommendations\n",
        "    recommendations = []\n",
        "    for idx in top_indices:\n",
        "        movie_id = idx + 1  # Convert 0-based index to 1-based movie_id\n",
        "        movie_info = movies_df[movies_df['movie_id'] == movie_id]\n",
        "        if not movie_info.empty:\n",
        "            title = movie_info.iloc[0]['title']\n",
        "            genres = movie_info.iloc[0]['genres']\n",
        "            score = user_ratings[idx].item()\n",
        "            recommendations.append({\n",
        "                'movie_id': movie_id,\n",
        "                'title': title,\n",
        "                'genres': genres,\n",
        "                'score': score\n",
        "            })\n",
        "\n",
        "    return recommendations\n",
        "\n",
        "def display_recommendations(user_id, num_recommendations=10):\n",
        "    \"\"\"Display formatted movie recommendations for a user\"\"\"\n",
        "    recommendations = get_top_movie_recommendations(user_id, num_recommendations)\n",
        "\n",
        "    print(f\"\\nTop {num_recommendations} Movie Recommendations for User {user_id}:\")\n",
        "    print(\"=\"*80)\n",
        "    for i, rec in enumerate(recommendations, 1):\n",
        "        print(f\"{i}. {rec['title']} ({rec['genres']})\")\n",
        "\n",
        "    return recommendations\n",
        "\n",
        "# Example\n",
        "if __name__ == \"__main__\":\n",
        "    display_recommendations(user_id=22, num_recommendations=10)\n",
        "    display_recommendations(user_id=105, num_recommendations=10)\n",
        "    display_recommendations(user_id=3054, num_recommendations=10)\n",
        "    display_recommendations(user_id=4760, num_recommendations=10)\n",
        "    display_recommendations(user_id=5433, num_recommendations=10)\n",
        "    display_recommendations(user_id=6030, num_recommendations=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKUp_p7jOdp_",
        "outputId": "22914403-fb78-4f2e-cbc0-42924c187184"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 10 Movie Recommendations for User 22:\n",
            "================================================================================\n",
            "1. Licence to Kill (1989) (Action)\n",
            "2. King of Masks, The (Bian Lian) (1996) (Drama)\n",
            "3. Toy Story (1995) (Animation|Children's|Comedy)\n",
            "4. Jumanji (1995) (Adventure|Children's|Fantasy)\n",
            "5. Sabrina (1995) (Comedy|Romance)\n",
            "6. Tom and Huck (1995) (Adventure|Children's)\n",
            "7. Heat (1995) (Action|Crime|Thriller)\n",
            "8. Father of the Bride Part II (1995) (Comedy)\n",
            "9. Grumpier Old Men (1995) (Comedy|Romance)\n",
            "10. Waiting to Exhale (1995) (Comedy|Drama)\n",
            "\n",
            "Top 10 Movie Recommendations for User 105:\n",
            "================================================================================\n",
            "1. Careful (1992) (Comedy)\n",
            "2. Jumanji (1995) (Adventure|Children's|Fantasy)\n",
            "3. Waiting to Exhale (1995) (Comedy|Drama)\n",
            "4. Tom and Huck (1995) (Adventure|Children's)\n",
            "5. Sudden Death (1995) (Action)\n",
            "6. Toy Story (1995) (Animation|Children's|Comedy)\n",
            "7. Grumpier Old Men (1995) (Comedy|Romance)\n",
            "8. Sabrina (1995) (Comedy|Romance)\n",
            "9. GoldenEye (1995) (Action|Adventure|Thriller)\n",
            "10. Father of the Bride Part II (1995) (Comedy)\n",
            "\n",
            "Top 10 Movie Recommendations for User 3054:\n",
            "================================================================================\n",
            "1. Sudden Death (1995) (Action)\n",
            "2. Tom and Huck (1995) (Adventure|Children's)\n",
            "3. Heat (1995) (Action|Crime|Thriller)\n",
            "4. Sabrina (1995) (Comedy|Romance)\n",
            "5. Grumpier Old Men (1995) (Comedy|Romance)\n",
            "6. Jumanji (1995) (Adventure|Children's|Fantasy)\n",
            "7. Waiting to Exhale (1995) (Comedy|Drama)\n",
            "8. Father of the Bride Part II (1995) (Comedy)\n",
            "9. GoldenEye (1995) (Action|Adventure|Thriller)\n",
            "10. American President, The (1995) (Comedy|Drama|Romance)\n",
            "\n",
            "Top 10 Movie Recommendations for User 4760:\n",
            "================================================================================\n",
            "1. Tom and Huck (1995) (Adventure|Children's)\n",
            "2. Sabrina (1995) (Comedy|Romance)\n",
            "3. Father of the Bride Part II (1995) (Comedy)\n",
            "4. Heat (1995) (Action|Crime|Thriller)\n",
            "5. Jumanji (1995) (Adventure|Children's|Fantasy)\n",
            "6. Toy Story (1995) (Animation|Children's|Comedy)\n",
            "7. Grumpier Old Men (1995) (Comedy|Romance)\n",
            "8. Waiting to Exhale (1995) (Comedy|Drama)\n",
            "9. Sudden Death (1995) (Action)\n",
            "10. GoldenEye (1995) (Action|Adventure|Thriller)\n",
            "\n",
            "Top 10 Movie Recommendations for User 5433:\n",
            "================================================================================\n",
            "1. Dracula: Dead and Loving It (1995) (Comedy|Horror)\n",
            "2. Sudden Death (1995) (Action)\n",
            "3. Sabrina (1995) (Comedy|Romance)\n",
            "4. Tom and Huck (1995) (Adventure|Children's)\n",
            "5. Grumpier Old Men (1995) (Comedy|Romance)\n",
            "6. Toy Story (1995) (Animation|Children's|Comedy)\n",
            "7. Waiting to Exhale (1995) (Comedy|Drama)\n",
            "8. Father of the Bride Part II (1995) (Comedy)\n",
            "9. Balto (1995) (Animation|Children's)\n",
            "10. Nixon (1995) (Drama)\n",
            "\n",
            "Top 10 Movie Recommendations for User 6030:\n",
            "================================================================================\n",
            "1. Sudden Death (1995) (Action)\n",
            "2. Tom and Huck (1995) (Adventure|Children's)\n",
            "3. Heat (1995) (Action|Crime|Thriller)\n",
            "4. Sabrina (1995) (Comedy|Romance)\n",
            "5. Grumpier Old Men (1995) (Comedy|Romance)\n",
            "6. Toy Story (1995) (Animation|Children's|Comedy)\n",
            "7. Waiting to Exhale (1995) (Comedy|Drama)\n",
            "8. Father of the Bride Part II (1995) (Comedy)\n",
            "9. GoldenEye (1995) (Action|Adventure|Thriller)\n",
            "10. American President, The (1995) (Comedy|Drama|Romance)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "axt_1VW7ko_i"
      }
    }
  ]
}